/** THIS FILE IS AUTOGENERATED FROM ark/repo/bundle.ts **/
// prettier-ignore
export const typeJs = "// ../util/out/arrays.js\nvar liftArray = (data) => Array.isArray(data) ? data : [data];\nvar spliterate = (arr, predicate) => {\n  const result = [[], []];\n  for (const item of arr) {\n    if (predicate(item))\n      result[0].push(item);\n    else\n      result[1].push(item);\n  }\n  return result;\n};\nvar ReadonlyArray = Array;\nvar includes = (array, element) => array.includes(element);\nvar range = (length, offset = 0) => [...new Array(length)].map((_, i) => i + offset);\nvar append = (to, value2, opts) => {\n  if (to === void 0) {\n    return value2 === void 0 ? [] : Array.isArray(value2) ? value2 : [value2];\n  }\n  if (opts?.prepend) {\n    if (Array.isArray(value2))\n      to.unshift(...value2);\n    else\n      to.unshift(value2);\n  } else {\n    if (Array.isArray(value2))\n      to.push(...value2);\n    else\n      to.push(value2);\n  }\n  return to;\n};\nvar conflatenate = (to, elementOrList) => {\n  if (elementOrList === void 0 || elementOrList === null)\n    return to ?? [];\n  if (to === void 0 || to === null)\n    return liftArray(elementOrList);\n  return to.concat(elementOrList);\n};\nvar conflatenateAll = (...elementsOrLists) => elementsOrLists.reduce(conflatenate, []);\nvar appendUnique = (to, value2, opts) => {\n  if (to === void 0)\n    return Array.isArray(value2) ? value2 : [value2];\n  const isEqual = opts?.isEqual ?? ((l, r) => l === r);\n  liftArray(value2).forEach((v) => {\n    if (!to.some((existing) => isEqual(existing, v)))\n      to.push(v);\n  });\n  return to;\n};\nvar groupBy = (array, discriminant) => array.reduce((result, item) => {\n  const key = item[discriminant];\n  result[key] = append(result[key], item);\n  return result;\n}, {});\nvar arrayEquals = (l, r, opts) => l.length === r.length && l.every(opts?.isEqual ? (lItem, i) => opts.isEqual(lItem, r[i]) : (lItem, i) => lItem === r[i]);\n\n// ../util/out/domain.js\nvar hasDomain = (data, kind) => domainOf(data) === kind;\nvar domainOf = (data) => {\n  const builtinType = typeof data;\n  return builtinType === \"object\" ? data === null ? \"null\" : \"object\" : builtinType === \"function\" ? \"object\" : builtinType;\n};\nvar domainDescriptions = {\n  boolean: \"boolean\",\n  null: \"null\",\n  undefined: \"undefined\",\n  bigint: \"a bigint\",\n  number: \"a number\",\n  object: \"an object\",\n  string: \"a string\",\n  symbol: \"a symbol\"\n};\nvar jsTypeOfDescriptions = {\n  ...domainDescriptions,\n  function: \"a function\"\n};\n\n// ../util/out/errors.js\nvar InternalArktypeError = class extends Error {\n};\nvar throwInternalError = (message) => throwError(message, InternalArktypeError);\nvar throwError = (message, ctor = Error) => {\n  throw new ctor(message);\n};\nvar ParseError = class extends Error {\n  name = \"ParseError\";\n};\nvar throwParseError = (message) => throwError(message, ParseError);\nvar noSuggest = (s) => ` ${s}`;\n\n// ../util/out/flatMorph.js\nvar flatMorph = (o, flatMapEntry) => {\n  const result = {};\n  const inputIsArray = Array.isArray(o);\n  let outputShouldBeArray = false;\n  Object.entries(o).forEach((entry, i) => {\n    const mapped = inputIsArray ? flatMapEntry(i, entry[1]) : flatMapEntry(...entry, i);\n    outputShouldBeArray ||= typeof mapped[0] === \"number\";\n    const flattenedEntries = Array.isArray(mapped[0]) || mapped.length === 0 ? (\n      // if we have an empty array (for filtering) or an array with\n      // another array as its first element, treat it as a list\n      mapped\n    ) : [mapped];\n    flattenedEntries.forEach(([k, v]) => {\n      if (typeof k === \"object\")\n        result[k.group] = append(result[k.group], v);\n      else\n        result[k] = v;\n    });\n  });\n  return outputShouldBeArray ? Object.values(result) : result;\n};\n\n// ../util/out/records.js\nvar entriesOf = Object.entries;\nvar isKeyOf = (k, o) => k in o;\nvar hasKey = (o, k) => k in o;\nvar DynamicBase = class {\n  constructor(properties) {\n    Object.assign(this, properties);\n  }\n};\nvar NoopBase = class {\n};\nvar CastableBase = class extends NoopBase {\n};\nvar splitByKeys = (o, leftKeys) => {\n  const l = {};\n  const r = {};\n  let k;\n  for (k in o) {\n    if (k in leftKeys)\n      l[k] = o[k];\n    else\n      r[k] = o[k];\n  }\n  return [l, r];\n};\nvar omit = (o, keys) => splitByKeys(o, keys)[1];\nvar isEmptyObject = (o) => Object.keys(o).length === 0;\nvar stringAndSymbolicEntriesOf = (o) => [\n  ...Object.entries(o),\n  ...Object.getOwnPropertySymbols(o).map((k) => [k, o[k]])\n];\nvar defineProperties = (base, merged) => (\n  // declared like this to avoid https://github.com/microsoft/TypeScript/issues/55049\n  Object.defineProperties(base, Object.getOwnPropertyDescriptors(merged))\n);\nvar withAlphabetizedKeys = (o) => {\n  const keys = Object.keys(o).sort();\n  const result = {};\n  for (let i = 0; i < keys.length; i++)\n    result[keys[i]] = o[keys[i]];\n  return result;\n};\nvar unset = noSuggest(\"represents an uninitialized value\");\nvar enumValues = (tsEnum) => Object.values(tsEnum).filter((v) => {\n  if (typeof v === \"number\")\n    return true;\n  return typeof tsEnum[v] !== \"number\";\n});\n\n// ../util/out/objectKinds.js\nvar ecmascriptConstructors = {\n  Array,\n  Boolean,\n  Date,\n  Error,\n  Function,\n  Map,\n  Number,\n  Promise,\n  RegExp,\n  Set,\n  String,\n  WeakMap,\n  WeakSet\n};\nvar FileConstructor = globalThis.File ?? Blob;\nvar platformConstructors = {\n  ArrayBuffer,\n  Blob,\n  File: FileConstructor,\n  FormData,\n  Headers,\n  Request,\n  Response,\n  URL\n};\nvar typedArrayConstructors = {\n  Int8Array,\n  Uint8Array,\n  Uint8ClampedArray,\n  Int16Array,\n  Uint16Array,\n  Int32Array,\n  Uint32Array,\n  Float32Array,\n  Float64Array,\n  BigInt64Array,\n  BigUint64Array\n};\nvar builtinConstructors = {\n  ...ecmascriptConstructors,\n  ...platformConstructors,\n  ...typedArrayConstructors,\n  String,\n  Number,\n  Boolean\n};\nvar objectKindOf = (data) => {\n  let prototype = Object.getPrototypeOf(data);\n  while (prototype?.constructor && (!isKeyOf(prototype.constructor.name, builtinConstructors) || !(data instanceof builtinConstructors[prototype.constructor.name])))\n    prototype = Object.getPrototypeOf(prototype);\n  const name = prototype?.constructor?.name;\n  if (name === void 0 || name === \"Object\")\n    return void 0;\n  return name;\n};\nvar objectKindOrDomainOf = (data) => typeof data === \"object\" && data !== null ? objectKindOf(data) ?? \"object\" : domainOf(data);\nvar isArray = Array.isArray;\nvar ecmascriptDescriptions = {\n  Array: \"an array\",\n  Function: \"a function\",\n  Date: \"a Date\",\n  RegExp: \"a RegExp\",\n  Error: \"an Error\",\n  Map: \"a Map\",\n  Set: \"a Set\",\n  String: \"a String object\",\n  Number: \"a Number object\",\n  Boolean: \"a Boolean object\",\n  Promise: \"a Promise\",\n  WeakMap: \"a WeakMap\",\n  WeakSet: \"a WeakSet\"\n};\nvar platformDescriptions = {\n  ArrayBuffer: \"an ArrayBuffer instance\",\n  Blob: \"a Blob instance\",\n  File: \"a File instance\",\n  FormData: \"a FormData instance\",\n  Headers: \"a Headers instance\",\n  Request: \"a Request instance\",\n  Response: \"a Response instance\",\n  URL: \"a URL instance\"\n};\nvar typedArrayDescriptions = {\n  Int8Array: \"an Int8Array\",\n  Uint8Array: \"a Uint8Array\",\n  Uint8ClampedArray: \"a Uint8ClampedArray\",\n  Int16Array: \"an Int16Array\",\n  Uint16Array: \"a Uint16Array\",\n  Int32Array: \"an Int32Array\",\n  Uint32Array: \"a Uint32Array\",\n  Float32Array: \"a Float32Array\",\n  Float64Array: \"a Float64Array\",\n  BigInt64Array: \"a BigInt64Array\",\n  BigUint64Array: \"a BigUint64Array\"\n};\nvar objectKindDescriptions = {\n  ...ecmascriptDescriptions,\n  ...platformDescriptions,\n  ...typedArrayDescriptions\n};\nvar getBuiltinNameOfConstructor = (ctor) => {\n  const constructorName = Object(ctor).name ?? null;\n  return constructorName && isKeyOf(constructorName, builtinConstructors) && builtinConstructors[constructorName] === ctor ? constructorName : null;\n};\nvar constructorExtends = (ctor, base) => {\n  let current = ctor.prototype;\n  while (current !== null) {\n    if (current === base.prototype)\n      return true;\n    current = Object.getPrototypeOf(current);\n  }\n  return false;\n};\n\n// ../util/out/clone.js\nvar deepClone = (input) => _clone(input, /* @__PURE__ */ new Map());\nvar _clone = (input, seen) => {\n  if (typeof input !== \"object\" || input === null)\n    return input;\n  if (seen?.has(input))\n    return seen.get(input);\n  const builtinConstructorName = getBuiltinNameOfConstructor(input.constructor);\n  if (builtinConstructorName === \"Date\")\n    return new Date(input.getTime());\n  if (builtinConstructorName && builtinConstructorName !== \"Array\")\n    return input;\n  const cloned = Array.isArray(input) ? input.slice() : Object.create(Object.getPrototypeOf(input));\n  const propertyDescriptors = Object.getOwnPropertyDescriptors(input);\n  if (seen) {\n    seen.set(input, cloned);\n    for (const k in propertyDescriptors) {\n      const desc = propertyDescriptors[k];\n      if (\"get\" in desc || \"set\" in desc)\n        continue;\n      desc.value = _clone(desc.value, seen);\n    }\n  }\n  Object.defineProperties(cloned, propertyDescriptors);\n  return cloned;\n};\n\n// ../util/out/functions.js\nvar cached = (thunk) => {\n  let result = unset;\n  return () => result === unset ? result = thunk() : result;\n};\nvar isThunk = (value2) => typeof value2 === \"function\" && value2.length === 0;\nvar DynamicFunction = class extends Function {\n  constructor(...args2) {\n    const params = args2.slice(0, -1);\n    const body = args2.at(-1);\n    try {\n      super(...params, body);\n    } catch (e) {\n      return throwInternalError(`Encountered an unexpected error while compiling your definition:\n                Message: ${e} \n                Source: (${args2.slice(0, -1)}) => {\n                    ${args2.at(-1)}\n                }`);\n    }\n  }\n};\nvar Callable = class {\n  constructor(fn, ...[opts]) {\n    return Object.assign(Object.setPrototypeOf(fn.bind(opts?.bind ?? this), this.constructor.prototype), opts?.attach);\n  }\n};\nvar envHasCsp = cached(() => {\n  try {\n    return new Function(\"return false\")();\n  } catch {\n    return true;\n  }\n});\n\n// ../util/out/generics.js\nvar brand = noSuggest(\"brand\");\nvar inferred = noSuggest(\"arkInferred\");\n\n// ../util/out/hkt.js\nvar args = noSuggest(\"args\");\nvar Hkt = class {\n  constructor() {\n  }\n};\n\n// ../util/out/strings.js\nvar capitalize = (s) => s[0].toUpperCase() + s.slice(1);\nvar anchoredRegex = (regex) => new RegExp(anchoredSource(regex), typeof regex === \"string\" ? \"\" : regex.flags);\nvar anchoredSource = (regex) => {\n  const source = typeof regex === \"string\" ? regex : regex.source;\n  return `^(?:${source})$`;\n};\nvar RegexPatterns = {\n  negativeLookahead: (pattern) => `(?!${pattern})`,\n  nonCapturingGroup: (pattern) => `(?:${pattern})`\n};\nvar escapeChar = \"\\\\\";\nvar whitespaceChars = {\n  \" \": 1,\n  \"\\n\": 1,\n  \"\t\": 1\n};\n\n// ../util/out/numbers.js\nvar anchoredNegativeZeroPattern = /^-0\\.?0*$/.source;\nvar positiveIntegerPattern = /[1-9]\\d*/.source;\nvar looseDecimalPattern = /\\.\\d+/.source;\nvar strictDecimalPattern = /\\.\\d*[1-9]/.source;\nvar createNumberMatcher = (opts) => anchoredRegex(RegexPatterns.negativeLookahead(anchoredNegativeZeroPattern) + RegexPatterns.nonCapturingGroup(\"-?\" + RegexPatterns.nonCapturingGroup(RegexPatterns.nonCapturingGroup(\"0|\" + positiveIntegerPattern) + RegexPatterns.nonCapturingGroup(opts.decimalPattern) + \"?\") + (opts.allowDecimalOnly ? \"|\" + opts.decimalPattern : \"\") + \"?\"));\nvar wellFormedNumberMatcher = createNumberMatcher({\n  decimalPattern: strictDecimalPattern,\n  allowDecimalOnly: false\n});\nvar isWellFormedNumber = wellFormedNumberMatcher.test.bind(wellFormedNumberMatcher);\nvar numericStringMatcher = createNumberMatcher({\n  decimalPattern: looseDecimalPattern,\n  allowDecimalOnly: true\n});\nvar isNumericString = numericStringMatcher.test.bind(numericStringMatcher);\nvar numberLikeMatcher = /^-?\\d*\\.?\\d*$/;\nvar isNumberLike = (s) => s.length !== 0 && numberLikeMatcher.test(s);\nvar wellFormedIntegerMatcher = anchoredRegex(RegexPatterns.negativeLookahead(\"^-0$\") + \"-?\" + RegexPatterns.nonCapturingGroup(RegexPatterns.nonCapturingGroup(\"0|\" + positiveIntegerPattern)));\nvar isWellFormedInteger = wellFormedIntegerMatcher.test.bind(wellFormedIntegerMatcher);\nvar integerLikeMatcher = /^-?\\d+$/;\nvar isIntegerLike = integerLikeMatcher.test.bind(integerLikeMatcher);\nvar numericLiteralDescriptions = {\n  number: \"a number\",\n  bigint: \"a bigint\",\n  integer: \"an integer\"\n};\nvar writeMalformedNumericLiteralMessage = (def, kind) => `'${def}' was parsed as ${numericLiteralDescriptions[kind]} but could not be narrowed to a literal value. Avoid unnecessary leading or trailing zeros and other abnormal notation`;\nvar isWellFormed = (def, kind) => kind === \"number\" ? isWellFormedNumber(def) : isWellFormedInteger(def);\nvar parseKind = (def, kind) => kind === \"number\" ? Number(def) : Number.parseInt(def);\nvar isKindLike = (def, kind) => kind === \"number\" ? isNumberLike(def) : isIntegerLike(def);\nvar tryParseNumber = (token, options) => parseNumeric(token, \"number\", options);\nvar tryParseWellFormedNumber = (token, options) => parseNumeric(token, \"number\", { ...options, strict: true });\nvar tryParseInteger = (token, options) => parseNumeric(token, \"integer\", options);\nvar parseNumeric = (token, kind, options) => {\n  const value2 = parseKind(token, kind);\n  if (!Number.isNaN(value2)) {\n    if (isKindLike(token, kind)) {\n      if (options?.strict) {\n        return isWellFormed(token, kind) ? value2 : throwParseError(writeMalformedNumericLiteralMessage(token, kind));\n      }\n      return value2;\n    }\n  }\n  return options?.errorOnFail ? throwParseError(options?.errorOnFail === true ? `Failed to parse ${numericLiteralDescriptions[kind]} from '${token}'` : options?.errorOnFail) : void 0;\n};\nvar tryParseWellFormedBigint = (def) => {\n  if (def[def.length - 1] !== \"n\")\n    return;\n  const maybeIntegerLiteral = def.slice(0, -1);\n  let value2;\n  try {\n    value2 = BigInt(maybeIntegerLiteral);\n  } catch {\n    return;\n  }\n  if (wellFormedIntegerMatcher.test(maybeIntegerLiteral))\n    return value2;\n  if (integerLikeMatcher.test(maybeIntegerLiteral)) {\n    return throwParseError(writeMalformedNumericLiteralMessage(def, \"bigint\"));\n  }\n};\n\n// ../util/out/fileName.js\nvar fileName = () => {\n  try {\n    const error = new Error();\n    const stackLine = error.stack?.split(\"\\n\")[2]?.trim() || \"\";\n    const filePath = stackLine.match(/\\(?(.+?)(?::\\d+:\\d+)?\\)?$/)?.[1] || \"unknown\";\n    return filePath.replace(/^file:\\/\\//, \"\");\n  } catch {\n    return \"unknown\";\n  }\n};\n\n// ../util/out/registry.js\nvar arkUtilVersion = \"0.45.6\";\nvar initialRegistryContents = {\n  version: arkUtilVersion,\n  filename: fileName(),\n  FileConstructor\n};\nvar registry = initialRegistryContents;\nvar namesByResolution = /* @__PURE__ */ new WeakMap();\nvar nameCounts = /* @__PURE__ */ Object.create(null);\nvar register = (value2) => {\n  const existingName = namesByResolution.get(value2);\n  if (existingName)\n    return existingName;\n  let name = baseNameFor(value2);\n  if (nameCounts[name])\n    name = `${name}${nameCounts[name]++}`;\n  else\n    nameCounts[name] = 1;\n  registry[name] = value2;\n  namesByResolution.set(value2, name);\n  return name;\n};\nvar isDotAccessible = (keyName) => /^[a-zA-Z_$][a-zA-Z_$0-9]*$/.test(keyName);\nvar baseNameFor = (value2) => {\n  switch (typeof value2) {\n    case \"object\": {\n      if (value2 === null)\n        break;\n      const prefix = objectKindOf(value2) ?? \"object\";\n      return prefix[0].toLowerCase() + prefix.slice(1);\n    }\n    case \"function\":\n      return isDotAccessible(value2.name) ? value2.name : \"fn\";\n    case \"symbol\":\n      return value2.description && isDotAccessible(value2.description) ? value2.description : \"symbol\";\n  }\n  return throwInternalError(`Unexpected attempt to register serializable value of type ${domainOf(value2)}`);\n};\n\n// ../util/out/primitive.js\nvar serializePrimitive = (value2) => typeof value2 === \"string\" ? JSON.stringify(value2) : typeof value2 === \"bigint\" ? `${value2}n` : `${value2}`;\n\n// ../util/out/serialize.js\nvar snapshot = (data, opts = {}) => _serialize(data, {\n  onUndefined: `$ark.undefined`,\n  onBigInt: (n) => `$ark.bigint-${n}`,\n  ...opts\n}, []);\nvar printable = (data, indent2) => {\n  switch (domainOf(data)) {\n    case \"object\":\n      const o = data;\n      const ctorName = o.constructor.name;\n      return ctorName === \"Object\" || ctorName === \"Array\" ? JSON.stringify(_serialize(o, printableOpts, []), null, indent2) : o instanceof Date ? describeCollapsibleDate(o) : typeof o.expression === \"string\" ? o.expression : ctorName;\n    case \"symbol\":\n      return printableOpts.onSymbol(data);\n    default:\n      return serializePrimitive(data);\n  }\n};\nvar printableOpts = {\n  onCycle: () => \"(cycle)\",\n  onSymbol: (v) => `Symbol(${register(v)})`,\n  onFunction: (v) => `Function(${register(v)})`\n};\nvar _serialize = (data, opts, seen) => {\n  switch (domainOf(data)) {\n    case \"object\": {\n      const o = data;\n      if (\"toJSON\" in o && typeof o.toJSON === \"function\")\n        return o.toJSON();\n      if (typeof o === \"function\")\n        return printableOpts.onFunction(o);\n      if (seen.includes(o))\n        return \"(cycle)\";\n      const nextSeen = [...seen, o];\n      if (Array.isArray(o))\n        return o.map((item) => _serialize(item, opts, nextSeen));\n      if (o instanceof Date)\n        return o.toDateString();\n      const result = {};\n      for (const k in o)\n        result[k] = _serialize(o[k], opts, nextSeen);\n      for (const s of Object.getOwnPropertySymbols(o)) {\n        result[opts.onSymbol?.(s) ?? s.toString()] = _serialize(o[s], opts, nextSeen);\n      }\n      return result;\n    }\n    case \"symbol\":\n      return printableOpts.onSymbol(data);\n    case \"bigint\":\n      return opts.onBigInt?.(data) ?? `${data}n`;\n    case \"undefined\":\n      return opts.onUndefined ?? \"undefined\";\n    case \"string\":\n      return data.replaceAll(\"\\\\\", \"\\\\\\\\\");\n    default:\n      return data;\n  }\n};\nvar describeCollapsibleDate = (date) => {\n  const year = date.getFullYear();\n  const month = date.getMonth();\n  const dayOfMonth = date.getDate();\n  const hours = date.getHours();\n  const minutes = date.getMinutes();\n  const seconds = date.getSeconds();\n  const milliseconds = date.getMilliseconds();\n  if (month === 0 && dayOfMonth === 1 && hours === 0 && minutes === 0 && seconds === 0 && milliseconds === 0)\n    return `${year}`;\n  const datePortion = `${months[month]} ${dayOfMonth}, ${year}`;\n  if (hours === 0 && minutes === 0 && seconds === 0 && milliseconds === 0)\n    return datePortion;\n  let timePortion = date.toLocaleTimeString();\n  const suffix2 = timePortion.endsWith(\" AM\") || timePortion.endsWith(\" PM\") ? timePortion.slice(-3) : \"\";\n  if (suffix2)\n    timePortion = timePortion.slice(0, -suffix2.length);\n  if (milliseconds)\n    timePortion += `.${pad(milliseconds, 3)}`;\n  else if (timeWithUnnecessarySeconds.test(timePortion))\n    timePortion = timePortion.slice(0, -3);\n  return `${timePortion + suffix2}, ${datePortion}`;\n};\nvar months = [\n  \"January\",\n  \"February\",\n  \"March\",\n  \"April\",\n  \"May\",\n  \"June\",\n  \"July\",\n  \"August\",\n  \"September\",\n  \"October\",\n  \"November\",\n  \"December\"\n];\nvar timeWithUnnecessarySeconds = /:\\d\\d:00$/;\nvar pad = (value2, length) => String(value2).padStart(length, \"0\");\n\n// ../util/out/path.js\nvar appendStringifiedKey = (path, prop, ...[opts]) => {\n  const stringifySymbol = opts?.stringifySymbol ?? printable;\n  let propAccessChain = path;\n  switch (typeof prop) {\n    case \"string\":\n      propAccessChain = isDotAccessible(prop) ? path === \"\" ? prop : `${path}.${prop}` : `${path}[${JSON.stringify(prop)}]`;\n      break;\n    case \"number\":\n      propAccessChain = `${path}[${prop}]`;\n      break;\n    case \"symbol\":\n      propAccessChain = `${path}[${stringifySymbol(prop)}]`;\n      break;\n    default:\n      if (opts?.stringifyNonKey)\n        propAccessChain = `${path}[${opts.stringifyNonKey(prop)}]`;\n      else {\n        throwParseError(`${printable(prop)} must be a PropertyKey or stringifyNonKey must be passed to options`);\n      }\n  }\n  return propAccessChain;\n};\nvar stringifyPath = (path, ...opts) => path.reduce((s, k) => appendStringifiedKey(s, k, ...opts), \"\");\nvar ReadonlyPath = class extends ReadonlyArray {\n  // alternate strategy for caching since the base object is frozen\n  cache = {};\n  constructor(...items) {\n    super();\n    this.push(...items);\n  }\n  toJSON() {\n    if (this.cache.json)\n      return this.cache.json;\n    this.cache.json = [];\n    for (let i = 0; i < this.length; i++) {\n      this.cache.json.push(typeof this[i] === \"symbol\" ? printable(this[i]) : this[i]);\n    }\n    return this.cache.json;\n  }\n  stringify() {\n    if (this.cache.stringify)\n      return this.cache.stringify;\n    return this.cache.stringify = stringifyPath(this);\n  }\n  stringifyAncestors() {\n    if (this.cache.stringifyAncestors)\n      return this.cache.stringifyAncestors;\n    let propString = \"\";\n    const result = [propString];\n    this.forEach((path) => {\n      propString = appendStringifiedKey(propString, path);\n      result.push(propString);\n    });\n    return this.cache.stringifyAncestors = result;\n  }\n};\n\n// ../util/out/scanner.js\nvar Scanner = class {\n  chars;\n  i;\n  def;\n  constructor(def) {\n    this.def = def;\n    this.chars = [...def];\n    this.i = 0;\n  }\n  /** Get lookahead and advance scanner by one */\n  shift() {\n    return this.chars[this.i++] ?? \"\";\n  }\n  get lookahead() {\n    return this.chars[this.i] ?? \"\";\n  }\n  get nextLookahead() {\n    return this.chars[this.i + 1] ?? \"\";\n  }\n  get length() {\n    return this.chars.length;\n  }\n  shiftUntil(condition) {\n    let shifted = \"\";\n    while (this.lookahead) {\n      if (condition(this, shifted)) {\n        if (shifted[shifted.length - 1] === escapeChar)\n          shifted = shifted.slice(0, -1);\n        else\n          break;\n      }\n      shifted += this.shift();\n    }\n    return shifted;\n  }\n  shiftUntilLookahead(charOrSet) {\n    return typeof charOrSet === \"string\" ? this.shiftUntil((s) => s.lookahead === charOrSet) : this.shiftUntil((s) => s.lookahead in charOrSet);\n  }\n  shiftUntilNonWhitespace() {\n    return this.shiftUntil(() => !(this.lookahead in whitespaceChars));\n  }\n  jumpToIndex(i) {\n    this.i = i < 0 ? this.length + i : i;\n  }\n  jumpForward(count) {\n    this.i += count;\n  }\n  get location() {\n    return this.i;\n  }\n  get unscanned() {\n    return this.chars.slice(this.i, this.length).join(\"\");\n  }\n  get scanned() {\n    return this.chars.slice(0, this.i).join(\"\");\n  }\n  sliceChars(start, end) {\n    return this.chars.slice(start, end).join(\"\");\n  }\n  lookaheadIs(char) {\n    return this.lookahead === char;\n  }\n  lookaheadIsIn(tokens) {\n    return this.lookahead in tokens;\n  }\n};\n\n// ../util/out/traits.js\nvar implementedTraits = noSuggest(\"implementedTraits\");\n\n// ../schema/out/shared/registry.js\nvar _registryName = \"$ark\";\nvar suffix = 2;\nwhile (_registryName in globalThis)\n  _registryName = `$ark${suffix++}`;\nvar registryName = _registryName;\nglobalThis[registryName] = registry;\nvar $ark = registry;\nif (suffix !== 2) {\n  const g = globalThis;\n  const registries = [g.$ark];\n  for (let i = 2; i < suffix; i++)\n    if (g[`$ark${i}`])\n      registries.push(g[`$ark${i}`]);\n  console.warn(`Multiple @ark registries detected. This can lead to unexpected behavior.`);\n  const byPath = groupBy(registries, \"filename\");\n  const paths = Object.keys(byPath);\n  for (const path of paths) {\n    if (byPath[path].length > 1) {\n      console.warn(`File ${path} was initialized multiple times, likely due to being imported from both CJS and ESM contexts.`);\n    }\n  }\n  if (paths.length > 1) {\n    console.warn(`Registries were initialized at the following paths:` + paths.map((path) => `\t${path} (@ark/util version ${byPath[path][0].version})`).join(\"\\n\"));\n  }\n}\nvar reference = (name) => `${registryName}.${name}`;\nvar registeredReference = (value2) => reference(register(value2));\n\n// ../schema/out/shared/compile.js\nvar CompiledFunction = class extends CastableBase {\n  argNames;\n  body = \"\";\n  constructor(...args2) {\n    super();\n    this.argNames = args2;\n    for (const arg of args2) {\n      if (arg in this) {\n        throw new Error(`Arg name '${arg}' would overwrite an existing property on FunctionBody`);\n      }\n      ;\n      this[arg] = arg;\n    }\n  }\n  indentation = 0;\n  indent() {\n    this.indentation += 4;\n    return this;\n  }\n  dedent() {\n    this.indentation -= 4;\n    return this;\n  }\n  prop(key, optional = false) {\n    return compileLiteralPropAccess(key, optional);\n  }\n  index(key, optional = false) {\n    return indexPropAccess(`${key}`, optional);\n  }\n  line(statement) {\n    ;\n    this.body += `${\" \".repeat(this.indentation)}${statement}\n`;\n    return this;\n  }\n  const(identifier, expression) {\n    this.line(`const ${identifier} = ${expression}`);\n    return this;\n  }\n  let(identifier, expression) {\n    return this.line(`let ${identifier} = ${expression}`);\n  }\n  set(identifier, expression) {\n    return this.line(`${identifier} = ${expression}`);\n  }\n  if(condition, then) {\n    return this.block(`if (${condition})`, then);\n  }\n  elseIf(condition, then) {\n    return this.block(`else if (${condition})`, then);\n  }\n  else(then) {\n    return this.block(\"else\", then);\n  }\n  /** Current index is \"i\" */\n  for(until, body, initialValue = 0) {\n    return this.block(`for (let i = ${initialValue}; ${until}; i++)`, body);\n  }\n  /** Current key is \"k\" */\n  forIn(object2, body) {\n    return this.block(`for (const k in ${object2})`, body);\n  }\n  block(prefix, contents, suffix2 = \"\") {\n    this.line(`${prefix} {`);\n    this.indent();\n    contents(this);\n    this.dedent();\n    return this.line(`}${suffix2}`);\n  }\n  return(expression = \"\") {\n    return this.line(`return ${expression}`);\n  }\n  write(name = \"anonymous\") {\n    return `${name}(${this.argNames.join(\", \")}) {\n${this.body}}`;\n  }\n  compile() {\n    return new DynamicFunction(...this.argNames, this.body);\n  }\n};\nvar compileSerializedValue = (value2) => hasDomain(value2, \"object\") || typeof value2 === \"symbol\" ? registeredReference(value2) : serializePrimitive(value2);\nvar compileLiteralPropAccess = (key, optional = false) => {\n  if (typeof key === \"string\" && isDotAccessible(key))\n    return `${optional ? \"?\" : \"\"}.${key}`;\n  return indexPropAccess(serializeLiteralKey(key), optional);\n};\nvar serializeLiteralKey = (key) => typeof key === \"symbol\" ? registeredReference(key) : JSON.stringify(key);\nvar indexPropAccess = (key, optional = false) => `${optional ? \"?.\" : \"\"}[${key}]`;\nvar NodeCompiler = class extends CompiledFunction {\n  traversalKind;\n  optimistic;\n  constructor(ctx) {\n    super(\"data\", \"ctx\");\n    this.traversalKind = ctx.kind;\n    this.optimistic = ctx.optimistic === true;\n  }\n  invoke(node2, opts) {\n    const arg = opts?.arg ?? this.data;\n    const requiresContext = typeof node2 === \"string\" ? true : this.requiresContextFor(node2);\n    const id = typeof node2 === \"string\" ? node2 : node2.id;\n    if (requiresContext)\n      return `${this.referenceToId(id, opts)}(${arg}, ${this.ctx})`;\n    return `${this.referenceToId(id, opts)}(${arg})`;\n  }\n  referenceToId(id, opts) {\n    const invokedKind = opts?.kind ?? this.traversalKind;\n    const base = `this.${id}${invokedKind}`;\n    return opts?.bind ? `${base}.bind(${opts?.bind})` : base;\n  }\n  requiresContextFor(node2) {\n    return this.traversalKind === \"Apply\" || node2.allowsRequiresContext;\n  }\n  initializeErrorCount() {\n    return this.const(\"errorCount\", \"ctx.currentErrorCount\");\n  }\n  returnIfFail() {\n    return this.if(\"ctx.currentErrorCount > errorCount\", () => this.return());\n  }\n  returnIfFailFast() {\n    return this.if(\"ctx.failFast && ctx.currentErrorCount > errorCount\", () => this.return());\n  }\n  traverseKey(keyExpression, accessExpression, node2) {\n    const requiresContext = this.requiresContextFor(node2);\n    if (requiresContext)\n      this.line(`${this.ctx}.path.push(${keyExpression})`);\n    this.check(node2, {\n      arg: accessExpression\n    });\n    if (requiresContext)\n      this.line(`${this.ctx}.path.pop()`);\n    return this;\n  }\n  check(node2, opts) {\n    return this.traversalKind === \"Allows\" ? this.if(`!${this.invoke(node2, opts)}`, () => this.return(false)) : this.line(this.invoke(node2, opts));\n  }\n};\n\n// ../schema/out/shared/utils.js\nvar makeRootAndArrayPropertiesMutable = (o) => (\n  // this cast should not be required, but it seems TS is referencing\n  // the wrong parameters here?\n  flatMorph(o, (k, v) => [k, isArray(v) ? [...v] : v])\n);\nvar arkKind = noSuggest(\"arkKind\");\nvar hasArkKind = (value2, kind) => value2?.[arkKind] === kind;\nvar isNode = (value2) => hasArkKind(value2, \"root\") || hasArkKind(value2, \"constraint\");\n\n// ../schema/out/shared/implement.js\nvar basisKinds = [\"unit\", \"proto\", \"domain\"];\nvar structuralKinds = [\n  \"required\",\n  \"optional\",\n  \"index\",\n  \"sequence\"\n];\nvar refinementKinds = [\n  \"pattern\",\n  \"divisor\",\n  \"exactLength\",\n  \"max\",\n  \"min\",\n  \"maxLength\",\n  \"minLength\",\n  \"before\",\n  \"after\"\n];\nvar constraintKinds = [\n  ...refinementKinds,\n  ...structuralKinds,\n  \"structure\",\n  \"predicate\"\n];\nvar rootKinds = [\n  \"alias\",\n  \"union\",\n  \"morph\",\n  \"unit\",\n  \"intersection\",\n  \"proto\",\n  \"domain\"\n];\nvar nodeKinds = [...rootKinds, ...constraintKinds];\nvar constraintKeys = flatMorph(constraintKinds, (i, kind) => [kind, 1]);\nvar structureKeys = flatMorph([...structuralKinds, \"undeclared\"], (i, k) => [k, 1]);\nvar precedenceByKind = flatMorph(nodeKinds, (i, kind) => [kind, i]);\nvar isNodeKind = (value2) => typeof value2 === \"string\" && value2 in precedenceByKind;\nvar precedenceOfKind = (kind) => precedenceByKind[kind];\nvar schemaKindsRightOf = (kind) => rootKinds.slice(precedenceOfKind(kind) + 1);\nvar unionChildKinds = [\n  ...schemaKindsRightOf(\"union\"),\n  \"alias\"\n];\nvar morphChildKinds = [\n  ...schemaKindsRightOf(\"morph\"),\n  \"alias\"\n];\nvar defaultValueSerializer = (v) => {\n  if (typeof v === \"string\" || typeof v === \"boolean\" || v === null)\n    return v;\n  if (typeof v === \"number\") {\n    if (Number.isNaN(v))\n      return \"NaN\";\n    if (v === Number.POSITIVE_INFINITY)\n      return \"Infinity\";\n    if (v === Number.NEGATIVE_INFINITY)\n      return \"-Infinity\";\n    return v;\n  }\n  return compileSerializedValue(v);\n};\nvar compileObjectLiteral = (ctx) => {\n  let result = \"{ \";\n  for (const [k, v] of Object.entries(ctx))\n    result += `${k}: ${compileSerializedValue(v)}, `;\n  return result + \" }\";\n};\nvar implementNode = (_) => {\n  const implementation23 = _;\n  if (implementation23.hasAssociatedError) {\n    implementation23.defaults.expected ??= (ctx) => \"description\" in ctx ? ctx.description : implementation23.defaults.description(ctx);\n    implementation23.defaults.actual ??= (data) => printable(data);\n    implementation23.defaults.problem ??= (ctx) => `must be ${ctx.expected}${ctx.actual ? ` (was ${ctx.actual})` : \"\"}`;\n    implementation23.defaults.message ??= (ctx) => {\n      if (ctx.path.length === 0)\n        return ctx.problem;\n      const problemWithLocation = `${ctx.propString} ${ctx.problem}`;\n      if (problemWithLocation[0] === \"[\") {\n        return `value at ${problemWithLocation}`;\n      }\n      return problemWithLocation;\n    };\n  }\n  return implementation23;\n};\n\n// ../schema/out/config.js\n$ark.config ??= {};\nvar configureSchema = (config) => {\n  const result = Object.assign($ark.config, mergeConfigs($ark.config, config));\n  $ark.resolvedConfig &&= mergeConfigs($ark.resolvedConfig, result);\n  return result;\n};\nvar mergeConfigs = (base, extensions) => {\n  if (!extensions)\n    return base;\n  const result = { ...base };\n  let k;\n  for (k in extensions) {\n    const keywords2 = { ...base.keywords };\n    if (k === \"keywords\") {\n      for (const flatAlias in extensions[k]) {\n        const v = extensions.keywords[flatAlias];\n        if (v === void 0)\n          continue;\n        keywords2[flatAlias] = typeof v === \"string\" ? { description: v } : v;\n      }\n      result.keywords = keywords2;\n    } else {\n      result[k] = isNodeKind(k) ? (\n        // not casting this makes TS compute a very inefficient\n        // type that is not needed\n        {\n          ...base[k],\n          ...extensions[k]\n        }\n      ) : extensions[k];\n    }\n  }\n  return result;\n};\n\n// ../schema/out/shared/errors.js\nvar ArkError = class _ArkError extends CastableBase {\n  [arkKind] = \"error\";\n  path;\n  data;\n  nodeConfig;\n  input;\n  ctx;\n  // TS gets confused by <code>, so internally we just use the base type for input\n  constructor({ prefixPath, relativePath, ...input }, ctx) {\n    super();\n    this.input = input;\n    this.ctx = ctx;\n    defineProperties(this, input);\n    const data = ctx.data;\n    if (input.code === \"union\") {\n      input.errors = input.errors.flatMap((innerError) => {\n        const flat = innerError.hasCode(\"union\") ? innerError.errors : [innerError];\n        if (!prefixPath && !relativePath)\n          return flat;\n        return flat.map((e) => e.transform((e2) => ({\n          ...e2,\n          path: conflatenateAll(prefixPath, e2.path, relativePath)\n        })));\n      });\n    }\n    this.nodeConfig = ctx.config[this.code];\n    const basePath = [...input.path ?? ctx.path];\n    if (relativePath)\n      basePath.push(...relativePath);\n    if (prefixPath)\n      basePath.unshift(...prefixPath);\n    this.path = new ReadonlyPath(...basePath);\n    this.data = \"data\" in input ? input.data : data;\n  }\n  transform(f) {\n    return new _ArkError(f({\n      data: this.data,\n      path: this.path,\n      ...this.input\n    }), this.ctx);\n  }\n  hasCode(code) {\n    return this.code === code;\n  }\n  get propString() {\n    return stringifyPath(this.path);\n  }\n  get expected() {\n    if (this.input.expected)\n      return this.input.expected;\n    const config = this.meta?.expected ?? this.nodeConfig.expected;\n    return typeof config === \"function\" ? config(this.input) : config;\n  }\n  get actual() {\n    if (this.input.actual)\n      return this.input.actual;\n    const config = this.meta?.actual ?? this.nodeConfig.actual;\n    return typeof config === \"function\" ? config(this.data) : config;\n  }\n  get problem() {\n    if (this.input.problem)\n      return this.input.problem;\n    const config = this.meta?.problem ?? this.nodeConfig.problem;\n    return typeof config === \"function\" ? config(this) : config;\n  }\n  get message() {\n    if (this.input.message)\n      return this.input.message;\n    const config = this.meta?.message ?? this.nodeConfig.message;\n    return typeof config === \"function\" ? config(this) : config;\n  }\n  get flat() {\n    return this.hasCode(\"intersection\") ? [...this.errors] : [this];\n  }\n  toJSON() {\n    return {\n      data: this.data,\n      path: this.path,\n      ...this.input,\n      expected: this.expected,\n      actual: this.actual,\n      problem: this.problem,\n      message: this.message\n    };\n  }\n  toString() {\n    return this.message;\n  }\n  throw() {\n    throw this;\n  }\n};\nvar ArkErrors = class _ArkErrors extends ReadonlyArray {\n  ctx;\n  constructor(ctx) {\n    super();\n    this.ctx = ctx;\n  }\n  /**\n   * Errors by a pathString representing their location.\n   */\n  byPath = /* @__PURE__ */ Object.create(null);\n  /**\n   * {@link byPath} flattened so that each value is an array of ArkError instances at that path.\n   *\n   * ✅ Since \"intersection\" errors will be flattened to their constituent `.errors`,\n   * they will never be directly present in this representation.\n   */\n  get flatByPath() {\n    return flatMorph(this.byPath, (k, v) => [k, v.flat]);\n  }\n  /**\n   * {@link byPath} flattened so that each value is an array of problem strings at that path.\n   */\n  get flatProblemsByPath() {\n    return flatMorph(this.byPath, (k, v) => [k, v.flat.map((e) => e.problem)]);\n  }\n  /**\n   * All pathStrings at which errors are present mapped to the errors occuring\n   * at that path or any nested path within it.\n   */\n  byAncestorPath = /* @__PURE__ */ Object.create(null);\n  count = 0;\n  mutable = this;\n  /**\n   * Throw a TraversalError based on these errors.\n   */\n  throw() {\n    throw this.toTraversalError();\n  }\n  /**\n   * Converts ArkErrors to TraversalError, a subclass of `Error` suitable for throwing with nice\n   * formatting.\n   */\n  toTraversalError() {\n    return new TraversalError(this);\n  }\n  /**\n   * Append an ArkError to this array, ignoring duplicates.\n   */\n  add(error) {\n    if (this.includes(error))\n      return;\n    this._add(error);\n  }\n  transform(f) {\n    const result = new _ArkErrors(this.ctx);\n    this.forEach((e) => result.add(f(e)));\n    return result;\n  }\n  /**\n   * Add all errors from an ArkErrors instance, ignoring duplicates and\n   * prefixing their paths with that of the current Traversal.\n   */\n  merge(errors) {\n    errors.forEach((e) => {\n      if (this.includes(e))\n        return;\n      this._add(new ArkError({ ...e, path: [...this.ctx.path, ...e.path] }, this.ctx));\n    });\n  }\n  /**\n   * @internal\n   */\n  affectsPath(path) {\n    if (this.length === 0)\n      return false;\n    return (\n      // this would occur if there is an existing error at a prefix of path\n      // e.g. the path is [\"foo\", \"bar\"] and there is an error at [\"foo\"]\n      path.stringifyAncestors().some((s) => s in this.byPath) || // this would occur if there is an existing error at a suffix of path\n      // e.g. the path is [\"foo\"] and there is an error at [\"foo\", \"bar\"]\n      path.stringify() in this.byAncestorPath\n    );\n  }\n  /**\n   * A human-readable summary of all errors.\n   */\n  get summary() {\n    return this.toString();\n  }\n  /**\n   * Alias of this ArkErrors instance for StandardSchema compatibility.\n   */\n  get issues() {\n    return this;\n  }\n  toJSON() {\n    return [...this.map((e) => e.toJSON())];\n  }\n  toString() {\n    return this.join(\"\\n\");\n  }\n  _add(error) {\n    const existing = this.byPath[error.propString];\n    if (existing) {\n      const errorIntersection = new ArkError({\n        code: \"intersection\",\n        errors: existing.hasCode(\"intersection\") ? [...existing.errors, error] : [existing, error]\n      }, this.ctx);\n      const existingIndex = this.indexOf(existing);\n      this.mutable[existingIndex === -1 ? this.length : existingIndex] = errorIntersection;\n      this.byPath[error.propString] = errorIntersection;\n      this.addAncestorPaths(error);\n    } else {\n      this.byPath[error.propString] = error;\n      this.addAncestorPaths(error);\n      this.mutable.push(error);\n    }\n    this.count++;\n  }\n  addAncestorPaths(error) {\n    error.path.stringifyAncestors().forEach((propString) => {\n      this.byAncestorPath[propString] = append(this.byAncestorPath[propString], error);\n    });\n  }\n};\nvar TraversalError = class extends Error {\n  name = \"TraversalError\";\n  constructor(errors) {\n    if (errors.length === 1)\n      super(errors.summary);\n    else\n      super(\"\\n\" + errors.map((error) => `  \\u2022 ${indent(error)}`).join(\"\\n\"));\n    Object.defineProperty(this, \"arkErrors\", {\n      value: errors,\n      enumerable: false\n    });\n  }\n};\nvar indent = (error) => error.toString().split(\"\\n\").join(\"\\n  \");\n\n// ../schema/out/shared/traversal.js\nvar Traversal = class {\n  /**\n   * #### the path being validated or morphed\n   *\n   * ✅ array indices represented as numbers\n   * ⚠️ mutated during traversal - use `path.slice(0)` to snapshot\n   * 🔗 use {@link propString} for a stringified version\n   */\n  path = [];\n  /**\n   * #### {@link ArkErrors} that will be part of this traversal's finalized result\n   *\n   * ✅ will always be an empty array for a valid traversal\n   */\n  errors = new ArkErrors(this);\n  /**\n   * #### the original value being traversed\n   */\n  root;\n  /**\n   * #### configuration for this traversal\n   *\n   * ✅ options can affect traversal results and error messages\n   * ✅ defaults < global config < scope config\n   * ✅ does not include options configured on individual types\n   */\n  config;\n  queuedMorphs = [];\n  branches = [];\n  seen = {};\n  constructor(root, config) {\n    this.root = root;\n    this.config = config;\n  }\n  /**\n   * #### the data being validated or morphed\n   *\n   * ✅ extracted from {@link root} at {@link path}\n   */\n  get data() {\n    let result = this.root;\n    for (const segment of this.path)\n      result = result?.[segment];\n    return result;\n  }\n  /**\n   * #### a string representing {@link path}\n   *\n   * @propString\n   */\n  get propString() {\n    return stringifyPath(this.path);\n  }\n  /**\n   * #### add an {@link ArkError} and return `false`\n   *\n   * ✅ useful for predicates like `.narrow`\n   */\n  reject(input) {\n    this.error(input);\n    return false;\n  }\n  /**\n   * #### add an {@link ArkError} from a description and return `false`\n   *\n   * ✅ useful for predicates like `.narrow`\n   * 🔗 equivalent to {@link reject}({ expected })\n   */\n  mustBe(expected) {\n    this.error(expected);\n    return false;\n  }\n  error(input) {\n    const errCtx = typeof input === \"object\" ? input.code ? input : { ...input, code: \"predicate\" } : { code: \"predicate\", expected: input };\n    return this.errorFromContext(errCtx);\n  }\n  /**\n   * #### whether {@link currentBranch} (or the traversal root, outside a union) has one or more errors\n   */\n  hasError() {\n    return this.currentErrorCount !== 0;\n  }\n  get currentBranch() {\n    return this.branches.at(-1);\n  }\n  queueMorphs(morphs) {\n    const input = {\n      path: new ReadonlyPath(...this.path),\n      morphs\n    };\n    if (this.currentBranch)\n      this.currentBranch.queuedMorphs.push(input);\n    else\n      this.queuedMorphs.push(input);\n  }\n  finalize(onFail) {\n    if (this.queuedMorphs.length) {\n      if (typeof this.root === \"object\" && this.root !== null && this.config.clone)\n        this.root = this.config.clone(this.root);\n      this.applyQueuedMorphs();\n    }\n    if (this.hasError())\n      return onFail ? onFail(this.errors) : this.errors;\n    return this.root;\n  }\n  get currentErrorCount() {\n    return this.currentBranch ? this.currentBranch.error ? 1 : 0 : this.errors.count;\n  }\n  get failFast() {\n    return this.branches.length !== 0;\n  }\n  pushBranch() {\n    this.branches.push({\n      error: void 0,\n      queuedMorphs: []\n    });\n  }\n  popBranch() {\n    return this.branches.pop();\n  }\n  /**\n   * @internal\n   * Convenience for casting from InternalTraversal to Traversal\n   * for cases where the extra methods on the external type are expected, e.g.\n   * a morph or predicate.\n   */\n  get external() {\n    return this;\n  }\n  errorFromNodeContext(input) {\n    return this.errorFromContext(input);\n  }\n  errorFromContext(errCtx) {\n    const error = new ArkError(errCtx, this);\n    if (this.currentBranch)\n      this.currentBranch.error = error;\n    else\n      this.errors.add(error);\n    return error;\n  }\n  applyQueuedMorphs() {\n    while (this.queuedMorphs.length) {\n      const queuedMorphs = this.queuedMorphs;\n      this.queuedMorphs = [];\n      for (const { path, morphs } of queuedMorphs) {\n        if (this.errors.affectsPath(path))\n          continue;\n        this.applyMorphsAtPath(path, morphs);\n      }\n    }\n  }\n  applyMorphsAtPath(path, morphs) {\n    const key = path.at(-1);\n    let parent;\n    if (key !== void 0) {\n      parent = this.root;\n      for (let pathIndex = 0; pathIndex < path.length - 1; pathIndex++)\n        parent = parent[path[pathIndex]];\n    }\n    this.path = [...path];\n    for (const morph of morphs) {\n      const morphIsNode = isNode(morph);\n      const result = morph(parent === void 0 ? this.root : parent[key], this);\n      if (result instanceof ArkError) {\n        this.errors.add(result);\n        break;\n      }\n      if (result instanceof ArkErrors) {\n        if (!morphIsNode) {\n          this.errors.merge(result);\n        }\n        break;\n      }\n      if (parent === void 0)\n        this.root = result;\n      else\n        parent[key] = result;\n      this.applyQueuedMorphs();\n    }\n  }\n};\nvar traverseKey = (key, fn, ctx) => {\n  if (!ctx)\n    return fn();\n  ctx.path.push(key);\n  const result = fn();\n  ctx.path.pop();\n  return result;\n};\n\n// ../schema/out/node.js\nvar BaseNode = class extends Callable {\n  attachments;\n  $;\n  onFail;\n  includesTransform;\n  // if a predicate accepts exactly one arg, we can safely skip passing context\n  // technically, a predicate could be written like `(data, ...[ctx]) => ctx.mustBe(\"malicious\")`\n  // that would break here, but it feels like a pathological case and is better to let people optimize\n  includesContextualPredicate;\n  isCyclic;\n  allowsRequiresContext;\n  rootApplyStrategy;\n  contextFreeMorph;\n  rootApply;\n  referencesById;\n  shallowReferences;\n  flatRefs;\n  flatMorphs;\n  allows;\n  get shallowMorphs() {\n    return [];\n  }\n  constructor(attachments, $) {\n    super((data, pipedFromCtx, onFail = this.onFail) => {\n      if (pipedFromCtx) {\n        this.traverseApply(data, pipedFromCtx);\n        return pipedFromCtx.hasError() ? pipedFromCtx.errors : pipedFromCtx.data;\n      }\n      return this.rootApply(data, onFail);\n    }, { attach: attachments });\n    this.attachments = attachments;\n    this.$ = $;\n    this.onFail = this.meta.onFail ?? this.$.resolvedConfig.onFail;\n    this.includesTransform = this.hasKind(\"morph\") || this.hasKind(\"structure\") && this.structuralMorph !== void 0;\n    this.includesContextualPredicate = this.hasKind(\"predicate\") && this.inner.predicate.length !== 1;\n    this.isCyclic = this.kind === \"alias\";\n    this.referencesById = { [this.id]: this };\n    this.shallowReferences = this.hasKind(\"structure\") ? [this, ...this.children] : this.children.reduce((acc, child) => appendUniqueNodes(acc, child.shallowReferences), [this]);\n    const isStructural = this.isStructural();\n    this.flatRefs = [];\n    this.flatMorphs = [];\n    for (let i = 0; i < this.children.length; i++) {\n      this.includesTransform ||= this.children[i].includesTransform;\n      this.includesContextualPredicate ||= this.children[i].includesContextualPredicate;\n      this.isCyclic ||= this.children[i].isCyclic;\n      if (!isStructural) {\n        const childFlatRefs = this.children[i].flatRefs;\n        for (let j = 0; j < childFlatRefs.length; j++) {\n          const childRef = childFlatRefs[j];\n          if (!this.flatRefs.some((existing) => flatRefsAreEqual(existing, childRef))) {\n            this.flatRefs.push(childRef);\n            for (const branch of childRef.node.branches) {\n              if (branch.hasKind(\"morph\") || branch.hasKind(\"intersection\") && branch.structure?.structuralMorph !== void 0) {\n                this.flatMorphs.push({\n                  path: childRef.path,\n                  propString: childRef.propString,\n                  node: branch\n                });\n              }\n            }\n          }\n        }\n      }\n      Object.assign(this.referencesById, this.children[i].referencesById);\n    }\n    this.flatRefs.sort((l, r) => l.path.length > r.path.length ? 1 : l.path.length < r.path.length ? -1 : l.propString > r.propString ? 1 : l.propString < r.propString ? -1 : l.node.expression < r.node.expression ? -1 : 1);\n    this.allowsRequiresContext = this.includesContextualPredicate || this.isCyclic;\n    this.rootApplyStrategy = !this.allowsRequiresContext && this.flatMorphs.length === 0 ? this.shallowMorphs.length === 0 ? \"allows\" : this.shallowMorphs.every((morph) => morph.length === 1 || morph.name === \"$arkStructuralMorph\") ? this.hasKind(\"union\") ? (\n      // multiple morphs not yet supported for optimistic compilation\n      this.branches.some((branch) => branch.shallowMorphs.length > 1) ? \"contextual\" : \"branchedOptimistic\"\n    ) : this.shallowMorphs.length > 1 ? \"contextual\" : \"optimistic\" : \"contextual\" : \"contextual\";\n    this.rootApply = this.createRootApply();\n    this.allows = this.allowsRequiresContext ? (data) => this.traverseAllows(data, new Traversal(data, this.$.resolvedConfig)) : (data) => this.traverseAllows(data);\n  }\n  createRootApply() {\n    switch (this.rootApplyStrategy) {\n      case \"allows\":\n        return (data, onFail) => {\n          if (this.allows(data))\n            return data;\n          const ctx = new Traversal(data, this.$.resolvedConfig);\n          this.traverseApply(data, ctx);\n          return ctx.finalize(onFail);\n        };\n      case \"contextual\":\n        return (data, onFail) => {\n          const ctx = new Traversal(data, this.$.resolvedConfig);\n          this.traverseApply(data, ctx);\n          return ctx.finalize(onFail);\n        };\n      case \"optimistic\":\n        this.contextFreeMorph = this.shallowMorphs[0];\n        const clone = this.$.resolvedConfig.clone;\n        return (data, onFail) => {\n          if (this.allows(data)) {\n            return this.contextFreeMorph(clone && (typeof data === \"object\" && data !== null || typeof data === \"function\") ? clone(data) : data);\n          }\n          const ctx = new Traversal(data, this.$.resolvedConfig);\n          this.traverseApply(data, ctx);\n          return ctx.finalize(onFail);\n        };\n      case \"branchedOptimistic\":\n        return this.createBranchedOptimisticRootApply();\n      default:\n        this.rootApplyStrategy;\n        return throwInternalError(`Unexpected rootApplyStrategy ${this.rootApplyStrategy}`);\n    }\n  }\n  compiledMeta = compileMeta(this.metaJson);\n  cacheGetter(name, value2) {\n    Object.defineProperty(this, name, { value: value2 });\n    return value2;\n  }\n  get description() {\n    return this.cacheGetter(\"description\", this.meta?.description ?? this.$.resolvedConfig[this.kind].description(this));\n  }\n  // we don't cache this currently since it can be updated once a scope finishes\n  // resolving cyclic references, although it may be possible to ensure it is cached safely\n  get references() {\n    return Object.values(this.referencesById);\n  }\n  precedence = precedenceOfKind(this.kind);\n  precompilation;\n  // defined as an arrow function since it is often detached, e.g. when passing to tRPC\n  // otherwise, would run into issues with this binding\n  assert = (data, pipedFromCtx) => this(data, pipedFromCtx, (errors) => errors.throw());\n  traverse(data, pipedFromCtx) {\n    return this(data, pipedFromCtx, null);\n  }\n  get in() {\n    return this.cacheGetter(\"in\", this.getIo(\"in\"));\n  }\n  get out() {\n    return this.cacheGetter(\"out\", this.getIo(\"out\"));\n  }\n  // Should be refactored to use transform\n  // https://github.com/arktypeio/arktype/issues/1020\n  getIo(ioKind) {\n    if (!this.includesTransform)\n      return this;\n    const ioInner = {};\n    for (const [k, v] of this.innerEntries) {\n      const keySchemaImplementation = this.impl.keys[k];\n      if (keySchemaImplementation.reduceIo)\n        keySchemaImplementation.reduceIo(ioKind, ioInner, v);\n      else if (keySchemaImplementation.child) {\n        const childValue = v;\n        ioInner[k] = isArray(childValue) ? childValue.map((child) => child[ioKind]) : childValue[ioKind];\n      } else\n        ioInner[k] = v;\n    }\n    return this.$.node(this.kind, ioInner);\n  }\n  toJSON() {\n    return this.json;\n  }\n  toString() {\n    return `Type<${this.expression}>`;\n  }\n  equals(r) {\n    const rNode = isNode(r) ? r : this.$.parseDefinition(r);\n    return this.innerHash === rNode.innerHash;\n  }\n  ifEquals(r) {\n    return this.equals(r) ? this : void 0;\n  }\n  hasKind(kind) {\n    return this.kind === kind;\n  }\n  assertHasKind(kind) {\n    if (this.kind !== kind)\n      throwError(`${this.kind} node was not of asserted kind ${kind}`);\n    return this;\n  }\n  hasKindIn(...kinds) {\n    return kinds.includes(this.kind);\n  }\n  assertHasKindIn(...kinds) {\n    if (!includes(kinds, this.kind))\n      throwError(`${this.kind} node was not one of asserted kinds ${kinds}`);\n    return this;\n  }\n  isBasis() {\n    return includes(basisKinds, this.kind);\n  }\n  isConstraint() {\n    return includes(constraintKinds, this.kind);\n  }\n  isStructural() {\n    return includes(structuralKinds, this.kind);\n  }\n  isRefinement() {\n    return includes(refinementKinds, this.kind);\n  }\n  isRoot() {\n    return includes(rootKinds, this.kind);\n  }\n  isUnknown() {\n    return this.hasKind(\"intersection\") && this.children.length === 0;\n  }\n  isNever() {\n    return this.hasKind(\"union\") && this.children.length === 0;\n  }\n  hasUnit(value2) {\n    return this.hasKind(\"unit\") && this.allows(value2);\n  }\n  hasOpenIntersection() {\n    return this.impl.intersectionIsOpen;\n  }\n  get nestableExpression() {\n    return this.expression;\n  }\n  select(selector) {\n    const normalized = NodeSelector.normalize(selector);\n    return this._select(normalized);\n  }\n  _select(selector) {\n    let nodes = NodeSelector.applyBoundary[selector.boundary ?? \"references\"](this);\n    if (selector.kind)\n      nodes = nodes.filter((n) => n.kind === selector.kind);\n    if (selector.where)\n      nodes = nodes.filter(selector.where);\n    return NodeSelector.applyMethod[selector.method ?? \"filter\"](nodes, this, selector);\n  }\n  transform(mapper, opts) {\n    return this._transform(mapper, this._createTransformContext(opts));\n  }\n  _createTransformContext(opts) {\n    return {\n      root: this,\n      selected: void 0,\n      seen: {},\n      path: [],\n      parseOptions: {\n        prereduced: opts?.prereduced ?? false\n      },\n      undeclaredKeyHandling: void 0,\n      ...opts\n    };\n  }\n  _transform(mapper, ctx) {\n    const $ = ctx.bindScope ?? this.$;\n    if (ctx.seen[this.id])\n      return this.$.lazilyResolve(ctx.seen[this.id]);\n    if (ctx.shouldTransform?.(this, ctx) === false)\n      return this;\n    let transformedNode;\n    ctx.seen[this.id] = () => transformedNode;\n    if (this.hasKind(\"structure\") && this.undeclared !== ctx.undeclaredKeyHandling) {\n      ctx = {\n        ...ctx,\n        undeclaredKeyHandling: this.undeclared\n      };\n    }\n    const innerWithTransformedChildren = flatMorph(this.inner, (k, v) => {\n      if (!this.impl.keys[k].child)\n        return [k, v];\n      const children = v;\n      if (!isArray(children)) {\n        const transformed2 = children._transform(mapper, ctx);\n        return transformed2 ? [k, transformed2] : [];\n      }\n      if (children.length === 0)\n        return [k, v];\n      const transformed = children.flatMap((n) => {\n        const transformedChild = n._transform(mapper, ctx);\n        return transformedChild ?? [];\n      });\n      return transformed.length ? [k, transformed] : [];\n    });\n    delete ctx.seen[this.id];\n    const innerWithMeta = Object.assign(innerWithTransformedChildren, {\n      meta: this.meta\n    });\n    const transformedInner = ctx.selected && !ctx.selected.includes(this) ? innerWithMeta : mapper(this.kind, innerWithMeta, ctx);\n    if (transformedInner === null)\n      return null;\n    if (isNode(transformedInner))\n      return transformedNode = transformedInner;\n    const transformedKeys = Object.keys(transformedInner);\n    const hasNoTypedKeys = transformedKeys.length === 0 || transformedKeys.length === 1 && transformedKeys[0] === \"meta\";\n    if (hasNoTypedKeys && // if inner was previously an empty object (e.g. unknown) ensure it is not pruned\n    !isEmptyObject(this.inner))\n      return null;\n    if ((this.kind === \"required\" || this.kind === \"optional\" || this.kind === \"index\") && !(\"value\" in transformedInner)) {\n      return ctx.undeclaredKeyHandling ? { ...transformedInner, value: $ark.intrinsic.unknown } : null;\n    }\n    if (this.kind === \"morph\") {\n      ;\n      transformedInner.in ??= $ark.intrinsic.unknown;\n    }\n    return transformedNode = $.node(this.kind, transformedInner, ctx.parseOptions);\n  }\n  configureReferences(meta, selector = \"references\") {\n    const normalized = NodeSelector.normalize(selector);\n    const mapper = typeof meta === \"string\" ? (kind, inner) => ({\n      ...inner,\n      meta: { ...inner.meta, description: meta }\n    }) : typeof meta === \"function\" ? (kind, inner) => ({ ...inner, meta: meta(inner.meta) }) : (kind, inner) => ({\n      ...inner,\n      meta: { ...inner.meta, ...meta }\n    });\n    if (normalized.boundary === \"self\") {\n      return this.$.node(this.kind, mapper(this.kind, { ...this.inner, meta: this.meta }));\n    }\n    const rawSelected = this._select(normalized);\n    const selected = rawSelected && liftArray(rawSelected);\n    const shouldTransform = normalized.boundary === \"child\" ? (node2, ctx) => ctx.root.children.includes(node2) : normalized.boundary === \"shallow\" ? (node2) => node2.kind !== \"structure\" : () => true;\n    return this.$.finalize(this.transform(mapper, {\n      shouldTransform,\n      selected\n    }));\n  }\n};\nvar NodeSelector = {\n  applyBoundary: {\n    self: (node2) => [node2],\n    child: (node2) => [...node2.children],\n    shallow: (node2) => [...node2.shallowReferences],\n    references: (node2) => [...node2.references]\n  },\n  applyMethod: {\n    filter: (nodes) => nodes,\n    assertFilter: (nodes, from, selector) => {\n      if (nodes.length === 0)\n        throwError(writeSelectAssertionMessage(from, selector));\n      return nodes;\n    },\n    find: (nodes) => nodes[0],\n    assertFind: (nodes, from, selector) => {\n      if (nodes.length === 0)\n        throwError(writeSelectAssertionMessage(from, selector));\n      return nodes[0];\n    }\n  },\n  normalize: (selector) => typeof selector === \"function\" ? { boundary: \"references\", method: \"filter\", where: selector } : typeof selector === \"string\" ? isKeyOf(selector, NodeSelector.applyBoundary) ? { method: \"filter\", boundary: selector } : { boundary: \"references\", method: \"filter\", kind: selector } : { boundary: \"references\", method: \"filter\", ...selector }\n};\nvar writeSelectAssertionMessage = (from, selector) => `${from} had no references matching ${printable(selector)}.`;\nvar typePathToPropString = (path) => stringifyPath(path, {\n  stringifyNonKey: (node2) => node2.expression\n});\nvar referenceMatcher = /\"(\\$ark\\.[^\"]+)\"/g;\nvar compileMeta = (metaJson) => JSON.stringify(metaJson).replaceAll(referenceMatcher, \"$1\");\nvar flatRef = (path, node2) => ({\n  path,\n  node: node2,\n  propString: typePathToPropString(path)\n});\nvar flatRefsAreEqual = (l, r) => l.propString === r.propString && l.node.equals(r.node);\nvar appendUniqueFlatRefs = (existing, refs) => appendUnique(existing, refs, {\n  isEqual: flatRefsAreEqual\n});\nvar appendUniqueNodes = (existing, refs) => appendUnique(existing, refs, {\n  isEqual: (l, r) => l.equals(r)\n});\n\n// ../schema/out/shared/disjoint.js\nvar Disjoint = class _Disjoint extends Array {\n  static init(kind, l, r, ctx) {\n    return new _Disjoint({\n      kind,\n      l,\n      r,\n      path: ctx?.path ?? [],\n      optional: ctx?.optional ?? false\n    });\n  }\n  add(kind, l, r, ctx) {\n    this.push({\n      kind,\n      l,\n      r,\n      path: ctx?.path ?? [],\n      optional: ctx?.optional ?? false\n    });\n    return this;\n  }\n  get summary() {\n    return this.describeReasons();\n  }\n  describeReasons() {\n    if (this.length === 1) {\n      const { path, l, r } = this[0];\n      const pathString = stringifyPath(path);\n      return writeUnsatisfiableExpressionError(`Intersection${pathString && ` at ${pathString}`} of ${describeReasons(l, r)}`);\n    }\n    return `The following intersections result in unsatisfiable types:\n\\u2022 ${this.map(({ path, l, r }) => `${path}: ${describeReasons(l, r)}`).join(\"\\n\\u2022 \")}`;\n  }\n  throw() {\n    return throwParseError(this.describeReasons());\n  }\n  invert() {\n    const result = this.map((entry) => ({\n      ...entry,\n      l: entry.r,\n      r: entry.l\n    }));\n    if (!(result instanceof _Disjoint))\n      return new _Disjoint(...result);\n    return result;\n  }\n  withPrefixKey(key, kind) {\n    return this.map((entry) => ({\n      ...entry,\n      path: [key, ...entry.path],\n      optional: entry.optional || kind === \"optional\"\n    }));\n  }\n  toNeverIfDisjoint() {\n    return $ark.intrinsic.never;\n  }\n};\nvar describeReasons = (l, r) => `${describeReason(l)} and ${describeReason(r)}`;\nvar describeReason = (value2) => isNode(value2) ? value2.expression : isArray(value2) ? value2.map(describeReason).join(\" | \") || \"never\" : String(value2);\nvar writeUnsatisfiableExpressionError = (expression) => `${expression} results in an unsatisfiable type`;\n\n// ../schema/out/shared/intersections.js\nvar intersectionCache = {};\nvar intersectNodesRoot = (l, r, $) => intersectOrPipeNodes(l, r, {\n  $,\n  invert: false,\n  pipe: false\n});\nvar pipeNodesRoot = (l, r, $) => intersectOrPipeNodes(l, r, {\n  $,\n  invert: false,\n  pipe: true\n});\nvar intersectOrPipeNodes = (l, r, ctx) => {\n  const operator = ctx.pipe ? \"|>\" : \"&\";\n  const lrCacheKey = `${l.hash}${operator}${r.hash}`;\n  if (intersectionCache[lrCacheKey] !== void 0)\n    return intersectionCache[lrCacheKey];\n  if (!ctx.pipe) {\n    const rlCacheKey = `${r.hash}${operator}${l.hash}`;\n    if (intersectionCache[rlCacheKey] !== void 0) {\n      const rlResult = intersectionCache[rlCacheKey];\n      const lrResult = rlResult instanceof Disjoint ? rlResult.invert() : rlResult;\n      intersectionCache[lrCacheKey] = lrResult;\n      return lrResult;\n    }\n  }\n  const isPureIntersection = !ctx.pipe || !l.includesTransform && !r.includesTransform;\n  if (isPureIntersection && l.equals(r))\n    return l;\n  let result = isPureIntersection ? _intersectNodes(l, r, ctx) : l.hasKindIn(...rootKinds) ? (\n    // if l is a RootNode, r will be as well\n    _pipeNodes(l, r, ctx)\n  ) : _intersectNodes(l, r, ctx);\n  if (isNode(result)) {\n    if (l.equals(result))\n      result = l;\n    else if (r.equals(result))\n      result = r;\n  }\n  intersectionCache[lrCacheKey] = result;\n  return result;\n};\nvar _intersectNodes = (l, r, ctx) => {\n  const leftmostKind = l.precedence < r.precedence ? l.kind : r.kind;\n  const implementation23 = l.impl.intersections[r.kind] ?? r.impl.intersections[l.kind];\n  if (implementation23 === void 0) {\n    return null;\n  } else if (leftmostKind === l.kind)\n    return implementation23(l, r, ctx);\n  else {\n    let result = implementation23(r, l, { ...ctx, invert: !ctx.invert });\n    if (result instanceof Disjoint)\n      result = result.invert();\n    return result;\n  }\n};\nvar _pipeNodes = (l, r, ctx) => l.includesTransform || r.includesTransform ? ctx.invert ? pipeMorphed(r, l, ctx) : pipeMorphed(l, r, ctx) : _intersectNodes(l, r, ctx);\nvar pipeMorphed = (from, to, ctx) => from.distribute((fromBranch) => _pipeMorphed(fromBranch, to, ctx), (results) => {\n  const viableBranches = results.filter(isNode);\n  if (viableBranches.length === 0)\n    return Disjoint.init(\"union\", from.branches, to.branches);\n  if (viableBranches.length < from.branches.length || !from.branches.every((branch, i) => branch.in.equals(viableBranches[i].in)))\n    return ctx.$.parseSchema(viableBranches);\n  let meta;\n  if (viableBranches.length === 1) {\n    const onlyBranch = viableBranches[0];\n    if (!meta)\n      return onlyBranch;\n    return ctx.$.node(\"morph\", {\n      ...onlyBranch.inner,\n      in: onlyBranch.in.configure(meta, \"self\")\n    });\n  }\n  const schema2 = {\n    branches: viableBranches\n  };\n  if (meta)\n    schema2.meta = meta;\n  return ctx.$.parseSchema(schema2);\n});\nvar _pipeMorphed = (from, to, ctx) => {\n  const fromIsMorph = from.hasKind(\"morph\");\n  if (fromIsMorph) {\n    const morphs = [...from.morphs];\n    if (from.lastMorphIfNode) {\n      const outIntersection = intersectOrPipeNodes(from.lastMorphIfNode, to, ctx);\n      if (outIntersection instanceof Disjoint)\n        return outIntersection;\n      morphs[morphs.length - 1] = outIntersection;\n    } else\n      morphs.push(to);\n    return ctx.$.node(\"morph\", {\n      morphs,\n      in: from.inner.in\n    });\n  }\n  if (to.hasKind(\"morph\")) {\n    const inTersection = intersectOrPipeNodes(from, to.in, ctx);\n    if (inTersection instanceof Disjoint)\n      return inTersection;\n    return ctx.$.node(\"morph\", {\n      morphs: [to],\n      in: inTersection\n    });\n  }\n  return ctx.$.node(\"morph\", {\n    morphs: [to],\n    in: from\n  });\n};\n\n// ../schema/out/constraint.js\nvar BaseConstraint = class extends BaseNode {\n  constructor(attachments, $) {\n    super(attachments, $);\n    Object.defineProperty(this, arkKind, {\n      value: \"constraint\",\n      enumerable: false\n    });\n  }\n  impliedSiblings;\n  intersect(r) {\n    return intersectNodesRoot(this, r, this.$);\n  }\n};\nvar InternalPrimitiveConstraint = class extends BaseConstraint {\n  traverseApply = (data, ctx) => {\n    if (!this.traverseAllows(data, ctx))\n      ctx.errorFromNodeContext(this.errorContext);\n  };\n  compile(js) {\n    if (js.traversalKind === \"Allows\")\n      js.return(this.compiledCondition);\n    else {\n      js.if(this.compiledNegation, () => js.line(`${js.ctx}.errorFromNodeContext(${this.compiledErrorContext})`));\n    }\n  }\n  get errorContext() {\n    return {\n      code: this.kind,\n      description: this.description,\n      meta: this.meta,\n      ...this.inner\n    };\n  }\n  get compiledErrorContext() {\n    return compileObjectLiteral(this.errorContext);\n  }\n};\nvar constraintKeyParser = (kind) => (schema2, ctx) => {\n  if (isArray(schema2)) {\n    if (schema2.length === 0) {\n      return;\n    }\n    const nodes = schema2.map((schema3) => ctx.$.node(kind, schema3));\n    if (kind === \"predicate\")\n      return nodes;\n    return nodes.sort((l, r) => l.hash < r.hash ? -1 : 1);\n  }\n  const child = ctx.$.node(kind, schema2);\n  return child.hasOpenIntersection() ? [child] : child;\n};\nvar intersectConstraints = (s) => {\n  const head = s.r.shift();\n  if (!head) {\n    let result = s.l.length === 0 && s.kind === \"structure\" ? $ark.intrinsic.unknown.internal : s.ctx.$.node(s.kind, Object.assign(s.baseInner, unflattenConstraints(s.l)), { prereduced: true });\n    for (const root of s.roots) {\n      if (result instanceof Disjoint)\n        return result;\n      result = intersectOrPipeNodes(root, result, s.ctx);\n    }\n    return result;\n  }\n  let matched = false;\n  for (let i = 0; i < s.l.length; i++) {\n    const result = intersectOrPipeNodes(s.l[i], head, s.ctx);\n    if (result === null)\n      continue;\n    if (result instanceof Disjoint)\n      return result;\n    if (!matched) {\n      if (result.isRoot()) {\n        s.roots.push(result);\n        s.l.splice(i);\n        return intersectConstraints(s);\n      }\n      s.l[i] = result;\n      matched = true;\n    } else if (!s.l.includes(result)) {\n      return throwInternalError(`Unexpectedly encountered multiple distinct intersection results for refinement ${result}`);\n    }\n  }\n  if (!matched)\n    s.l.push(head);\n  if (s.kind === \"intersection\")\n    head.impliedSiblings?.forEach((node2) => appendUnique(s.r, node2));\n  return intersectConstraints(s);\n};\nvar flattenConstraints = (inner) => {\n  const result = Object.entries(inner).flatMap(([k, v]) => k in constraintKeys ? v : []).sort((l, r) => l.precedence < r.precedence ? -1 : l.precedence > r.precedence ? 1 : l.kind === \"predicate\" && r.kind === \"predicate\" ? 0 : l.hash < r.hash ? -1 : 1);\n  return result;\n};\nvar unflattenConstraints = (constraints) => {\n  const inner = {};\n  for (const constraint of constraints) {\n    if (constraint.hasOpenIntersection()) {\n      inner[constraint.kind] = append(inner[constraint.kind], constraint);\n    } else {\n      if (inner[constraint.kind]) {\n        return throwInternalError(`Unexpected intersection of closed refinements of kind ${constraint.kind}`);\n      }\n      inner[constraint.kind] = constraint;\n    }\n  }\n  return inner;\n};\nvar throwInvalidOperandError = (...args2) => throwParseError(writeInvalidOperandMessage(...args2));\nvar writeInvalidOperandMessage = (kind, expected, actual) => {\n  const actualDescription = actual.hasKind(\"morph\") ? \"a morph\" : actual.isUnknown() ? \"unknown\" : actual.exclude(expected).defaultShortDescription;\n  return `${capitalize(kind)} operand must be ${expected.description} (was ${actualDescription})`;\n};\n\n// ../schema/out/generic.js\nvar parseGeneric = (paramDefs, bodyDef, $) => new GenericRoot(paramDefs, bodyDef, $, $, null);\nvar LazyGenericBody = class extends Callable {\n};\nvar GenericRoot = class extends Callable {\n  [arkKind] = \"generic\";\n  paramDefs;\n  bodyDef;\n  $;\n  arg$;\n  baseInstantiation;\n  hkt;\n  description;\n  constructor(paramDefs, bodyDef, $, arg$, hkt) {\n    super((...args2) => {\n      const argNodes = flatMorph(this.names, (i, name) => {\n        const arg = this.arg$.parse(args2[i]);\n        if (!arg.extends(this.constraints[i])) {\n          throwParseError(writeUnsatisfiedParameterConstraintMessage(name, this.constraints[i].expression, arg.expression));\n        }\n        return [name, arg];\n      });\n      if (this.defIsLazy()) {\n        const def = this.bodyDef(argNodes);\n        return this.$.parse(def);\n      }\n      return this.$.parse(bodyDef, { args: argNodes });\n    });\n    this.paramDefs = paramDefs;\n    this.bodyDef = bodyDef;\n    this.$ = $;\n    this.arg$ = arg$;\n    this.hkt = hkt;\n    this.description = hkt ? new hkt().description ?? `a generic type for ${hkt.constructor.name}` : \"a generic type\";\n    this.baseInstantiation = this(...this.constraints);\n  }\n  defIsLazy() {\n    return this.bodyDef instanceof LazyGenericBody;\n  }\n  cacheGetter(name, value2) {\n    Object.defineProperty(this, name, { value: value2 });\n    return value2;\n  }\n  get json() {\n    return this.cacheGetter(\"json\", {\n      params: this.params.map((param) => param[1].isUnknown() ? param[0] : [param[0], param[1].json]),\n      body: snapshot(this.bodyDef)\n    });\n  }\n  get params() {\n    return this.cacheGetter(\"params\", this.paramDefs.map((param) => typeof param === \"string\" ? [param, $ark.intrinsic.unknown] : [param[0], this.$.parse(param[1])]));\n  }\n  get names() {\n    return this.cacheGetter(\"names\", this.params.map((e) => e[0]));\n  }\n  get constraints() {\n    return this.cacheGetter(\"constraints\", this.params.map((e) => e[1]));\n  }\n  get internal() {\n    return this;\n  }\n  get referencesById() {\n    return this.baseInstantiation.internal.referencesById;\n  }\n  get references() {\n    return this.baseInstantiation.internal.references;\n  }\n};\nvar writeUnsatisfiedParameterConstraintMessage = (name, constraint, arg) => `${name} must be assignable to ${constraint} (was ${arg})`;\n\n// ../schema/out/shared/jsonSchema.js\nvar unjsonifiableExplanations = {\n  morph: \"it represents a transformation, while JSON Schema only allows validation. Consider creating a Schema from one of its endpoints using `.in` or `.out`.\",\n  cyclic: \"cyclic types are not yet convertible to JSON Schema. If this feature is important to you, please add your feedback at https://github.com/arktypeio/arktype/issues/1087\"\n};\nvar writeUnjsonifiableMessage = (description, explanation) => {\n  let message = `${description} is not convertible to JSON Schema`;\n  if (explanation) {\n    const normalizedExplanation = isKeyOf(explanation, unjsonifiableExplanations) ? unjsonifiableExplanations[explanation] : explanation;\n    message += ` because ${normalizedExplanation}`;\n  }\n  return message;\n};\nvar JsonSchema = {\n  writeUnjsonifiableMessage,\n  UnjsonifiableError: class UnjsonifiableError extends Error {\n  },\n  throwUnjsonifiableError: (...args2) => throwError(writeUnjsonifiableMessage(...args2)),\n  throwInternalOperandError: (kind, schema2) => throwInternalError(`Unexpected JSON Schema input for ${kind}: ${printable(schema2)}`)\n};\n\n// ../schema/out/predicate.js\nvar implementation = implementNode({\n  kind: \"predicate\",\n  hasAssociatedError: true,\n  collapsibleKey: \"predicate\",\n  keys: {\n    predicate: {}\n  },\n  normalize: (schema2) => typeof schema2 === \"function\" ? { predicate: schema2 } : schema2,\n  defaults: {\n    description: (node2) => `valid according to ${node2.predicate.name || \"an anonymous predicate\"}`\n  },\n  intersectionIsOpen: true,\n  intersections: {\n    // as long as the narrows in l and r are individually safe to check\n    // in the order they're specified, checking them in the order\n    // resulting from this intersection should also be safe.\n    predicate: () => null\n  }\n});\nvar PredicateNode = class extends BaseConstraint {\n  serializedPredicate = registeredReference(this.predicate);\n  compiledCondition = `${this.serializedPredicate}(data, ctx)`;\n  compiledNegation = `!${this.compiledCondition}`;\n  impliedBasis = null;\n  expression = this.serializedPredicate;\n  traverseAllows = this.predicate;\n  errorContext = {\n    code: \"predicate\",\n    description: this.description,\n    meta: this.meta\n  };\n  compiledErrorContext = compileObjectLiteral(this.errorContext);\n  traverseApply = (data, ctx) => {\n    if (!this.predicate(data, ctx.external) && !ctx.hasError())\n      ctx.errorFromNodeContext(this.errorContext);\n  };\n  compile(js) {\n    if (js.traversalKind === \"Allows\") {\n      js.return(this.compiledCondition);\n      return;\n    }\n    js.if(`${this.compiledNegation} && !ctx.hasError()`, () => js.line(`ctx.errorFromNodeContext(${this.compiledErrorContext})`));\n  }\n  reduceJsonSchema() {\n    return JsonSchema.throwUnjsonifiableError(`Predicate ${this.expression}`);\n  }\n};\nvar Predicate = {\n  implementation,\n  Node: PredicateNode\n};\n\n// ../schema/out/refinements/divisor.js\nvar implementation2 = implementNode({\n  kind: \"divisor\",\n  collapsibleKey: \"rule\",\n  keys: {\n    rule: {}\n  },\n  normalize: (schema2) => typeof schema2 === \"number\" ? { rule: schema2 } : schema2,\n  hasAssociatedError: true,\n  defaults: {\n    description: (node2) => node2.rule === 1 ? \"an integer\" : node2.rule === 2 ? \"even\" : `a multiple of ${node2.rule}`\n  },\n  intersections: {\n    divisor: (l, r, ctx) => ctx.$.node(\"divisor\", {\n      rule: Math.abs(l.rule * r.rule / greatestCommonDivisor(l.rule, r.rule))\n    })\n  },\n  obviatesBasisDescription: true\n});\nvar DivisorNode = class extends InternalPrimitiveConstraint {\n  traverseAllows = (data) => data % this.rule === 0;\n  compiledCondition = `data % ${this.rule} === 0`;\n  compiledNegation = `data % ${this.rule} !== 0`;\n  impliedBasis = $ark.intrinsic.number.internal;\n  expression = `% ${this.rule}`;\n  reduceJsonSchema(schema2) {\n    schema2.type = \"integer\";\n    if (this.rule === 1)\n      return schema2;\n    schema2.multipleOf = this.rule;\n    return schema2;\n  }\n};\nvar Divisor = {\n  implementation: implementation2,\n  Node: DivisorNode\n};\nvar greatestCommonDivisor = (l, r) => {\n  let previous;\n  let greatestCommonDivisor2 = l;\n  let current = r;\n  while (current !== 0) {\n    previous = current;\n    current = greatestCommonDivisor2 % current;\n    greatestCommonDivisor2 = previous;\n  }\n  return greatestCommonDivisor2;\n};\n\n// ../schema/out/refinements/range.js\nvar BaseRange = class extends InternalPrimitiveConstraint {\n  boundOperandKind = operandKindsByBoundKind[this.kind];\n  compiledActual = this.boundOperandKind === \"value\" ? `data` : this.boundOperandKind === \"length\" ? `data.length` : `data.valueOf()`;\n  comparator = compileComparator(this.kind, this.exclusive);\n  numericLimit = this.rule.valueOf();\n  expression = `${this.comparator} ${this.rule}`;\n  compiledCondition = `${this.compiledActual} ${this.comparator} ${this.numericLimit}`;\n  compiledNegation = `${this.compiledActual} ${negatedComparators[this.comparator]} ${this.numericLimit}`;\n  // we need to compute stringLimit before errorContext, which references it\n  // transitively through description for date bounds\n  stringLimit = this.boundOperandKind === \"date\" ? dateLimitToString(this.numericLimit) : `${this.numericLimit}`;\n  limitKind = this.comparator[\"0\"] === \"<\" ? \"upper\" : \"lower\";\n  isStricterThan(r) {\n    const thisLimitIsStricter = this.limitKind === \"upper\" ? this.numericLimit < r.numericLimit : this.numericLimit > r.numericLimit;\n    return thisLimitIsStricter || this.numericLimit === r.numericLimit && this.exclusive === true && !r.exclusive;\n  }\n  overlapsRange(r) {\n    if (this.isStricterThan(r))\n      return false;\n    if (this.numericLimit === r.numericLimit && (this.exclusive || r.exclusive))\n      return false;\n    return true;\n  }\n  overlapIsUnit(r) {\n    return this.numericLimit === r.numericLimit && !this.exclusive && !r.exclusive;\n  }\n};\nvar negatedComparators = {\n  \"<\": \">=\",\n  \"<=\": \">\",\n  \">\": \"<=\",\n  \">=\": \"<\"\n};\nvar boundKindPairsByLower = {\n  min: \"max\",\n  minLength: \"maxLength\",\n  after: \"before\"\n};\nvar parseExclusiveKey = {\n  // omit key with value false since it is the default\n  parse: (flag) => flag || void 0\n};\nvar createLengthSchemaNormalizer = (kind) => (schema2) => {\n  if (typeof schema2 === \"number\")\n    return { rule: schema2 };\n  const { exclusive, ...normalized } = schema2;\n  return exclusive ? {\n    ...normalized,\n    rule: kind === \"minLength\" ? normalized.rule + 1 : normalized.rule - 1\n  } : normalized;\n};\nvar createDateSchemaNormalizer = (kind) => (schema2) => {\n  if (typeof schema2 === \"number\" || typeof schema2 === \"string\" || schema2 instanceof Date)\n    return { rule: schema2 };\n  const { exclusive, ...normalized } = schema2;\n  if (!exclusive)\n    return normalized;\n  const numericLimit = typeof normalized.rule === \"number\" ? normalized.rule : typeof normalized.rule === \"string\" ? new Date(normalized.rule).valueOf() : normalized.rule.valueOf();\n  return exclusive ? {\n    ...normalized,\n    rule: kind === \"after\" ? numericLimit + 1 : numericLimit - 1\n  } : normalized;\n};\nvar parseDateLimit = (limit) => typeof limit === \"string\" || typeof limit === \"number\" ? new Date(limit) : limit;\nvar writeInvalidLengthBoundMessage = (kind, limit) => `${kind} bound must be a positive integer (was ${limit})`;\nvar createLengthRuleParser = (kind) => (limit) => {\n  if (!Number.isInteger(limit) || limit < 0)\n    throwParseError(writeInvalidLengthBoundMessage(kind, limit));\n  return limit;\n};\nvar operandKindsByBoundKind = {\n  min: \"value\",\n  max: \"value\",\n  minLength: \"length\",\n  maxLength: \"length\",\n  after: \"date\",\n  before: \"date\"\n};\nvar compileComparator = (kind, exclusive) => `${isKeyOf(kind, boundKindPairsByLower) ? \">\" : \"<\"}${exclusive ? \"\" : \"=\"}`;\nvar dateLimitToString = (limit) => typeof limit === \"string\" ? limit : new Date(limit).toLocaleString();\nvar writeUnboundableMessage = (root) => `Bounded expression ${root} must be exactly one of number, string, Array, or Date`;\n\n// ../schema/out/refinements/after.js\nvar implementation3 = implementNode({\n  kind: \"after\",\n  collapsibleKey: \"rule\",\n  hasAssociatedError: true,\n  keys: {\n    rule: {\n      parse: parseDateLimit,\n      serialize: (schema2) => schema2.toISOString()\n    }\n  },\n  normalize: createDateSchemaNormalizer(\"after\"),\n  defaults: {\n    description: (node2) => `${node2.collapsibleLimitString} or later`,\n    actual: describeCollapsibleDate\n  },\n  intersections: {\n    after: (l, r) => l.isStricterThan(r) ? l : r\n  }\n});\nvar AfterNode = class extends BaseRange {\n  impliedBasis = $ark.intrinsic.Date.internal;\n  collapsibleLimitString = describeCollapsibleDate(this.rule);\n  traverseAllows = (data) => data >= this.rule;\n  reduceJsonSchema() {\n    return JsonSchema.throwUnjsonifiableError(\"Date instance\");\n  }\n};\nvar After = {\n  implementation: implementation3,\n  Node: AfterNode\n};\n\n// ../schema/out/refinements/before.js\nvar implementation4 = implementNode({\n  kind: \"before\",\n  collapsibleKey: \"rule\",\n  hasAssociatedError: true,\n  keys: {\n    rule: {\n      parse: parseDateLimit,\n      serialize: (schema2) => schema2.toISOString()\n    }\n  },\n  normalize: createDateSchemaNormalizer(\"before\"),\n  defaults: {\n    description: (node2) => `${node2.collapsibleLimitString} or earlier`,\n    actual: describeCollapsibleDate\n  },\n  intersections: {\n    before: (l, r) => l.isStricterThan(r) ? l : r,\n    after: (before, after, ctx) => before.overlapsRange(after) ? before.overlapIsUnit(after) ? ctx.$.node(\"unit\", { unit: before.rule }) : null : Disjoint.init(\"range\", before, after)\n  }\n});\nvar BeforeNode = class extends BaseRange {\n  collapsibleLimitString = describeCollapsibleDate(this.rule);\n  traverseAllows = (data) => data <= this.rule;\n  impliedBasis = $ark.intrinsic.Date.internal;\n  reduceJsonSchema() {\n    return JsonSchema.throwUnjsonifiableError(\"Date instance\");\n  }\n};\nvar Before = {\n  implementation: implementation4,\n  Node: BeforeNode\n};\n\n// ../schema/out/refinements/exactLength.js\nvar implementation5 = implementNode({\n  kind: \"exactLength\",\n  collapsibleKey: \"rule\",\n  keys: {\n    rule: {\n      parse: createLengthRuleParser(\"exactLength\")\n    }\n  },\n  normalize: (schema2) => typeof schema2 === \"number\" ? { rule: schema2 } : schema2,\n  hasAssociatedError: true,\n  defaults: {\n    description: (node2) => `exactly length ${node2.rule}`,\n    actual: (data) => `${data.length}`\n  },\n  intersections: {\n    exactLength: (l, r, ctx) => Disjoint.init(\"unit\", ctx.$.node(\"unit\", { unit: l.rule }), ctx.$.node(\"unit\", { unit: r.rule }), { path: [\"length\"] }),\n    minLength: (exactLength, minLength) => exactLength.rule >= minLength.rule ? exactLength : Disjoint.init(\"range\", exactLength, minLength),\n    maxLength: (exactLength, maxLength) => exactLength.rule <= maxLength.rule ? exactLength : Disjoint.init(\"range\", exactLength, maxLength)\n  }\n});\nvar ExactLengthNode = class extends InternalPrimitiveConstraint {\n  traverseAllows = (data) => data.length === this.rule;\n  compiledCondition = `data.length === ${this.rule}`;\n  compiledNegation = `data.length !== ${this.rule}`;\n  impliedBasis = $ark.intrinsic.lengthBoundable.internal;\n  expression = `== ${this.rule}`;\n  reduceJsonSchema(schema2) {\n    switch (schema2.type) {\n      case \"string\":\n        schema2.minLength = this.rule;\n        schema2.maxLength = this.rule;\n        return schema2;\n      case \"array\":\n        schema2.minItems = this.rule;\n        schema2.maxItems = this.rule;\n        return schema2;\n      default:\n        return JsonSchema.throwInternalOperandError(\"exactLength\", schema2);\n    }\n  }\n};\nvar ExactLength = {\n  implementation: implementation5,\n  Node: ExactLengthNode\n};\n\n// ../schema/out/refinements/max.js\nvar implementation6 = implementNode({\n  kind: \"max\",\n  collapsibleKey: \"rule\",\n  hasAssociatedError: true,\n  keys: {\n    rule: {},\n    exclusive: parseExclusiveKey\n  },\n  normalize: (schema2) => typeof schema2 === \"number\" ? { rule: schema2 } : schema2,\n  defaults: {\n    description: (node2) => {\n      if (node2.rule === 0)\n        return node2.exclusive ? \"negative\" : \"non-positive\";\n      return `${node2.exclusive ? \"less than\" : \"at most\"} ${node2.rule}`;\n    }\n  },\n  intersections: {\n    max: (l, r) => l.isStricterThan(r) ? l : r,\n    min: (max, min, ctx) => max.overlapsRange(min) ? max.overlapIsUnit(min) ? ctx.$.node(\"unit\", { unit: max.rule }) : null : Disjoint.init(\"range\", max, min)\n  },\n  obviatesBasisDescription: true\n});\nvar MaxNode = class extends BaseRange {\n  impliedBasis = $ark.intrinsic.number.internal;\n  traverseAllows = this.exclusive ? (data) => data < this.rule : (data) => data <= this.rule;\n  reduceJsonSchema(schema2) {\n    if (this.exclusive)\n      schema2.exclusiveMaximum = this.rule;\n    else\n      schema2.maximum = this.rule;\n    return schema2;\n  }\n};\nvar Max = {\n  implementation: implementation6,\n  Node: MaxNode\n};\n\n// ../schema/out/refinements/maxLength.js\nvar implementation7 = implementNode({\n  kind: \"maxLength\",\n  collapsibleKey: \"rule\",\n  hasAssociatedError: true,\n  keys: {\n    rule: {\n      parse: createLengthRuleParser(\"maxLength\")\n    }\n  },\n  reduce: (inner, $) => inner.rule === 0 ? $.node(\"exactLength\", inner) : void 0,\n  normalize: createLengthSchemaNormalizer(\"maxLength\"),\n  defaults: {\n    description: (node2) => `at most length ${node2.rule}`,\n    actual: (data) => `${data.length}`\n  },\n  intersections: {\n    maxLength: (l, r) => l.isStricterThan(r) ? l : r,\n    minLength: (max, min, ctx) => max.overlapsRange(min) ? max.overlapIsUnit(min) ? ctx.$.node(\"exactLength\", { rule: max.rule }) : null : Disjoint.init(\"range\", max, min)\n  }\n});\nvar MaxLengthNode = class extends BaseRange {\n  impliedBasis = $ark.intrinsic.lengthBoundable.internal;\n  traverseAllows = (data) => data.length <= this.rule;\n  reduceJsonSchema(schema2) {\n    switch (schema2.type) {\n      case \"string\":\n        schema2.maxLength = this.rule;\n        return schema2;\n      case \"array\":\n        schema2.maxItems = this.rule;\n        return schema2;\n      default:\n        return JsonSchema.throwInternalOperandError(\"maxLength\", schema2);\n    }\n  }\n};\nvar MaxLength = {\n  implementation: implementation7,\n  Node: MaxLengthNode\n};\n\n// ../schema/out/refinements/min.js\nvar implementation8 = implementNode({\n  kind: \"min\",\n  collapsibleKey: \"rule\",\n  hasAssociatedError: true,\n  keys: {\n    rule: {},\n    exclusive: parseExclusiveKey\n  },\n  normalize: (schema2) => typeof schema2 === \"number\" ? { rule: schema2 } : schema2,\n  defaults: {\n    description: (node2) => {\n      if (node2.rule === 0)\n        return node2.exclusive ? \"positive\" : \"non-negative\";\n      return `${node2.exclusive ? \"more than\" : \"at least\"} ${node2.rule}`;\n    }\n  },\n  intersections: {\n    min: (l, r) => l.isStricterThan(r) ? l : r\n  },\n  obviatesBasisDescription: true\n});\nvar MinNode = class extends BaseRange {\n  impliedBasis = $ark.intrinsic.number.internal;\n  traverseAllows = this.exclusive ? (data) => data > this.rule : (data) => data >= this.rule;\n  reduceJsonSchema(schema2) {\n    if (this.exclusive)\n      schema2.exclusiveMinimum = this.rule;\n    else\n      schema2.minimum = this.rule;\n    return schema2;\n  }\n};\nvar Min = {\n  implementation: implementation8,\n  Node: MinNode\n};\n\n// ../schema/out/refinements/minLength.js\nvar implementation9 = implementNode({\n  kind: \"minLength\",\n  collapsibleKey: \"rule\",\n  hasAssociatedError: true,\n  keys: {\n    rule: {\n      parse: createLengthRuleParser(\"minLength\")\n    }\n  },\n  reduce: (inner) => inner.rule === 0 ? (\n    // a minimum length of zero is trivially satisfied\n    $ark.intrinsic.unknown\n  ) : void 0,\n  normalize: createLengthSchemaNormalizer(\"minLength\"),\n  defaults: {\n    description: (node2) => node2.rule === 1 ? \"non-empty\" : `at least length ${node2.rule}`,\n    // avoid default message like \"must be non-empty (was 0)\"\n    actual: (data) => data.length === 0 ? \"\" : `${data.length}`\n  },\n  intersections: {\n    minLength: (l, r) => l.isStricterThan(r) ? l : r\n  }\n});\nvar MinLengthNode = class extends BaseRange {\n  impliedBasis = $ark.intrinsic.lengthBoundable.internal;\n  traverseAllows = (data) => data.length >= this.rule;\n  reduceJsonSchema(schema2) {\n    switch (schema2.type) {\n      case \"string\":\n        schema2.minLength = this.rule;\n        return schema2;\n      case \"array\":\n        schema2.minItems = this.rule;\n        return schema2;\n      default:\n        return JsonSchema.throwInternalOperandError(\"minLength\", schema2);\n    }\n  }\n};\nvar MinLength = {\n  implementation: implementation9,\n  Node: MinLengthNode\n};\n\n// ../schema/out/refinements/kinds.js\nvar boundImplementationsByKind = {\n  min: Min.implementation,\n  max: Max.implementation,\n  minLength: MinLength.implementation,\n  maxLength: MaxLength.implementation,\n  exactLength: ExactLength.implementation,\n  after: After.implementation,\n  before: Before.implementation\n};\nvar boundClassesByKind = {\n  min: Min.Node,\n  max: Max.Node,\n  minLength: MinLength.Node,\n  maxLength: MaxLength.Node,\n  exactLength: ExactLength.Node,\n  after: After.Node,\n  before: Before.Node\n};\n\n// ../schema/out/refinements/pattern.js\nvar implementation10 = implementNode({\n  kind: \"pattern\",\n  collapsibleKey: \"rule\",\n  keys: {\n    rule: {},\n    flags: {}\n  },\n  normalize: (schema2) => typeof schema2 === \"string\" ? { rule: schema2 } : schema2 instanceof RegExp ? schema2.flags ? { rule: schema2.source, flags: schema2.flags } : { rule: schema2.source } : schema2,\n  obviatesBasisDescription: true,\n  obviatesBasisExpression: true,\n  hasAssociatedError: true,\n  intersectionIsOpen: true,\n  defaults: {\n    description: (node2) => `matched by ${node2.rule}`\n  },\n  intersections: {\n    // for now, non-equal regex are naively intersected:\n    // https://github.com/arktypeio/arktype/issues/853\n    pattern: () => null\n  }\n});\nvar PatternNode = class extends InternalPrimitiveConstraint {\n  instance = new RegExp(this.rule, this.flags);\n  expression = `${this.instance}`;\n  traverseAllows = this.instance.test.bind(this.instance);\n  compiledCondition = `${this.expression}.test(data)`;\n  compiledNegation = `!${this.compiledCondition}`;\n  impliedBasis = $ark.intrinsic.string.internal;\n  reduceJsonSchema(schema2) {\n    if (schema2.pattern) {\n      return JsonSchema.throwUnjsonifiableError(`Intersection of patterns ${schema2.pattern} & ${this.rule}`);\n    }\n    schema2.pattern = this.rule;\n    return schema2;\n  }\n};\nvar Pattern = {\n  implementation: implementation10,\n  Node: PatternNode\n};\n\n// ../schema/out/parse.js\nvar schemaKindOf = (schema2, allowedKinds) => {\n  const kind = discriminateRootKind(schema2);\n  if (allowedKinds && !allowedKinds.includes(kind)) {\n    return throwParseError(`Root of kind ${kind} should be one of ${allowedKinds}`);\n  }\n  return kind;\n};\nvar discriminateRootKind = (schema2) => {\n  if (hasArkKind(schema2, \"root\"))\n    return schema2.kind;\n  if (typeof schema2 === \"string\")\n    return schema2[0] === \"$\" ? \"alias\" : \"domain\";\n  if (typeof schema2 === \"function\")\n    return \"proto\";\n  if (typeof schema2 !== \"object\" || schema2 === null)\n    return throwParseError(writeInvalidSchemaMessage(schema2));\n  if (\"morphs\" in schema2)\n    return \"morph\";\n  if (\"branches\" in schema2 || isArray(schema2))\n    return \"union\";\n  if (\"unit\" in schema2)\n    return \"unit\";\n  if (\"reference\" in schema2)\n    return \"alias\";\n  const schemaKeys = Object.keys(schema2);\n  if (schemaKeys.length === 0 || schemaKeys.some((k) => k in constraintKeys))\n    return \"intersection\";\n  if (\"proto\" in schema2)\n    return \"proto\";\n  if (\"domain\" in schema2)\n    return \"domain\";\n  return throwParseError(writeInvalidSchemaMessage(schema2));\n};\nvar writeInvalidSchemaMessage = (schema2) => `${printable(schema2)} is not a valid type schema`;\nvar nodeCountsByPrefix = {};\nvar serializeListableChild = (listableNode) => isArray(listableNode) ? listableNode.map((node2) => node2.collapsibleJson) : listableNode.collapsibleJson;\nvar nodesByRegisteredId = {};\n$ark.nodesByRegisteredId = nodesByRegisteredId;\nvar registerNodeId = (prefix) => {\n  nodeCountsByPrefix[prefix] ??= 0;\n  return `${prefix}${++nodeCountsByPrefix[prefix]}`;\n};\nvar parseNode = (ctx) => {\n  const impl = nodeImplementationsByKind[ctx.kind];\n  const configuredSchema = impl.applyConfig?.(ctx.def, ctx.$.resolvedConfig) ?? ctx.def;\n  const inner = {};\n  const { meta: metaSchema, ...innerSchema } = configuredSchema;\n  const meta = metaSchema === void 0 ? {} : typeof metaSchema === \"string\" ? { description: metaSchema } : metaSchema;\n  const innerSchemaEntries = entriesOf(innerSchema).sort(([lKey], [rKey]) => isNodeKind(lKey) ? isNodeKind(rKey) ? precedenceOfKind(lKey) - precedenceOfKind(rKey) : 1 : isNodeKind(rKey) ? -1 : lKey < rKey ? -1 : 1).filter(([k, v]) => {\n    if (k.startsWith(\"meta.\")) {\n      const metaKey = k.slice(5);\n      meta[metaKey] = v;\n      return false;\n    }\n    return true;\n  });\n  for (const entry of innerSchemaEntries) {\n    const k = entry[0];\n    const keyImpl = impl.keys[k];\n    if (!keyImpl)\n      return throwParseError(`Key ${k} is not valid on ${ctx.kind} schema`);\n    const v = keyImpl.parse ? keyImpl.parse(entry[1], ctx) : entry[1];\n    if (v !== unset && (v !== void 0 || keyImpl.preserveUndefined))\n      inner[k] = v;\n  }\n  if (impl.reduce && !ctx.prereduced) {\n    const reduced = impl.reduce(inner, ctx.$);\n    if (reduced) {\n      if (reduced instanceof Disjoint)\n        return reduced.throw();\n      return withMeta(reduced, meta);\n    }\n  }\n  const node2 = createNode({\n    id: ctx.id,\n    kind: ctx.kind,\n    inner,\n    meta,\n    $: ctx.$\n  });\n  return node2;\n};\nvar createNode = ({ id, kind, inner, meta, $, ignoreCache }) => {\n  const impl = nodeImplementationsByKind[kind];\n  const innerEntries = entriesOf(inner);\n  const children = [];\n  let innerJson = {};\n  innerEntries.forEach(([k, v]) => {\n    const keyImpl = impl.keys[k];\n    const serialize = keyImpl.serialize ?? (keyImpl.child ? serializeListableChild : defaultValueSerializer);\n    innerJson[k] = serialize(v);\n    if (keyImpl.child === true) {\n      const listableNode = v;\n      if (isArray(listableNode))\n        children.push(...listableNode);\n      else\n        children.push(listableNode);\n    } else if (typeof keyImpl.child === \"function\")\n      children.push(...keyImpl.child(v));\n  });\n  if (impl.finalizeInnerJson)\n    innerJson = impl.finalizeInnerJson(innerJson);\n  let json3 = { ...innerJson };\n  let metaJson = {};\n  if (!isEmptyObject(meta)) {\n    metaJson = flatMorph(meta, (k, v) => [\n      k,\n      k === \"examples\" ? v : defaultValueSerializer(v)\n    ]);\n    json3.meta = possiblyCollapse(metaJson, \"description\", true);\n  }\n  innerJson = possiblyCollapse(innerJson, impl.collapsibleKey, false);\n  const innerHash = JSON.stringify({ kind, ...innerJson });\n  json3 = possiblyCollapse(json3, impl.collapsibleKey, false);\n  const collapsibleJson = possiblyCollapse(json3, impl.collapsibleKey, true);\n  const hash = JSON.stringify({ kind, ...json3 });\n  if ($.nodesByHash[hash] && !ignoreCache)\n    return $.nodesByHash[hash];\n  const attachments = {\n    id,\n    kind,\n    impl,\n    inner,\n    innerEntries,\n    innerJson,\n    innerHash,\n    meta,\n    metaJson,\n    json: json3,\n    hash,\n    collapsibleJson,\n    children\n  };\n  if (kind !== \"intersection\") {\n    for (const k in inner)\n      if (k !== \"in\" && k !== \"out\")\n        attachments[k] = inner[k];\n  }\n  const node2 = new nodeClassesByKind[kind](attachments, $);\n  return $.nodesByHash[hash] = node2;\n};\nvar withId = (node2, id) => {\n  if (node2.id === id)\n    return node2;\n  if (isNode(nodesByRegisteredId[id]))\n    throwInternalError(`Unexpected attempt to overwrite node id ${id}`);\n  return createNode({\n    id,\n    kind: node2.kind,\n    inner: node2.inner,\n    meta: node2.meta,\n    $: node2.$,\n    ignoreCache: true\n  });\n};\nvar withMeta = (node2, meta, id) => {\n  if (id && isNode(nodesByRegisteredId[id]))\n    throwInternalError(`Unexpected attempt to overwrite node id ${id}`);\n  return createNode({\n    id: id ?? registerNodeId(meta.alias ?? node2.kind),\n    kind: node2.kind,\n    inner: node2.inner,\n    meta,\n    $: node2.$\n  });\n};\nvar possiblyCollapse = (json3, toKey, allowPrimitive) => {\n  const collapsibleKeys = Object.keys(json3);\n  if (collapsibleKeys.length === 1 && collapsibleKeys[0] === toKey) {\n    const collapsed = json3[toKey];\n    if (allowPrimitive)\n      return collapsed;\n    if (\n      // if the collapsed value is still an object\n      hasDomain(collapsed, \"object\") && // and the JSON did not include any implied keys\n      (Object.keys(collapsed).length === 1 || Array.isArray(collapsed))\n    ) {\n      return collapsed;\n    }\n  }\n  return json3;\n};\n\n// ../schema/out/structure/prop.js\nvar intersectProps = (l, r, ctx) => {\n  if (l.key !== r.key)\n    return null;\n  const key = l.key;\n  let value2 = intersectOrPipeNodes(l.value, r.value, ctx);\n  const kind = l.required || r.required ? \"required\" : \"optional\";\n  if (value2 instanceof Disjoint) {\n    if (kind === \"optional\")\n      value2 = $ark.intrinsic.never.internal;\n    else {\n      return value2.withPrefixKey(l.key, l.required && r.required ? \"required\" : \"optional\");\n    }\n  }\n  if (kind === \"required\") {\n    return ctx.$.node(\"required\", {\n      key,\n      value: value2\n    });\n  }\n  const defaultIntersection = l.hasDefault() ? r.hasDefault() ? l.default === r.default ? l.default : throwParseError(writeDefaultIntersectionMessage(l.default, r.default)) : l.default : r.hasDefault() ? r.default : unset;\n  return ctx.$.node(\"optional\", {\n    key,\n    value: value2,\n    // unset is stripped during parsing\n    default: defaultIntersection\n  });\n};\nvar BaseProp = class extends BaseConstraint {\n  required = this.kind === \"required\";\n  optional = this.kind === \"optional\";\n  impliedBasis = $ark.intrinsic.object.internal;\n  serializedKey = compileSerializedValue(this.key);\n  compiledKey = typeof this.key === \"string\" ? this.key : this.serializedKey;\n  flatRefs = append(this.value.flatRefs.map((ref) => flatRef([this.key, ...ref.path], ref.node)), flatRef([this.key], this.value));\n  _transform(mapper, ctx) {\n    ctx.path.push(this.key);\n    const result = super._transform(mapper, ctx);\n    ctx.path.pop();\n    return result;\n  }\n  hasDefault() {\n    return \"default\" in this.inner;\n  }\n  traverseAllows = (data, ctx) => {\n    if (this.key in data) {\n      return traverseKey(this.key, () => this.value.traverseAllows(data[this.key], ctx), ctx);\n    }\n    return this.optional;\n  };\n  traverseApply = (data, ctx) => {\n    if (this.key in data) {\n      traverseKey(this.key, () => this.value.traverseApply(data[this.key], ctx), ctx);\n    } else if (this.hasKind(\"required\"))\n      ctx.errorFromNodeContext(this.errorContext);\n  };\n  compile(js) {\n    js.if(`${this.serializedKey} in data`, () => js.traverseKey(this.serializedKey, `data${js.prop(this.key)}`, this.value));\n    if (this.hasKind(\"required\")) {\n      js.else(() => {\n        if (js.traversalKind === \"Apply\") {\n          return js.line(`ctx.errorFromNodeContext(${this.compiledErrorContext})`);\n        } else\n          return js.return(false);\n      });\n    }\n    if (js.traversalKind === \"Allows\")\n      js.return(true);\n  }\n};\nvar writeDefaultIntersectionMessage = (lValue, rValue) => `Invalid intersection of default values ${printable(lValue)} & ${printable(rValue)}`;\n\n// ../schema/out/structure/optional.js\nvar implementation11 = implementNode({\n  kind: \"optional\",\n  hasAssociatedError: false,\n  intersectionIsOpen: true,\n  keys: {\n    key: {},\n    value: {\n      child: true,\n      parse: (schema2, ctx) => ctx.$.parseSchema(schema2)\n    },\n    default: {\n      preserveUndefined: true\n    }\n  },\n  normalize: (schema2) => schema2,\n  reduce: (inner, $) => {\n    if ($.resolvedConfig.exactOptionalPropertyTypes === false) {\n      if (!inner.value.allows(void 0)) {\n        return $.node(\"optional\", { ...inner, value: inner.value.or(intrinsic.undefined) }, { prereduced: true });\n      }\n    }\n  },\n  defaults: {\n    description: (node2) => `${node2.compiledKey}?: ${node2.value.description}`\n  },\n  intersections: {\n    optional: intersectProps\n  }\n});\nvar OptionalNode = class extends BaseProp {\n  constructor(...args2) {\n    super(...args2);\n    if (\"default\" in this.inner)\n      assertDefaultValueAssignability(this.value, this.inner.default, this.key);\n  }\n  get outProp() {\n    if (!this.hasDefault())\n      return this;\n    const { default: defaultValue, ...requiredInner } = this.inner;\n    return this.cacheGetter(\"outProp\", this.$.node(\"required\", requiredInner, { prereduced: true }));\n  }\n  expression = this.hasDefault() ? `${this.compiledKey}: ${this.value.expression} = ${printable(this.inner.default)}` : `${this.compiledKey}?: ${this.value.expression}`;\n  defaultValueMorph = getDefaultableMorph(this);\n  defaultValueMorphRef = this.defaultValueMorph && registeredReference(this.defaultValueMorph);\n};\nvar Optional = {\n  implementation: implementation11,\n  Node: OptionalNode\n};\nvar defaultableMorphCache = {};\nvar getDefaultableMorph = (node2) => {\n  if (!node2.hasDefault())\n    return;\n  const cacheKey = `{${node2.compiledKey}: ${node2.value.id} = ${defaultValueSerializer(node2.default)}}`;\n  return defaultableMorphCache[cacheKey] ??= computeDefaultValueMorph(node2.key, node2.value, node2.default);\n};\nvar computeDefaultValueMorph = (key, value2, defaultInput) => {\n  if (typeof defaultInput === \"function\") {\n    return value2.includesTransform ? (data, ctx) => {\n      traverseKey(key, () => value2(data[key] = defaultInput(), ctx), ctx);\n      return data;\n    } : (data) => {\n      data[key] = defaultInput();\n      return data;\n    };\n  }\n  const precomputedMorphedDefault = value2.includesTransform ? value2.assert(defaultInput) : defaultInput;\n  return hasDomain(precomputedMorphedDefault, \"object\") ? (\n    // the type signature only allows this if the value was morphed\n    (data, ctx) => {\n      traverseKey(key, () => value2(data[key] = defaultInput, ctx), ctx);\n      return data;\n    }\n  ) : (data) => {\n    data[key] = precomputedMorphedDefault;\n    return data;\n  };\n};\nvar assertDefaultValueAssignability = (node2, value2, key) => {\n  const wrapped = isThunk(value2);\n  if (hasDomain(value2, \"object\") && !wrapped)\n    throwParseError(writeNonPrimitiveNonFunctionDefaultValueMessage(key));\n  const out = node2.in(wrapped ? value2() : value2);\n  if (out instanceof ArkErrors) {\n    if (key === null) {\n      throwParseError(`Default ${out.summary}`);\n    }\n    const atPath = out.transform((e) => e.transform((input) => ({ ...input, prefixPath: [key] })));\n    throwParseError(`Default for ${atPath.summary}`);\n  }\n  return value2;\n};\nvar writeNonPrimitiveNonFunctionDefaultValueMessage = (key) => {\n  const keyDescription = key === null ? \"\" : typeof key === \"number\" ? `for value at [${key}] ` : `for ${compileSerializedValue(key)} `;\n  return `Non-primitive default ${keyDescription}must be specified as a function like () => ({my: 'object'})`;\n};\n\n// ../schema/out/roots/root.js\nvar BaseRoot = class extends BaseNode {\n  constructor(attachments, $) {\n    super(attachments, $);\n    Object.defineProperty(this, arkKind, { value: \"root\", enumerable: false });\n  }\n  get internal() {\n    return this;\n  }\n  get \"~standard\"() {\n    return {\n      vendor: \"arktype\",\n      version: 1,\n      validate: (input) => {\n        const out = this(input);\n        if (out instanceof ArkErrors)\n          return out;\n        return { value: out };\n      }\n    };\n  }\n  as() {\n    return this;\n  }\n  brand(name) {\n    if (name === \"\")\n      return throwParseError(emptyBrandNameMessage);\n    return this;\n  }\n  readonly() {\n    return this;\n  }\n  branches = this.hasKind(\"union\") ? this.inner.branches : [this];\n  distribute(mapBranch, reduceMapped) {\n    const mappedBranches = this.branches.map(mapBranch);\n    return reduceMapped?.(mappedBranches) ?? mappedBranches;\n  }\n  get shortDescription() {\n    return this.meta.description ?? this.defaultShortDescription;\n  }\n  toJsonSchema() {\n    const schema2 = this.innerToJsonSchema();\n    return Object.assign(schema2, this.metaJson);\n  }\n  intersect(r) {\n    const rNode = this.$.parseDefinition(r);\n    const result = this.rawIntersect(rNode);\n    if (result instanceof Disjoint)\n      return result;\n    return this.$.finalize(result);\n  }\n  rawIntersect(r) {\n    return intersectNodesRoot(this, r, this.$);\n  }\n  toNeverIfDisjoint() {\n    return this;\n  }\n  and(r) {\n    const result = this.intersect(r);\n    return result instanceof Disjoint ? result.throw() : result;\n  }\n  rawAnd(r) {\n    const result = this.rawIntersect(r);\n    return result instanceof Disjoint ? result.throw() : result;\n  }\n  or(r) {\n    const rNode = this.$.parseDefinition(r);\n    return this.$.finalize(this.rawOr(rNode));\n  }\n  rawOr(r) {\n    const branches = [...this.branches, ...r.branches];\n    return this.$.node(\"union\", branches);\n  }\n  map(flatMapEntry) {\n    return this.$.schema(this.applyStructuralOperation(\"map\", [flatMapEntry]));\n  }\n  pick(...keys) {\n    return this.$.schema(this.applyStructuralOperation(\"pick\", keys));\n  }\n  omit(...keys) {\n    return this.$.schema(this.applyStructuralOperation(\"omit\", keys));\n  }\n  required() {\n    return this.$.schema(this.applyStructuralOperation(\"required\", []));\n  }\n  partial() {\n    return this.$.schema(this.applyStructuralOperation(\"partial\", []));\n  }\n  _keyof;\n  keyof() {\n    if (this._keyof)\n      return this._keyof;\n    const result = this.applyStructuralOperation(\"keyof\", []).reduce((result2, branch) => result2.intersect(branch).toNeverIfDisjoint(), $ark.intrinsic.unknown.internal);\n    if (result.branches.length === 0) {\n      throwParseError(writeUnsatisfiableExpressionError(`keyof ${this.expression}`));\n    }\n    return this._keyof = this.$.finalize(result);\n  }\n  get props() {\n    if (this.branches.length !== 1)\n      return throwParseError(writeLiteralUnionEntriesMessage(this.expression));\n    return [...this.applyStructuralOperation(\"props\", [])[0]];\n  }\n  merge(r) {\n    const rNode = this.$.parseDefinition(r);\n    return this.$.schema(rNode.distribute((branch) => this.applyStructuralOperation(\"merge\", [\n      structureOf(branch) ?? throwParseError(writeNonStructuralOperandMessage(\"merge\", branch.expression))\n    ])));\n  }\n  applyStructuralOperation(operation, args2) {\n    return this.distribute((branch) => {\n      if (branch.equals($ark.intrinsic.object) && operation !== \"merge\")\n        return branch;\n      const structure = structureOf(branch);\n      if (!structure) {\n        throwParseError(writeNonStructuralOperandMessage(operation, branch.expression));\n      }\n      if (operation === \"keyof\")\n        return structure.keyof();\n      if (operation === \"get\")\n        return structure.get(...args2);\n      if (operation === \"props\")\n        return structure.props;\n      const structuralMethodName = operation === \"required\" ? \"require\" : operation === \"partial\" ? \"optionalize\" : operation;\n      return this.$.node(\"intersection\", {\n        ...branch.inner,\n        structure: structure[structuralMethodName](...args2)\n      });\n    });\n  }\n  get(...path) {\n    if (path[0] === void 0)\n      return this;\n    return this.$.schema(this.applyStructuralOperation(\"get\", path));\n  }\n  extract(r) {\n    const rNode = this.$.parseDefinition(r);\n    return this.$.schema(this.branches.filter((branch) => branch.extends(rNode)));\n  }\n  exclude(r) {\n    const rNode = this.$.parseDefinition(r);\n    return this.$.schema(this.branches.filter((branch) => !branch.extends(rNode)));\n  }\n  array() {\n    return this.$.schema(this.isUnknown() ? { proto: Array } : {\n      proto: Array,\n      sequence: this\n    }, { prereduced: true });\n  }\n  overlaps(r) {\n    const intersection = this.intersect(r);\n    return !(intersection instanceof Disjoint);\n  }\n  extends(r) {\n    const intersection = this.intersect(r);\n    return !(intersection instanceof Disjoint) && this.equals(intersection);\n  }\n  ifExtends(r) {\n    return this.extends(r) ? this : void 0;\n  }\n  subsumes(r) {\n    const rNode = this.$.parseDefinition(r);\n    return rNode.extends(this);\n  }\n  configure(meta, selector = \"shallow\") {\n    return this.configureReferences(meta, selector);\n  }\n  describe(description, selector = \"shallow\") {\n    return this.configure({ description }, selector);\n  }\n  // these should ideally be implemented in arktype since they use its syntax\n  // https://github.com/arktypeio/arktype/issues/1223\n  optional() {\n    return [this, \"?\"];\n  }\n  // these should ideally be implemented in arktype since they use its syntax\n  // https://github.com/arktypeio/arktype/issues/1223\n  default(thunkableValue) {\n    assertDefaultValueAssignability(this, thunkableValue, null);\n    return [this, \"=\", thunkableValue];\n  }\n  from(input) {\n    return this.assert(input);\n  }\n  _pipe(...morphs) {\n    const result = morphs.reduce((acc, morph) => acc.rawPipeOnce(morph), this);\n    return this.$.finalize(result);\n  }\n  tryPipe(...morphs) {\n    const result = morphs.reduce((acc, morph) => acc.rawPipeOnce(hasArkKind(morph, \"root\") ? morph : (In, ctx) => {\n      try {\n        return morph(In, ctx);\n      } catch (e) {\n        return ctx.error({\n          code: \"predicate\",\n          predicate: morph,\n          actual: `aborted due to error:\n    ${e}\n`\n        });\n      }\n    }), this);\n    return this.$.finalize(result);\n  }\n  pipe = Object.assign(this._pipe.bind(this), {\n    try: this.tryPipe.bind(this)\n  });\n  to(def) {\n    return this.$.finalize(this.toNode(this.$.parseDefinition(def)));\n  }\n  toNode(root) {\n    const result = pipeNodesRoot(this, root, this.$);\n    if (result instanceof Disjoint)\n      return result.throw();\n    return result;\n  }\n  rawPipeOnce(morph) {\n    if (hasArkKind(morph, \"root\"))\n      return this.toNode(morph);\n    return this.distribute((branch) => branch.hasKind(\"morph\") ? this.$.node(\"morph\", {\n      in: branch.inner.in,\n      morphs: [...branch.morphs, morph]\n    }) : this.$.node(\"morph\", {\n      in: branch,\n      morphs: [morph]\n    }), this.$.parseSchema);\n  }\n  narrow(predicate) {\n    return this.constrainOut(\"predicate\", predicate);\n  }\n  constrain(kind, schema2) {\n    return this._constrain(\"root\", kind, schema2);\n  }\n  constrainIn(kind, schema2) {\n    return this._constrain(\"in\", kind, schema2);\n  }\n  constrainOut(kind, schema2) {\n    return this._constrain(\"out\", kind, schema2);\n  }\n  _constrain(io, kind, schema2) {\n    const constraint = this.$.node(kind, schema2);\n    if (constraint.isRoot()) {\n      return constraint.isUnknown() ? this : throwInternalError(`Unexpected constraint node ${constraint}`);\n    }\n    const operand = io === \"root\" ? this : this[io];\n    if (operand.hasKind(\"morph\") || constraint.impliedBasis && !operand.extends(constraint.impliedBasis)) {\n      return throwInvalidOperandError(kind, constraint.impliedBasis, this);\n    }\n    const partialIntersection = this.$.node(\"intersection\", {\n      // important this is constraint.kind instead of kind in case\n      // the node was reduced during parsing\n      [constraint.kind]: constraint\n    });\n    const result = io === \"out\" ? pipeNodesRoot(this, partialIntersection, this.$) : intersectNodesRoot(this, partialIntersection, this.$);\n    if (result instanceof Disjoint)\n      result.throw();\n    return this.$.finalize(result);\n  }\n  onUndeclaredKey(cfg) {\n    const rule = typeof cfg === \"string\" ? cfg : cfg.rule;\n    const deep = typeof cfg === \"string\" ? false : cfg.deep;\n    return this.$.finalize(this.transform((kind, inner) => kind === \"structure\" ? rule === \"ignore\" ? omit(inner, { undeclared: 1 }) : { ...inner, undeclared: rule } : inner, deep ? void 0 : { shouldTransform: (node2) => !includes(structuralKinds, node2.kind) }));\n  }\n  hasEqualMorphs(r) {\n    if (!this.includesTransform && !r.includesTransform)\n      return true;\n    if (!arrayEquals(this.shallowMorphs, r.shallowMorphs))\n      return false;\n    if (!arrayEquals(this.flatMorphs, r.flatMorphs, {\n      isEqual: (l, r2) => l.propString === r2.propString && (l.node.hasKind(\"morph\") && r2.node.hasKind(\"morph\") ? l.node.hasEqualMorphs(r2.node) : l.node.hasKind(\"intersection\") && r2.node.hasKind(\"intersection\") ? l.node.structure?.structuralMorphRef === r2.node.structure?.structuralMorphRef : false)\n    }))\n      return false;\n    return true;\n  }\n  onDeepUndeclaredKey(behavior) {\n    return this.onUndeclaredKey({ rule: behavior, deep: true });\n  }\n  filter(predicate) {\n    return this.constrainIn(\"predicate\", predicate);\n  }\n  divisibleBy(schema2) {\n    return this.constrain(\"divisor\", schema2);\n  }\n  matching(schema2) {\n    return this.constrain(\"pattern\", schema2);\n  }\n  atLeast(schema2) {\n    return this.constrain(\"min\", schema2);\n  }\n  atMost(schema2) {\n    return this.constrain(\"max\", schema2);\n  }\n  moreThan(schema2) {\n    return this.constrain(\"min\", exclusivizeRangeSchema(schema2));\n  }\n  lessThan(schema2) {\n    return this.constrain(\"max\", exclusivizeRangeSchema(schema2));\n  }\n  atLeastLength(schema2) {\n    return this.constrain(\"minLength\", schema2);\n  }\n  atMostLength(schema2) {\n    return this.constrain(\"maxLength\", schema2);\n  }\n  moreThanLength(schema2) {\n    return this.constrain(\"minLength\", exclusivizeRangeSchema(schema2));\n  }\n  lessThanLength(schema2) {\n    return this.constrain(\"maxLength\", exclusivizeRangeSchema(schema2));\n  }\n  exactlyLength(schema2) {\n    return this.constrain(\"exactLength\", schema2);\n  }\n  atOrAfter(schema2) {\n    return this.constrain(\"after\", schema2);\n  }\n  atOrBefore(schema2) {\n    return this.constrain(\"before\", schema2);\n  }\n  laterThan(schema2) {\n    return this.constrain(\"after\", exclusivizeRangeSchema(schema2));\n  }\n  earlierThan(schema2) {\n    return this.constrain(\"before\", exclusivizeRangeSchema(schema2));\n  }\n};\nvar emptyBrandNameMessage = `Expected a non-empty brand name after #`;\nvar exclusivizeRangeSchema = (schema2) => typeof schema2 === \"object\" && !(schema2 instanceof Date) ? { ...schema2, exclusive: true } : {\n  rule: schema2,\n  exclusive: true\n};\nvar typeOrTermExtends = (t, base) => hasArkKind(base, \"root\") ? hasArkKind(t, \"root\") ? t.extends(base) : base.allows(t) : hasArkKind(t, \"root\") ? t.hasUnit(base) : base === t;\nvar structureOf = (branch) => {\n  if (branch.hasKind(\"morph\"))\n    return null;\n  if (branch.hasKind(\"intersection\")) {\n    return branch.inner.structure ?? (branch.basis?.domain === \"object\" ? branch.$.bindReference($ark.intrinsic.emptyStructure) : null);\n  }\n  if (branch.isBasis() && branch.domain === \"object\")\n    return branch.$.bindReference($ark.intrinsic.emptyStructure);\n  return null;\n};\nvar writeLiteralUnionEntriesMessage = (expression) => `Props cannot be extracted from a union. Use .distribute to extract props from each branch instead. Received:\n${expression}`;\nvar writeNonStructuralOperandMessage = (operation, operand) => `${operation} operand must be an object (was ${operand})`;\n\n// ../schema/out/roots/utils.js\nvar defineRightwardIntersections = (kind, implementation23) => flatMorph(schemaKindsRightOf(kind), (i, kind2) => [\n  kind2,\n  implementation23\n]);\n\n// ../schema/out/roots/alias.js\nvar normalizeAliasSchema = (schema2) => typeof schema2 === \"string\" ? { reference: schema2 } : schema2;\nvar neverIfDisjoint = (result) => result instanceof Disjoint ? $ark.intrinsic.never.internal : result;\nvar implementation12 = implementNode({\n  kind: \"alias\",\n  hasAssociatedError: false,\n  collapsibleKey: \"reference\",\n  keys: {\n    reference: {\n      serialize: (s) => s.startsWith(\"$\") ? s : `$ark.${s}`\n    },\n    resolve: {}\n  },\n  normalize: normalizeAliasSchema,\n  defaults: {\n    description: (node2) => node2.reference\n  },\n  intersections: {\n    alias: (l, r, ctx) => ctx.$.lazilyResolve(() => neverIfDisjoint(intersectOrPipeNodes(l.resolution, r.resolution, ctx)), `${l.reference}${ctx.pipe ? \"=>\" : \"&\"}${r.reference}`),\n    ...defineRightwardIntersections(\"alias\", (l, r, ctx) => {\n      if (r.isUnknown())\n        return l;\n      if (r.isNever())\n        return r;\n      if (r.isBasis() && !r.overlaps($ark.intrinsic.object)) {\n        return Disjoint.init(\"assignability\", $ark.intrinsic.object, r);\n      }\n      return ctx.$.lazilyResolve(() => neverIfDisjoint(intersectOrPipeNodes(l.resolution, r, ctx)), `${l.reference}${ctx.pipe ? \"=>\" : \"&\"}${r.id}`);\n    })\n  }\n});\nvar AliasNode = class extends BaseRoot {\n  expression = this.reference;\n  structure = void 0;\n  get resolution() {\n    const result = this._resolve();\n    return nodesByRegisteredId[this.id] = result;\n  }\n  _resolve() {\n    if (this.resolve)\n      return this.resolve();\n    if (this.reference[0] === \"$\")\n      return this.$.resolveRoot(this.reference.slice(1));\n    const id = this.reference;\n    let resolution = nodesByRegisteredId[id];\n    const seen = [];\n    while (hasArkKind(resolution, \"context\")) {\n      if (seen.includes(resolution.id)) {\n        return throwParseError(writeShallowCycleErrorMessage(resolution.id, seen));\n      }\n      seen.push(resolution.id);\n      resolution = nodesByRegisteredId[resolution.id];\n    }\n    if (!hasArkKind(resolution, \"root\")) {\n      return throwInternalError(`Unexpected resolution for reference ${this.reference}\nSeen: [${seen.join(\"->\")}] \nResolution: ${printable(resolution)}`);\n    }\n    return resolution;\n  }\n  get resolutionId() {\n    if (this.reference.includes(\"&\") || this.reference.includes(\"=>\"))\n      return this.resolution.id;\n    if (this.reference[0] !== \"$\")\n      return this.reference;\n    const alias = this.reference.slice(1);\n    const resolution = this.$.resolutions[alias];\n    if (typeof resolution === \"string\")\n      return resolution;\n    if (hasArkKind(resolution, \"root\"))\n      return resolution.id;\n    return throwInternalError(`Unexpected resolution for reference ${this.reference}: ${printable(resolution)}`);\n  }\n  get defaultShortDescription() {\n    return domainDescriptions.object;\n  }\n  innerToJsonSchema() {\n    return JsonSchema.throwUnjsonifiableError(this.expression, \"cyclic\");\n  }\n  traverseAllows = (data, ctx) => {\n    const seen = ctx.seen[this.reference];\n    if (seen?.includes(data))\n      return true;\n    ctx.seen[this.reference] = append(seen, data);\n    return this.resolution.traverseAllows(data, ctx);\n  };\n  traverseApply = (data, ctx) => {\n    const seen = ctx.seen[this.reference];\n    if (seen?.includes(data))\n      return;\n    ctx.seen[this.reference] = append(seen, data);\n    this.resolution.traverseApply(data, ctx);\n  };\n  compile(js) {\n    const id = this.resolutionId;\n    js.if(`ctx.seen.${id} && ctx.seen.${id}.includes(data)`, () => js.return(true));\n    js.if(`!ctx.seen.${id}`, () => js.line(`ctx.seen.${id} = []`));\n    js.line(`ctx.seen.${id}.push(data)`);\n    js.return(js.invoke(id));\n  }\n};\nvar writeShallowCycleErrorMessage = (name, seen) => `Alias '${name}' has a shallow resolution cycle: ${[...seen, name].join(\"->\")}`;\nvar Alias = {\n  implementation: implementation12,\n  Node: AliasNode\n};\n\n// ../schema/out/roots/basis.js\nvar InternalBasis = class extends BaseRoot {\n  traverseApply = (data, ctx) => {\n    if (!this.traverseAllows(data, ctx))\n      ctx.errorFromNodeContext(this.errorContext);\n  };\n  get errorContext() {\n    return {\n      code: this.kind,\n      description: this.description,\n      meta: this.meta,\n      ...this.inner\n    };\n  }\n  get compiledErrorContext() {\n    return compileObjectLiteral(this.errorContext);\n  }\n  compile(js) {\n    if (js.traversalKind === \"Allows\")\n      js.return(this.compiledCondition);\n    else {\n      js.if(this.compiledNegation, () => js.line(`${js.ctx}.errorFromNodeContext(${this.compiledErrorContext})`));\n    }\n  }\n};\n\n// ../schema/out/roots/domain.js\nvar implementation13 = implementNode({\n  kind: \"domain\",\n  hasAssociatedError: true,\n  collapsibleKey: \"domain\",\n  keys: {\n    domain: {},\n    numberAllowsNaN: {}\n  },\n  normalize: (schema2) => typeof schema2 === \"string\" ? { domain: schema2 } : hasKey(schema2, \"numberAllowsNaN\") && schema2.domain !== \"number\" ? throwParseError(Domain.writeBadAllowNanMessage(schema2.domain)) : schema2,\n  applyConfig: (schema2, config) => schema2.numberAllowsNaN === void 0 && schema2.domain === \"number\" && config.numberAllowsNaN ? { ...schema2, numberAllowsNaN: true } : schema2,\n  defaults: {\n    description: (node2) => domainDescriptions[node2.domain],\n    actual: (data) => Number.isNaN(data) ? \"NaN\" : domainDescriptions[domainOf(data)]\n  },\n  intersections: {\n    domain: (l, r) => (\n      // since l === r is handled by default, remaining cases are disjoint\n      // outside those including options like numberAllowsNaN\n      l.domain === \"number\" && r.domain === \"number\" ? l.numberAllowsNaN ? r : l : Disjoint.init(\"domain\", l, r)\n    )\n  }\n});\nvar DomainNode = class extends InternalBasis {\n  requiresNaNCheck = this.domain === \"number\" && !this.numberAllowsNaN;\n  traverseAllows = this.requiresNaNCheck ? (data) => typeof data === \"number\" && !Number.isNaN(data) : (data) => domainOf(data) === this.domain;\n  compiledCondition = this.domain === \"object\" ? `((typeof data === \"object\" && data !== null) || typeof data === \"function\")` : `typeof data === \"${this.domain}\"${this.requiresNaNCheck ? \" && !Number.isNaN(data)\" : \"\"}`;\n  compiledNegation = this.domain === \"object\" ? `((typeof data !== \"object\" || data === null) && typeof data !== \"function\")` : `typeof data !== \"${this.domain}\"${this.requiresNaNCheck ? \" || Number.isNaN(data)\" : \"\"}`;\n  expression = this.numberAllowsNaN ? \"number | NaN\" : this.domain;\n  get nestableExpression() {\n    return this.numberAllowsNaN ? `(${this.expression})` : this.expression;\n  }\n  get defaultShortDescription() {\n    return domainDescriptions[this.domain];\n  }\n  innerToJsonSchema() {\n    if (this.domain === \"bigint\" || this.domain === \"symbol\")\n      return JsonSchema.throwUnjsonifiableError(this.domain);\n    return {\n      type: this.domain\n    };\n  }\n};\nvar Domain = {\n  implementation: implementation13,\n  Node: DomainNode,\n  writeBadAllowNanMessage: (actual) => `numberAllowsNaN may only be specified with domain \"number\" (was ${actual})`\n};\n\n// ../schema/out/roots/intersection.js\nvar implementation14 = implementNode({\n  kind: \"intersection\",\n  hasAssociatedError: true,\n  normalize: (rawSchema) => {\n    if (isNode(rawSchema))\n      return rawSchema;\n    const { structure, ...schema2 } = rawSchema;\n    const hasRootStructureKey = !!structure;\n    const normalizedStructure = structure ?? {};\n    const normalized = flatMorph(schema2, (k, v) => {\n      if (isKeyOf(k, structureKeys)) {\n        if (hasRootStructureKey) {\n          throwParseError(`Flattened structure key ${k} cannot be specified alongside a root 'structure' key.`);\n        }\n        normalizedStructure[k] = v;\n        return [];\n      }\n      return [k, v];\n    });\n    if (hasArkKind(normalizedStructure, \"constraint\") || !isEmptyObject(normalizedStructure))\n      normalized.structure = normalizedStructure;\n    return normalized;\n  },\n  finalizeInnerJson: ({ structure, ...rest }) => hasDomain(structure, \"object\") ? { ...structure, ...rest } : rest,\n  keys: {\n    domain: {\n      child: true,\n      parse: (schema2, ctx) => ctx.$.node(\"domain\", schema2)\n    },\n    proto: {\n      child: true,\n      parse: (schema2, ctx) => ctx.$.node(\"proto\", schema2)\n    },\n    structure: {\n      child: true,\n      parse: (schema2, ctx) => ctx.$.node(\"structure\", schema2),\n      serialize: (node2) => {\n        if (!node2.sequence?.minLength)\n          return node2.collapsibleJson;\n        const { sequence, ...structureJson } = node2.collapsibleJson;\n        const { minVariadicLength, ...sequenceJson } = sequence;\n        const collapsibleSequenceJson = sequenceJson.variadic && Object.keys(sequenceJson).length === 1 ? sequenceJson.variadic : sequenceJson;\n        return { ...structureJson, sequence: collapsibleSequenceJson };\n      }\n    },\n    divisor: {\n      child: true,\n      parse: constraintKeyParser(\"divisor\")\n    },\n    max: {\n      child: true,\n      parse: constraintKeyParser(\"max\")\n    },\n    min: {\n      child: true,\n      parse: constraintKeyParser(\"min\")\n    },\n    maxLength: {\n      child: true,\n      parse: constraintKeyParser(\"maxLength\")\n    },\n    minLength: {\n      child: true,\n      parse: constraintKeyParser(\"minLength\")\n    },\n    exactLength: {\n      child: true,\n      parse: constraintKeyParser(\"exactLength\")\n    },\n    before: {\n      child: true,\n      parse: constraintKeyParser(\"before\")\n    },\n    after: {\n      child: true,\n      parse: constraintKeyParser(\"after\")\n    },\n    pattern: {\n      child: true,\n      parse: constraintKeyParser(\"pattern\")\n    },\n    predicate: {\n      child: true,\n      parse: constraintKeyParser(\"predicate\")\n    }\n  },\n  // leverage reduction logic from intersection and identity to ensure initial\n  // parse result is reduced\n  reduce: (inner, $) => (\n    // we cast union out of the result here since that only occurs when intersecting two sequences\n    // that cannot occur when reducing a single intersection schema using unknown\n    intersectIntersections({}, inner, {\n      $,\n      invert: false,\n      pipe: false\n    })\n  ),\n  defaults: {\n    description: (node2) => {\n      if (node2.children.length === 0)\n        return \"unknown\";\n      if (node2.structure)\n        return node2.structure.description;\n      const childDescriptions = [];\n      if (node2.basis && !node2.refinements.some((r) => r.impl.obviatesBasisDescription))\n        childDescriptions.push(node2.basis.description);\n      if (node2.refinements.length) {\n        const sortedRefinementDescriptions = node2.refinements.toSorted((l, r) => l.kind === \"min\" && r.kind === \"max\" ? -1 : 0).map((r) => r.description);\n        childDescriptions.push(...sortedRefinementDescriptions);\n      }\n      if (node2.inner.predicate) {\n        childDescriptions.push(...node2.inner.predicate.map((p) => p.description));\n      }\n      return childDescriptions.join(\" and \");\n    },\n    expected: (source) => `  \\u25E6 ${source.errors.map((e) => e.expected).join(\"\\n  \\u25E6 \")}`,\n    problem: (ctx) => `(${ctx.actual}) must be...\n${ctx.expected}`\n  },\n  intersections: {\n    intersection: (l, r, ctx) => intersectIntersections(l.inner, r.inner, ctx),\n    ...defineRightwardIntersections(\"intersection\", (l, r, ctx) => {\n      if (l.children.length === 0)\n        return r;\n      const { domain, proto, ...lInnerConstraints } = l.inner;\n      const lBasis = proto ?? domain;\n      const basis = lBasis ? intersectOrPipeNodes(lBasis, r, ctx) : r;\n      return basis instanceof Disjoint ? basis : l?.basis?.equals(basis) ? (\n        // if the basis doesn't change, return the original intesection\n        l\n      ) : l.$.node(\"intersection\", { ...lInnerConstraints, [basis.kind]: basis }, { prereduced: true });\n    })\n  }\n});\nvar IntersectionNode = class extends BaseRoot {\n  basis = this.inner.domain ?? this.inner.proto ?? null;\n  refinements = this.children.filter((node2) => node2.isRefinement());\n  structure = this.inner.structure;\n  expression = writeIntersectionExpression(this);\n  get shallowMorphs() {\n    return this.inner.structure?.structuralMorph ? [this.inner.structure.structuralMorph] : [];\n  }\n  get defaultShortDescription() {\n    return this.basis?.defaultShortDescription ?? \"present\";\n  }\n  innerToJsonSchema() {\n    return this.children.reduce(\n      // cast is required since TS doesn't know children have compatible schema prerequisites\n      (schema2, child) => child.isBasis() ? child.toJsonSchema() : child.reduceJsonSchema(schema2),\n      {}\n    );\n  }\n  traverseAllows = (data, ctx) => this.children.every((child) => child.traverseAllows(data, ctx));\n  traverseApply = (data, ctx) => {\n    const errorCount = ctx.currentErrorCount;\n    if (this.basis) {\n      this.basis.traverseApply(data, ctx);\n      if (ctx.currentErrorCount > errorCount)\n        return;\n    }\n    if (this.refinements.length) {\n      for (let i = 0; i < this.refinements.length - 1; i++) {\n        this.refinements[i].traverseApply(data, ctx);\n        if (ctx.failFast && ctx.currentErrorCount > errorCount)\n          return;\n      }\n      this.refinements.at(-1).traverseApply(data, ctx);\n      if (ctx.currentErrorCount > errorCount)\n        return;\n    }\n    if (this.structure) {\n      this.structure.traverseApply(data, ctx);\n      if (ctx.currentErrorCount > errorCount)\n        return;\n    }\n    if (this.inner.predicate) {\n      for (let i = 0; i < this.inner.predicate.length - 1; i++) {\n        this.inner.predicate[i].traverseApply(data, ctx);\n        if (ctx.failFast && ctx.currentErrorCount > errorCount)\n          return;\n      }\n      this.inner.predicate.at(-1).traverseApply(data, ctx);\n    }\n  };\n  compile(js) {\n    if (js.traversalKind === \"Allows\") {\n      this.children.forEach((child) => js.check(child));\n      js.return(true);\n      return;\n    }\n    js.initializeErrorCount();\n    if (this.basis) {\n      js.check(this.basis);\n      if (this.children.length > 1)\n        js.returnIfFail();\n    }\n    if (this.refinements.length) {\n      for (let i = 0; i < this.refinements.length - 1; i++) {\n        js.check(this.refinements[i]);\n        js.returnIfFailFast();\n      }\n      js.check(this.refinements.at(-1));\n      if (this.structure || this.inner.predicate)\n        js.returnIfFail();\n    }\n    if (this.structure) {\n      js.check(this.structure);\n      if (this.inner.predicate)\n        js.returnIfFail();\n    }\n    if (this.inner.predicate) {\n      for (let i = 0; i < this.inner.predicate.length - 1; i++) {\n        js.check(this.inner.predicate[i]);\n        js.returnIfFail();\n      }\n      js.check(this.inner.predicate.at(-1));\n    }\n  }\n};\nvar Intersection = {\n  implementation: implementation14,\n  Node: IntersectionNode\n};\nvar writeIntersectionExpression = (node2) => {\n  let expression = node2.structure?.expression || `${node2.basis && !node2.refinements.some((n) => n.impl.obviatesBasisExpression) ? node2.basis.nestableExpression + \" \" : \"\"}${node2.refinements.map((n) => n.expression).join(\" & \")}` || \"unknown\";\n  if (expression === \"Array == 0\")\n    expression = \"[]\";\n  return expression;\n};\nvar intersectIntersections = (l, r, ctx) => {\n  const baseInner = {};\n  const lBasis = l.proto ?? l.domain;\n  const rBasis = r.proto ?? r.domain;\n  const basisResult = lBasis ? rBasis ? intersectOrPipeNodes(lBasis, rBasis, ctx) : lBasis : rBasis;\n  if (basisResult instanceof Disjoint)\n    return basisResult;\n  if (basisResult)\n    baseInner[basisResult.kind] = basisResult;\n  return intersectConstraints({\n    kind: \"intersection\",\n    baseInner,\n    l: flattenConstraints(l),\n    r: flattenConstraints(r),\n    roots: [],\n    ctx\n  });\n};\n\n// ../schema/out/roots/morph.js\nvar implementation15 = implementNode({\n  kind: \"morph\",\n  hasAssociatedError: false,\n  keys: {\n    in: {\n      child: true,\n      parse: (schema2, ctx) => ctx.$.parseSchema(schema2)\n    },\n    morphs: {\n      parse: liftArray,\n      serialize: (morphs) => morphs.map((m) => hasArkKind(m, \"root\") ? m.json : registeredReference(m))\n    },\n    declaredIn: {\n      child: false,\n      serialize: (node2) => node2.json\n    },\n    declaredOut: {\n      child: false,\n      serialize: (node2) => node2.json\n    }\n  },\n  normalize: (schema2) => schema2,\n  defaults: {\n    description: (node2) => `a morph from ${node2.in.description} to ${node2.out?.description ?? \"unknown\"}`\n  },\n  intersections: {\n    morph: (l, r, ctx) => {\n      if (!l.hasEqualMorphs(r)) {\n        return throwParseError(writeMorphIntersectionMessage(l.expression, r.expression));\n      }\n      const inTersection = intersectOrPipeNodes(l.in, r.in, ctx);\n      if (inTersection instanceof Disjoint)\n        return inTersection;\n      const baseInner = {\n        morphs: l.morphs\n      };\n      if (l.declaredIn || r.declaredIn) {\n        const declaredIn = intersectOrPipeNodes(l.in, r.in, ctx);\n        if (declaredIn instanceof Disjoint)\n          return declaredIn.throw();\n        else\n          baseInner.declaredIn = declaredIn;\n      }\n      if (l.declaredOut || r.declaredOut) {\n        const declaredOut = intersectOrPipeNodes(l.out, r.out, ctx);\n        if (declaredOut instanceof Disjoint)\n          return declaredOut.throw();\n        else\n          baseInner.declaredOut = declaredOut;\n      }\n      return inTersection.distribute((inBranch) => ctx.$.node(\"morph\", {\n        ...baseInner,\n        in: inBranch\n      }), ctx.$.parseSchema);\n    },\n    ...defineRightwardIntersections(\"morph\", (l, r, ctx) => {\n      const inTersection = l.inner.in ? intersectOrPipeNodes(l.inner.in, r, ctx) : r;\n      return inTersection instanceof Disjoint ? inTersection : inTersection.equals(l.inner.in) ? l : ctx.$.node(\"morph\", {\n        ...l.inner,\n        in: inTersection\n      });\n    })\n  }\n});\nvar MorphNode = class extends BaseRoot {\n  serializedMorphs = this.morphs.map(registeredReference);\n  compiledMorphs = `[${this.serializedMorphs}]`;\n  lastMorph = this.inner.morphs.at(-1);\n  lastMorphIfNode = hasArkKind(this.lastMorph, \"root\") ? this.lastMorph : void 0;\n  introspectableIn = this.inner.in;\n  introspectableOut = this.lastMorphIfNode ? Object.assign(this.referencesById, this.lastMorphIfNode.referencesById) && this.lastMorphIfNode.out : void 0;\n  get shallowMorphs() {\n    return Array.isArray(this.inner.in?.shallowMorphs) ? [...this.inner.in.shallowMorphs, ...this.morphs] : this.morphs;\n  }\n  get in() {\n    return this.declaredIn ?? this.inner.in?.in ?? $ark.intrinsic.unknown.internal;\n  }\n  get out() {\n    return this.declaredOut ?? this.introspectableOut ?? $ark.intrinsic.unknown.internal;\n  }\n  declareIn(declaredIn) {\n    return this.$.node(\"morph\", {\n      ...this.inner,\n      declaredIn\n    });\n  }\n  declareOut(declaredOut) {\n    return this.$.node(\"morph\", {\n      ...this.inner,\n      declaredOut\n    });\n  }\n  expression = `(In: ${this.in.expression}) => ${this.lastMorphIfNode ? \"To\" : \"Out\"}<${this.out.expression}>`;\n  get defaultShortDescription() {\n    return this.in.meta.description ?? this.in.defaultShortDescription;\n  }\n  innerToJsonSchema() {\n    return JsonSchema.throwUnjsonifiableError(this.expression, \"morph\");\n  }\n  compile(js) {\n    if (js.traversalKind === \"Allows\") {\n      if (!this.introspectableIn)\n        return;\n      js.return(js.invoke(this.introspectableIn));\n      return;\n    }\n    if (this.introspectableIn)\n      js.line(js.invoke(this.introspectableIn));\n    js.line(`ctx.queueMorphs(${this.compiledMorphs})`);\n  }\n  traverseAllows = (data, ctx) => !this.introspectableIn || this.introspectableIn.traverseAllows(data, ctx);\n  traverseApply = (data, ctx) => {\n    if (this.introspectableIn)\n      this.introspectableIn.traverseApply(data, ctx);\n    ctx.queueMorphs(this.morphs);\n  };\n  /** Check if the morphs of r are equal to those of this node */\n  hasEqualMorphs(r) {\n    return arrayEquals(this.morphs, r.morphs, {\n      isEqual: (lMorph, rMorph) => lMorph === rMorph || hasArkKind(lMorph, \"root\") && hasArkKind(rMorph, \"root\") && lMorph.equals(rMorph)\n    });\n  }\n};\nvar Morph = {\n  implementation: implementation15,\n  Node: MorphNode\n};\nvar writeMorphIntersectionMessage = (lDescription, rDescription) => `The intersection of distinct morphs at a single path is indeterminate:\nLeft: ${lDescription}\nRight: ${rDescription}`;\n\n// ../schema/out/roots/proto.js\nvar implementation16 = implementNode({\n  kind: \"proto\",\n  hasAssociatedError: true,\n  collapsibleKey: \"proto\",\n  keys: {\n    proto: {\n      serialize: (ctor) => getBuiltinNameOfConstructor(ctor) ?? defaultValueSerializer(ctor)\n    },\n    dateAllowsInvalid: {}\n  },\n  normalize: (schema2) => {\n    const normalized = typeof schema2 === \"string\" ? { proto: builtinConstructors[schema2] } : typeof schema2 === \"function\" ? isNode(schema2) ? schema2 : { proto: schema2 } : typeof schema2.proto === \"string\" ? { ...schema2, proto: builtinConstructors[schema2.proto] } : schema2;\n    if (typeof normalized.proto !== \"function\")\n      throwParseError(Proto.writeInvalidSchemaMessage(normalized.proto));\n    if (hasKey(normalized, \"dateAllowsInvalid\") && normalized.proto !== Date)\n      throwParseError(Proto.writeBadInvalidDateMessage(normalized.proto));\n    return normalized;\n  },\n  applyConfig: (schema2, config) => {\n    if (schema2.dateAllowsInvalid === void 0 && schema2.proto === Date && config.dateAllowsInvalid)\n      return { ...schema2, dateAllowsInvalid: true };\n    return schema2;\n  },\n  defaults: {\n    description: (node2) => node2.builtinName ? objectKindDescriptions[node2.builtinName] : `an instance of ${node2.proto.name}`,\n    actual: (data) => data instanceof Date && data.toString() === \"Invalid Date\" ? \"an invalid Date\" : objectKindOrDomainOf(data)\n  },\n  intersections: {\n    proto: (l, r) => l.proto === Date && r.proto === Date ? (\n      // since l === r is handled by default,\n      // exactly one of l or r must have allow invalid dates\n      l.dateAllowsInvalid ? r : l\n    ) : constructorExtends(l.proto, r.proto) ? l : constructorExtends(r.proto, l.proto) ? r : Disjoint.init(\"proto\", l, r),\n    domain: (proto, domain) => domain.domain === \"object\" ? proto : Disjoint.init(\"domain\", $ark.intrinsic.object.internal, domain)\n  }\n});\nvar ProtoNode = class extends InternalBasis {\n  builtinName = getBuiltinNameOfConstructor(this.proto);\n  serializedConstructor = this.json.proto;\n  requiresInvalidDateCheck = this.proto === Date && !this.dateAllowsInvalid;\n  traverseAllows = this.requiresInvalidDateCheck ? (data) => data instanceof Date && data.toString() !== \"Invalid Date\" : (data) => data instanceof this.proto;\n  compiledCondition = `data instanceof ${this.serializedConstructor}${this.requiresInvalidDateCheck ? ` && data.toString() !== \"Invalid Date\"` : \"\"}`;\n  compiledNegation = `!(${this.compiledCondition})`;\n  innerToJsonSchema() {\n    switch (this.builtinName) {\n      case \"Array\":\n        return {\n          type: \"array\"\n        };\n      default:\n        return JsonSchema.throwUnjsonifiableError(this.description);\n    }\n  }\n  expression = this.dateAllowsInvalid ? \"Date | InvalidDate\" : this.proto.name;\n  get nestableExpression() {\n    return this.dateAllowsInvalid ? `(${this.expression})` : this.expression;\n  }\n  domain = \"object\";\n  get defaultShortDescription() {\n    return this.description;\n  }\n};\nvar Proto = {\n  implementation: implementation16,\n  Node: ProtoNode,\n  writeBadInvalidDateMessage: (actual) => `dateAllowsInvalid may only be specified with constructor Date (was ${actual.name})`,\n  writeInvalidSchemaMessage: (actual) => `instanceOf operand must be a function (was ${domainOf(actual)})`\n};\n\n// ../schema/out/roots/union.js\nvar implementation17 = implementNode({\n  kind: \"union\",\n  hasAssociatedError: true,\n  collapsibleKey: \"branches\",\n  keys: {\n    ordered: {},\n    branches: {\n      child: true,\n      parse: (schema2, ctx) => {\n        const branches = [];\n        schema2.forEach((branchSchema) => {\n          const branchNodes = hasArkKind(branchSchema, \"root\") ? branchSchema.branches : ctx.$.parseSchema(branchSchema).branches;\n          branchNodes.forEach((node2) => {\n            if (node2.hasKind(\"morph\")) {\n              const matchingMorphIndex = branches.findIndex((matching) => matching.hasKind(\"morph\") && matching.hasEqualMorphs(node2));\n              if (matchingMorphIndex === -1)\n                branches.push(node2);\n              else {\n                const matchingMorph = branches[matchingMorphIndex];\n                branches[matchingMorphIndex] = ctx.$.node(\"morph\", {\n                  ...matchingMorph.inner,\n                  in: matchingMorph.in.rawOr(node2.in)\n                });\n              }\n            } else\n              branches.push(node2);\n          });\n        });\n        if (!ctx.def.ordered)\n          branches.sort((l, r) => l.hash < r.hash ? -1 : 1);\n        return branches;\n      }\n    }\n  },\n  normalize: (schema2) => isArray(schema2) ? { branches: schema2 } : schema2,\n  reduce: (inner, $) => {\n    const reducedBranches = reduceBranches(inner);\n    if (reducedBranches.length === 1)\n      return reducedBranches[0];\n    if (reducedBranches.length === inner.branches.length)\n      return;\n    return $.node(\"union\", {\n      ...inner,\n      branches: reducedBranches\n    }, { prereduced: true });\n  },\n  defaults: {\n    description: (node2) => node2.distribute((branch) => branch.description, describeBranches),\n    expected: (ctx) => {\n      const byPath = groupBy(ctx.errors, \"propString\");\n      const pathDescriptions = Object.entries(byPath).map(([path, errors]) => {\n        const branchesAtPath = [];\n        errors.forEach((errorAtPath) => (\n          // avoid duplicate messages when multiple branches\n          // are invalid due to the same error\n          appendUnique(branchesAtPath, errorAtPath.expected)\n        ));\n        const expected = describeBranches(branchesAtPath);\n        const actual = errors.every((e) => e.actual === errors[0].actual) ? errors[0].actual : printable(errors[0].data);\n        return `${path && `${path} `}must be ${expected}${actual && ` (was ${actual})`}`;\n      });\n      return describeBranches(pathDescriptions);\n    },\n    problem: (ctx) => ctx.expected,\n    message: (ctx) => ctx.problem\n  },\n  intersections: {\n    union: (l, r, ctx) => {\n      if (l.isNever !== r.isNever) {\n        return Disjoint.init(\"presence\", l, r);\n      }\n      let resultBranches;\n      if (l.ordered) {\n        if (r.ordered) {\n          throwParseError(writeOrderedIntersectionMessage(l.expression, r.expression));\n        }\n        resultBranches = intersectBranches(r.branches, l.branches, ctx);\n        if (resultBranches instanceof Disjoint)\n          resultBranches.invert();\n      } else\n        resultBranches = intersectBranches(l.branches, r.branches, ctx);\n      if (resultBranches instanceof Disjoint)\n        return resultBranches;\n      return ctx.$.parseSchema(l.ordered || r.ordered ? {\n        branches: resultBranches,\n        ordered: true\n      } : { branches: resultBranches });\n    },\n    ...defineRightwardIntersections(\"union\", (l, r, ctx) => {\n      const branches = intersectBranches(l.branches, [r], ctx);\n      if (branches instanceof Disjoint)\n        return branches;\n      if (branches.length === 1)\n        return branches[0];\n      return ctx.$.parseSchema(l.ordered ? { branches, ordered: true } : { branches });\n    })\n  }\n});\nvar UnionNode = class extends BaseRoot {\n  isBoolean = this.branches.length === 2 && this.branches[0].hasUnit(false) && this.branches[1].hasUnit(true);\n  get branchGroups() {\n    const branchGroups = [];\n    let firstBooleanIndex = -1;\n    this.branches.forEach((branch) => {\n      if (branch.hasKind(\"unit\") && branch.domain === \"boolean\") {\n        if (firstBooleanIndex === -1) {\n          firstBooleanIndex = branchGroups.length;\n          branchGroups.push(branch);\n        } else\n          branchGroups[firstBooleanIndex] = $ark.intrinsic.boolean;\n        return;\n      }\n      branchGroups.push(branch);\n    });\n    return branchGroups;\n  }\n  unitBranches = this.branches.filter((n) => n.in.hasKind(\"unit\"));\n  discriminant = this.discriminate();\n  discriminantJson = this.discriminant ? discriminantToJson(this.discriminant) : null;\n  expression = this.distribute((n) => n.nestableExpression, expressBranches);\n  createBranchedOptimisticRootApply() {\n    return (data, onFail) => {\n      const optimisticResult = this.traverseOptimistic(data);\n      if (optimisticResult !== unset)\n        return optimisticResult;\n      const ctx = new Traversal(data, this.$.resolvedConfig);\n      this.traverseApply(data, ctx);\n      return ctx.finalize(onFail);\n    };\n  }\n  get shallowMorphs() {\n    return this.branches.reduce((morphs, branch) => appendUnique(morphs, branch.shallowMorphs), []);\n  }\n  get defaultShortDescription() {\n    return this.distribute((branch) => branch.defaultShortDescription, describeBranches);\n  }\n  innerToJsonSchema() {\n    if (this.branchGroups.length === 1 && this.branchGroups[0].equals($ark.intrinsic.boolean))\n      return { type: \"boolean\" };\n    return {\n      anyOf: this.branchGroups.map((group) => group.toJsonSchema())\n    };\n  }\n  traverseAllows = (data, ctx) => this.branches.some((b) => b.traverseAllows(data, ctx));\n  traverseApply = (data, ctx) => {\n    const errors = [];\n    for (let i = 0; i < this.branches.length; i++) {\n      ctx.pushBranch();\n      this.branches[i].traverseApply(data, ctx);\n      if (!ctx.hasError()) {\n        if (this.branches[i].includesTransform)\n          return ctx.queuedMorphs.push(...ctx.popBranch().queuedMorphs);\n        return ctx.popBranch();\n      }\n      errors.push(ctx.popBranch().error);\n    }\n    ctx.errorFromNodeContext({ code: \"union\", errors, meta: this.meta });\n  };\n  traverseOptimistic = (data) => {\n    for (let i = 0; i < this.branches.length; i++) {\n      const branch = this.branches[i];\n      if (branch.traverseAllows(data)) {\n        if (branch.contextFreeMorph)\n          return branch.contextFreeMorph(data);\n        return data;\n      }\n    }\n    return unset;\n  };\n  compile(js) {\n    if (!this.discriminant || // if we have a union of two units like `boolean`, the\n    // undiscriminated compilation will be just as fast\n    this.unitBranches.length === this.branches.length && this.branches.length === 2)\n      return this.compileIndiscriminable(js);\n    let condition = this.discriminant.optionallyChainedPropString;\n    if (this.discriminant.kind === \"domain\")\n      condition = `typeof ${condition} === \"object\" ? ${condition} === null ? \"null\" : \"object\" : typeof ${condition} === \"function\" ? \"object\" : typeof ${condition}`;\n    const cases = this.discriminant.cases;\n    const caseKeys = Object.keys(cases);\n    const { optimistic } = js;\n    js.optimistic = false;\n    js.block(`switch(${condition})`, () => {\n      for (const k in cases) {\n        const v = cases[k];\n        const caseCondition = k === \"default\" ? k : `case ${k}`;\n        js.line(`${caseCondition}: return ${v === true ? optimistic ? js.data : v : optimistic ? `${js.invoke(v)} ? ${v.contextFreeMorph ? `${registeredReference(v.contextFreeMorph)}(${js.data})` : js.data} : \"${unset}\"` : js.invoke(v)}`);\n      }\n      return js;\n    });\n    if (js.traversalKind === \"Allows\") {\n      js.return(optimistic ? `\"${unset}\"` : false);\n      return;\n    }\n    const expected = describeBranches(this.discriminant.kind === \"domain\" ? caseKeys.map((k) => {\n      const jsTypeOf = k.slice(1, -1);\n      return jsTypeOf === \"function\" ? domainDescriptions.object : domainDescriptions[jsTypeOf];\n    }) : caseKeys);\n    const serializedPathSegments = this.discriminant.path.map((k) => typeof k === \"symbol\" ? registeredReference(k) : JSON.stringify(k));\n    const serializedExpected = JSON.stringify(expected);\n    const serializedActual = this.discriminant.kind === \"domain\" ? `${serializedTypeOfDescriptions}[${condition}]` : `${serializedPrintable}(${condition})`;\n    js.line(`ctx.errorFromNodeContext({\n\tcode: \"predicate\",\n\texpected: ${serializedExpected},\n\tactual: ${serializedActual},\n\trelativePath: [${serializedPathSegments}],\n\tmeta: ${this.compiledMeta}\n})`);\n  }\n  compileIndiscriminable(js) {\n    if (js.traversalKind === \"Apply\") {\n      js.const(\"errors\", \"[]\");\n      this.branches.forEach((branch) => js.line(\"ctx.pushBranch()\").line(js.invoke(branch)).if(\"!ctx.hasError()\", () => js.return(branch.includesTransform ? \"ctx.queuedMorphs.push(...ctx.popBranch().queuedMorphs)\" : \"ctx.popBranch()\")).line(\"errors.push(ctx.popBranch().error)\"));\n      js.line(`ctx.errorFromNodeContext({ code: \"union\", errors, meta: ${this.compiledMeta} })`);\n    } else {\n      const { optimistic } = js;\n      js.optimistic = false;\n      this.branches.forEach((branch) => js.if(`${js.invoke(branch)}`, () => js.return(optimistic ? branch.contextFreeMorph ? `${registeredReference(branch.contextFreeMorph)}(${js.data})` : js.data : true)));\n      js.return(optimistic ? `\"${unset}\"` : false);\n    }\n  }\n  get nestableExpression() {\n    return this.isBoolean ? \"boolean\" : `(${this.expression})`;\n  }\n  discriminate() {\n    if (this.branches.length < 2)\n      return null;\n    if (this.unitBranches.length === this.branches.length) {\n      const cases2 = flatMorph(this.unitBranches, (i, n) => [\n        `${n.in.serializedValue}`,\n        n.hasKind(\"morph\") ? n : true\n      ]);\n      return {\n        kind: \"unit\",\n        path: [],\n        optionallyChainedPropString: \"data\",\n        cases: cases2\n      };\n    }\n    const candidates = [];\n    for (let lIndex = 0; lIndex < this.branches.length - 1; lIndex++) {\n      const l = this.branches[lIndex];\n      for (let rIndex = lIndex + 1; rIndex < this.branches.length; rIndex++) {\n        const r = this.branches[rIndex];\n        const result = intersectNodesRoot(l.in, r.in, l.$);\n        if (!(result instanceof Disjoint))\n          continue;\n        for (const entry of result) {\n          if (!entry.kind || entry.optional)\n            continue;\n          let lSerialized;\n          let rSerialized;\n          if (entry.kind === \"domain\") {\n            const lValue = entry.l;\n            const rValue = entry.r;\n            lSerialized = `\"${typeof lValue === \"string\" ? lValue : lValue.domain}\"`;\n            rSerialized = `\"${typeof rValue === \"string\" ? rValue : rValue.domain}\"`;\n          } else if (entry.kind === \"unit\") {\n            lSerialized = entry.l.serializedValue;\n            rSerialized = entry.r.serializedValue;\n          } else\n            continue;\n          const matching = candidates.find((d) => arrayEquals(d.path, entry.path) && d.kind === entry.kind);\n          if (!matching) {\n            candidates.push({\n              kind: entry.kind,\n              cases: {\n                [lSerialized]: {\n                  branchIndices: [lIndex],\n                  condition: entry.l\n                },\n                [rSerialized]: {\n                  branchIndices: [rIndex],\n                  condition: entry.r\n                }\n              },\n              path: entry.path\n            });\n          } else {\n            if (matching.cases[lSerialized]) {\n              matching.cases[lSerialized].branchIndices = appendUnique(matching.cases[lSerialized].branchIndices, lIndex);\n            } else {\n              matching.cases[lSerialized] ??= {\n                branchIndices: [lIndex],\n                condition: entry.l\n              };\n            }\n            if (matching.cases[rSerialized]) {\n              matching.cases[rSerialized].branchIndices = appendUnique(matching.cases[rSerialized].branchIndices, rIndex);\n            } else {\n              matching.cases[rSerialized] ??= {\n                branchIndices: [rIndex],\n                condition: entry.r\n              };\n            }\n          }\n        }\n      }\n    }\n    const orderedCandidates = this.ordered ? orderCandidates(candidates, this.branches) : candidates;\n    if (!orderedCandidates.length)\n      return null;\n    const ctx = createCaseResolutionContext(orderedCandidates, this);\n    const cases = {};\n    for (const k in ctx.best.cases) {\n      const resolution = resolveCase(ctx, k);\n      if (resolution === null) {\n        cases[k] = true;\n        continue;\n      }\n      if (resolution.length === this.branches.length)\n        return null;\n      if (this.ordered) {\n        resolution.sort((l, r) => l.originalIndex - r.originalIndex);\n      }\n      const branches = resolution.map((entry) => entry.branch);\n      const caseNode = branches.length === 1 ? branches[0] : this.$.node(\"union\", this.ordered ? { branches, ordered: true } : branches);\n      Object.assign(this.referencesById, caseNode.referencesById);\n      cases[k] = caseNode;\n    }\n    if (ctx.defaultEntries.length) {\n      const branches = ctx.defaultEntries.map((entry) => entry.branch);\n      cases.default = this.$.node(\"union\", this.ordered ? { branches, ordered: true } : branches, {\n        prereduced: true\n      });\n      Object.assign(this.referencesById, cases.default.referencesById);\n    }\n    return Object.assign(ctx.location, {\n      cases\n    });\n  }\n};\nvar createCaseResolutionContext = (orderedCandidates, node2) => {\n  const best = orderedCandidates.sort((l, r) => Object.keys(r.cases).length - Object.keys(l.cases).length)[0];\n  const location = {\n    kind: best.kind,\n    path: best.path,\n    optionallyChainedPropString: optionallyChainPropString(best.path)\n  };\n  const defaultEntries = node2.branches.map((branch, originalIndex) => ({\n    originalIndex,\n    branch\n  }));\n  return {\n    best,\n    location,\n    defaultEntries,\n    node: node2\n  };\n};\nvar resolveCase = (ctx, key) => {\n  const caseCtx = ctx.best.cases[key];\n  const discriminantNode = discriminantCaseToNode(caseCtx.condition, ctx.location.path, ctx.node.$);\n  let resolvedEntries = [];\n  const nextDefaults = [];\n  for (let i = 0; i < ctx.defaultEntries.length; i++) {\n    const entry = ctx.defaultEntries[i];\n    if (caseCtx.branchIndices.includes(entry.originalIndex)) {\n      const pruned = pruneDiscriminant(ctx.node.branches[entry.originalIndex], ctx.location);\n      if (pruned === null) {\n        resolvedEntries = null;\n      } else {\n        resolvedEntries?.push({\n          originalIndex: entry.originalIndex,\n          branch: pruned\n        });\n      }\n    } else if (\n      // we shouldn't need a special case for alias to avoid the below\n      // once alias resolution issues are improved:\n      // https://github.com/arktypeio/arktype/issues/1026\n      entry.branch.hasKind(\"alias\") && discriminantNode.hasKind(\"domain\") && discriminantNode.domain === \"object\"\n    )\n      resolvedEntries?.push(entry);\n    else {\n      if (entry.branch.in.overlaps(discriminantNode)) {\n        const overlapping = pruneDiscriminant(entry.branch, ctx.location);\n        resolvedEntries?.push({\n          originalIndex: entry.originalIndex,\n          branch: overlapping\n        });\n      }\n      nextDefaults.push(entry);\n    }\n  }\n  ctx.defaultEntries = nextDefaults;\n  return resolvedEntries;\n};\nvar orderCandidates = (candidates, originalBranches) => {\n  const viableCandidates = candidates.filter((candidate) => {\n    const caseGroups = Object.values(candidate.cases).map((caseCtx) => caseCtx.branchIndices);\n    for (let i = 0; i < caseGroups.length - 1; i++) {\n      const currentGroup = caseGroups[i];\n      for (let j = i + 1; j < caseGroups.length; j++) {\n        const nextGroup = caseGroups[j];\n        for (const currentIndex of currentGroup) {\n          for (const nextIndex of nextGroup) {\n            if (currentIndex > nextIndex) {\n              if (originalBranches[currentIndex].overlaps(originalBranches[nextIndex])) {\n                return false;\n              }\n            }\n          }\n        }\n      }\n    }\n    return true;\n  });\n  return viableCandidates;\n};\nvar discriminantCaseToNode = (caseDiscriminant, path, $) => {\n  let node2 = caseDiscriminant === \"undefined\" ? $.node(\"unit\", { unit: void 0 }) : caseDiscriminant === \"null\" ? $.node(\"unit\", { unit: null }) : caseDiscriminant === \"boolean\" ? $.units([true, false]) : caseDiscriminant;\n  for (let i = path.length - 1; i >= 0; i--) {\n    const key = path[i];\n    node2 = $.node(\"intersection\", typeof key === \"number\" ? {\n      proto: \"Array\",\n      // create unknown for preceding elements (could be optimized with safe imports)\n      sequence: [...range(key).map((_) => ({})), node2]\n    } : {\n      domain: \"object\",\n      required: [{ key, value: node2 }]\n    });\n  }\n  return node2;\n};\nvar optionallyChainPropString = (path) => path.reduce((acc, k) => acc + compileLiteralPropAccess(k, true), \"data\");\nvar serializedTypeOfDescriptions = registeredReference(jsTypeOfDescriptions);\nvar serializedPrintable = registeredReference(printable);\nvar Union = {\n  implementation: implementation17,\n  Node: UnionNode\n};\nvar discriminantToJson = (discriminant) => ({\n  kind: discriminant.kind,\n  path: discriminant.path.map((k) => typeof k === \"string\" ? k : compileSerializedValue(k)),\n  cases: flatMorph(discriminant.cases, (k, node2) => [\n    k,\n    node2 === true ? node2 : node2.hasKind(\"union\") && node2.discriminantJson ? node2.discriminantJson : node2.json\n  ])\n});\nvar describeExpressionOptions = {\n  delimiter: \" | \",\n  finalDelimiter: \" | \"\n};\nvar expressBranches = (expressions) => describeBranches(expressions, describeExpressionOptions);\nvar describeBranches = (descriptions, opts) => {\n  const delimiter = opts?.delimiter ?? \", \";\n  const finalDelimiter = opts?.finalDelimiter ?? \" or \";\n  if (descriptions.length === 0)\n    return \"never\";\n  if (descriptions.length === 1)\n    return descriptions[0];\n  if (descriptions.length === 2 && descriptions[0] === \"false\" && descriptions[1] === \"true\" || descriptions[0] === \"true\" && descriptions[1] === \"false\")\n    return \"boolean\";\n  const seen = {};\n  const unique = descriptions.filter((s) => seen[s] ? false : seen[s] = true);\n  const last = unique.pop();\n  return `${unique.join(delimiter)}${unique.length ? finalDelimiter : \"\"}${last}`;\n};\nvar intersectBranches = (l, r, ctx) => {\n  const batchesByR = r.map(() => []);\n  for (let lIndex = 0; lIndex < l.length; lIndex++) {\n    let candidatesByR = {};\n    for (let rIndex = 0; rIndex < r.length; rIndex++) {\n      if (batchesByR[rIndex] === null) {\n        continue;\n      }\n      if (l[lIndex].equals(r[rIndex])) {\n        batchesByR[rIndex] = null;\n        candidatesByR = {};\n        break;\n      }\n      const branchIntersection = intersectOrPipeNodes(l[lIndex], r[rIndex], ctx);\n      if (branchIntersection instanceof Disjoint) {\n        continue;\n      }\n      if (branchIntersection.equals(l[lIndex])) {\n        batchesByR[rIndex].push(l[lIndex]);\n        candidatesByR = {};\n        break;\n      }\n      if (branchIntersection.equals(r[rIndex])) {\n        batchesByR[rIndex] = null;\n      } else {\n        candidatesByR[rIndex] = branchIntersection;\n      }\n    }\n    for (const rIndex in candidatesByR) {\n      batchesByR[rIndex][lIndex] = candidatesByR[rIndex];\n    }\n  }\n  const resultBranches = batchesByR.flatMap(\n    // ensure unions returned from branchable intersections like sequence are flattened\n    (batch, i) => batch?.flatMap((branch) => branch.branches) ?? r[i]\n  );\n  return resultBranches.length === 0 ? Disjoint.init(\"union\", l, r) : resultBranches;\n};\nvar reduceBranches = ({ branches, ordered }) => {\n  if (branches.length < 2)\n    return branches;\n  const uniquenessByIndex = branches.map(() => true);\n  for (let i = 0; i < branches.length; i++) {\n    for (let j = i + 1; j < branches.length && uniquenessByIndex[i] && uniquenessByIndex[j]; j++) {\n      if (branches[i].equals(branches[j])) {\n        uniquenessByIndex[j] = false;\n        continue;\n      }\n      const intersection = intersectNodesRoot(branches[i].in, branches[j].in, branches[0].$);\n      if (intersection instanceof Disjoint)\n        continue;\n      if (!ordered)\n        assertDeterminateOverlap(branches[i], branches[j]);\n      if (intersection.equals(branches[i].in)) {\n        uniquenessByIndex[i] = !!ordered;\n      } else if (intersection.equals(branches[j].in))\n        uniquenessByIndex[j] = false;\n    }\n  }\n  return branches.filter((_, i) => uniquenessByIndex[i]);\n};\nvar assertDeterminateOverlap = (l, r) => {\n  if (!l.includesTransform && !r.includesTransform)\n    return;\n  if (!arrayEquals(l.shallowMorphs, r.shallowMorphs)) {\n    throwParseError(writeIndiscriminableMorphMessage(l.expression, r.expression));\n  }\n  if (!arrayEquals(l.flatMorphs, r.flatMorphs, {\n    isEqual: (l2, r2) => l2.propString === r2.propString && (l2.node.hasKind(\"morph\") && r2.node.hasKind(\"morph\") ? l2.node.hasEqualMorphs(r2.node) : l2.node.hasKind(\"intersection\") && r2.node.hasKind(\"intersection\") ? l2.node.structure?.structuralMorphRef === r2.node.structure?.structuralMorphRef : false)\n  })) {\n    throwParseError(writeIndiscriminableMorphMessage(l.expression, r.expression));\n  }\n};\nvar pruneDiscriminant = (discriminantBranch, discriminantCtx) => discriminantBranch.transform((nodeKind, inner) => {\n  if (nodeKind === \"domain\" || nodeKind === \"unit\")\n    return null;\n  return inner;\n}, {\n  shouldTransform: (node2, ctx) => {\n    const propString = optionallyChainPropString(ctx.path);\n    if (!discriminantCtx.optionallyChainedPropString.startsWith(propString))\n      return false;\n    if (node2.hasKind(\"domain\") && node2.domain === \"object\")\n      return true;\n    if ((node2.hasKind(\"domain\") || discriminantCtx.kind === \"unit\") && propString === discriminantCtx.optionallyChainedPropString)\n      return true;\n    return node2.children.length !== 0 && node2.kind !== \"index\";\n  }\n});\nvar writeIndiscriminableMorphMessage = (lDescription, rDescription) => `An unordered union of a type including a morph and a type with overlapping input is indeterminate:\nLeft: ${lDescription}\nRight: ${rDescription}`;\nvar writeOrderedIntersectionMessage = (lDescription, rDescription) => `The intersection of two ordered unions is indeterminate:\nLeft: ${lDescription}\nRight: ${rDescription}`;\n\n// ../schema/out/roots/unit.js\nvar implementation18 = implementNode({\n  kind: \"unit\",\n  hasAssociatedError: true,\n  keys: {\n    unit: {\n      preserveUndefined: true,\n      serialize: (schema2) => schema2 instanceof Date ? schema2.toISOString() : defaultValueSerializer(schema2)\n    }\n  },\n  normalize: (schema2) => schema2,\n  defaults: {\n    description: (node2) => printable(node2.unit),\n    problem: ({ expected, actual }) => `${expected === actual ? `must be reference equal to ${expected} (serialized to the same value)` : `must be ${expected} (was ${actual})`}`\n  },\n  intersections: {\n    unit: (l, r) => Disjoint.init(\"unit\", l, r),\n    ...defineRightwardIntersections(\"unit\", (l, r) => {\n      if (r.allows(l.unit))\n        return l;\n      const rBasis = r.hasKind(\"intersection\") ? r.basis : r;\n      if (rBasis) {\n        const rDomain = rBasis.hasKind(\"domain\") ? rBasis : $ark.intrinsic.object;\n        if (l.domain !== rDomain.domain) {\n          const lDomainDisjointValue = l.domain === \"undefined\" || l.domain === \"null\" || l.domain === \"boolean\" ? l.domain : $ark.intrinsic[l.domain];\n          return Disjoint.init(\"domain\", lDomainDisjointValue, rDomain);\n        }\n      }\n      return Disjoint.init(\"assignability\", l, r.hasKind(\"intersection\") ? r.children.find((rConstraint) => !rConstraint.allows(l.unit)) : r);\n    })\n  }\n});\nvar UnitNode = class extends InternalBasis {\n  compiledValue = this.json.unit;\n  serializedValue = typeof this.unit === \"string\" || this.unit instanceof Date ? JSON.stringify(this.compiledValue) : `${this.compiledValue}`;\n  compiledCondition = compileEqualityCheck(this.unit, this.serializedValue);\n  compiledNegation = compileEqualityCheck(this.unit, this.serializedValue, \"negated\");\n  expression = printable(this.unit);\n  domain = domainOf(this.unit);\n  get defaultShortDescription() {\n    return this.domain === \"object\" ? domainDescriptions.object : this.description;\n  }\n  innerToJsonSchema() {\n    return $ark.intrinsic.jsonPrimitive.allows(this.unit) ? { const: this.unit } : JsonSchema.throwUnjsonifiableError(this.defaultShortDescription);\n  }\n  traverseAllows = this.unit instanceof Date ? (data) => data instanceof Date && data.toISOString() === this.compiledValue : Number.isNaN(this.unit) ? (data) => Number.isNaN(data) : (data) => data === this.unit;\n};\nvar Unit = {\n  implementation: implementation18,\n  Node: UnitNode\n};\nvar compileEqualityCheck = (unit, serializedValue, negated) => {\n  if (unit instanceof Date) {\n    const condition = `data instanceof Date && data.toISOString() === ${serializedValue}`;\n    return negated ? `!(${condition})` : condition;\n  }\n  if (Number.isNaN(unit))\n    return `${negated ? \"!\" : \"\"}Number.isNaN(data)`;\n  return `data ${negated ? \"!\" : \"=\"}== ${serializedValue}`;\n};\n\n// ../schema/out/structure/index.js\nvar implementation19 = implementNode({\n  kind: \"index\",\n  hasAssociatedError: false,\n  intersectionIsOpen: true,\n  keys: {\n    signature: {\n      child: true,\n      parse: (schema2, ctx) => {\n        const key = ctx.$.parseSchema(schema2);\n        if (!key.extends($ark.intrinsic.key)) {\n          return throwParseError(writeInvalidPropertyKeyMessage(key.expression));\n        }\n        const enumerableBranches = key.branches.filter((b) => b.hasKind(\"unit\"));\n        if (enumerableBranches.length) {\n          return throwParseError(writeEnumerableIndexBranches(enumerableBranches.map((b) => printable(b.unit))));\n        }\n        return key;\n      }\n    },\n    value: {\n      child: true,\n      parse: (schema2, ctx) => ctx.$.parseSchema(schema2)\n    }\n  },\n  normalize: (schema2) => schema2,\n  defaults: {\n    description: (node2) => `[${node2.signature.expression}]: ${node2.value.description}`\n  },\n  intersections: {\n    index: (l, r, ctx) => {\n      if (l.signature.equals(r.signature)) {\n        const valueIntersection = intersectOrPipeNodes(l.value, r.value, ctx);\n        const value2 = valueIntersection instanceof Disjoint ? $ark.intrinsic.never.internal : valueIntersection;\n        return ctx.$.node(\"index\", { signature: l.signature, value: value2 });\n      }\n      if (l.signature.extends(r.signature) && l.value.subsumes(r.value))\n        return r;\n      if (r.signature.extends(l.signature) && r.value.subsumes(l.value))\n        return l;\n      return null;\n    }\n  }\n});\nvar IndexNode = class extends BaseConstraint {\n  impliedBasis = $ark.intrinsic.object.internal;\n  expression = `[${this.signature.expression}]: ${this.value.expression}`;\n  flatRefs = append(this.value.flatRefs.map((ref) => flatRef([this.signature, ...ref.path], ref.node)), flatRef([this.signature], this.value));\n  traverseAllows = (data, ctx) => stringAndSymbolicEntriesOf(data).every((entry) => {\n    if (this.signature.traverseAllows(entry[0], ctx)) {\n      return traverseKey(entry[0], () => this.value.traverseAllows(entry[1], ctx), ctx);\n    }\n    return true;\n  });\n  traverseApply = (data, ctx) => stringAndSymbolicEntriesOf(data).forEach((entry) => {\n    if (this.signature.traverseAllows(entry[0], ctx)) {\n      traverseKey(entry[0], () => this.value.traverseApply(entry[1], ctx), ctx);\n    }\n  });\n  _transform(mapper, ctx) {\n    ctx.path.push(this.signature);\n    const result = super._transform(mapper, ctx);\n    ctx.path.pop();\n    return result;\n  }\n  compile() {\n  }\n};\nvar Index = {\n  implementation: implementation19,\n  Node: IndexNode\n};\nvar writeEnumerableIndexBranches = (keys) => `Index keys ${keys.join(\", \")} should be specified as named props.`;\nvar writeInvalidPropertyKeyMessage = (indexSchema) => `Indexed key definition '${indexSchema}' must be a string or symbol`;\n\n// ../schema/out/structure/required.js\nvar implementation20 = implementNode({\n  kind: \"required\",\n  hasAssociatedError: true,\n  intersectionIsOpen: true,\n  keys: {\n    key: {},\n    value: {\n      child: true,\n      parse: (schema2, ctx) => ctx.$.parseSchema(schema2)\n    }\n  },\n  normalize: (schema2) => schema2,\n  defaults: {\n    description: (node2) => `${node2.compiledKey}: ${node2.value.description}`,\n    expected: (ctx) => ctx.missingValueDescription,\n    actual: () => \"missing\"\n  },\n  intersections: {\n    required: intersectProps,\n    optional: intersectProps\n  }\n});\nvar RequiredNode = class extends BaseProp {\n  expression = `${this.compiledKey}: ${this.value.expression}`;\n  errorContext = Object.freeze({\n    code: \"required\",\n    missingValueDescription: this.value.defaultShortDescription,\n    relativePath: [this.key],\n    meta: this.meta\n  });\n  compiledErrorContext = compileObjectLiteral(this.errorContext);\n};\nvar Required = {\n  implementation: implementation20,\n  Node: RequiredNode\n};\n\n// ../schema/out/structure/sequence.js\nvar implementation21 = implementNode({\n  kind: \"sequence\",\n  hasAssociatedError: false,\n  collapsibleKey: \"variadic\",\n  keys: {\n    prefix: {\n      child: true,\n      parse: (schema2, ctx) => {\n        if (schema2.length === 0)\n          return void 0;\n        return schema2.map((element) => ctx.$.parseSchema(element));\n      }\n    },\n    optionals: {\n      child: true,\n      parse: (schema2, ctx) => {\n        if (schema2.length === 0)\n          return void 0;\n        return schema2.map((element) => ctx.$.parseSchema(element));\n      }\n    },\n    defaultables: {\n      child: (defaultables) => defaultables.map((element) => element[0]),\n      parse: (defaultables, ctx) => {\n        if (defaultables.length === 0)\n          return void 0;\n        return defaultables.map((element) => {\n          const node2 = ctx.$.parseSchema(element[0]);\n          assertDefaultValueAssignability(node2, element[1], null);\n          return [node2, element[1]];\n        });\n      },\n      serialize: (defaults) => defaults.map((element) => [\n        element[0].collapsibleJson,\n        defaultValueSerializer(element[1])\n      ])\n    },\n    variadic: {\n      child: true,\n      parse: (schema2, ctx) => ctx.$.parseSchema(schema2, ctx)\n    },\n    minVariadicLength: {\n      // minVariadicLength is reflected in the id of this node,\n      // but not its IntersectionNode parent since it is superceded by the minLength\n      // node it implies\n      parse: (min) => min === 0 ? void 0 : min\n    },\n    postfix: {\n      child: true,\n      parse: (schema2, ctx) => {\n        if (schema2.length === 0)\n          return void 0;\n        return schema2.map((element) => ctx.$.parseSchema(element));\n      }\n    }\n  },\n  normalize: (schema2) => {\n    if (typeof schema2 === \"string\")\n      return { variadic: schema2 };\n    if (\"variadic\" in schema2 || \"prefix\" in schema2 || \"defaultables\" in schema2 || \"optionals\" in schema2 || \"postfix\" in schema2 || \"minVariadicLength\" in schema2) {\n      if (schema2.postfix?.length) {\n        if (!schema2.variadic)\n          return throwParseError(postfixWithoutVariadicMessage);\n        if (schema2.optionals?.length || schema2.defaultables?.length)\n          return throwParseError(postfixAfterOptionalOrDefaultableMessage);\n      }\n      if (schema2.minVariadicLength && !schema2.variadic) {\n        return throwParseError(\"minVariadicLength may not be specified without a variadic element\");\n      }\n      return schema2;\n    }\n    return { variadic: schema2 };\n  },\n  reduce: (raw, $) => {\n    let minVariadicLength = raw.minVariadicLength ?? 0;\n    const prefix = raw.prefix?.slice() ?? [];\n    const defaultables = raw.defaultables?.slice() ?? [];\n    const optionals = raw.optionals?.slice() ?? [];\n    const postfix = raw.postfix?.slice() ?? [];\n    if (raw.variadic) {\n      while (optionals.at(-1)?.equals(raw.variadic))\n        optionals.pop();\n      if (optionals.length === 0 && defaultables.length === 0) {\n        while (prefix.at(-1)?.equals(raw.variadic)) {\n          prefix.pop();\n          minVariadicLength++;\n        }\n      }\n      while (postfix[0]?.equals(raw.variadic)) {\n        postfix.shift();\n        minVariadicLength++;\n      }\n    } else if (optionals.length === 0 && defaultables.length === 0) {\n      prefix.push(...postfix.splice(0));\n    }\n    if (\n      // if any variadic adjacent elements were moved to minVariadicLength\n      minVariadicLength !== raw.minVariadicLength || // or any postfix elements were moved to prefix\n      raw.prefix && raw.prefix.length !== prefix.length\n    ) {\n      return $.node(\"sequence\", {\n        ...raw,\n        // empty lists will be omitted during parsing\n        prefix,\n        defaultables,\n        optionals,\n        postfix,\n        minVariadicLength\n      }, { prereduced: true });\n    }\n  },\n  defaults: {\n    description: (node2) => {\n      if (node2.isVariadicOnly)\n        return `${node2.variadic.nestableExpression}[]`;\n      const innerDescription = node2.tuple.map((element) => element.kind === \"defaultables\" ? `${element.node.nestableExpression} = ${printable(element.default)}` : element.kind === \"optionals\" ? `${element.node.nestableExpression}?` : element.kind === \"variadic\" ? `...${element.node.nestableExpression}[]` : element.node.expression).join(\", \");\n      return `[${innerDescription}]`;\n    }\n  },\n  intersections: {\n    sequence: (l, r, ctx) => {\n      const rootState = _intersectSequences({\n        l: l.tuple,\n        r: r.tuple,\n        disjoint: new Disjoint(),\n        result: [],\n        fixedVariants: [],\n        ctx\n      });\n      const viableBranches = rootState.disjoint.length === 0 ? [rootState, ...rootState.fixedVariants] : rootState.fixedVariants;\n      return viableBranches.length === 0 ? rootState.disjoint : viableBranches.length === 1 ? ctx.$.node(\"sequence\", sequenceTupleToInner(viableBranches[0].result)) : ctx.$.node(\"union\", viableBranches.map((state) => ({\n        proto: Array,\n        sequence: sequenceTupleToInner(state.result)\n      })));\n    }\n    // exactLength, minLength, and maxLength don't need to be defined\n    // here since impliedSiblings guarantees they will be added\n    // directly to the IntersectionNode parent of the SequenceNode\n    // they exist on\n  }\n});\nvar SequenceNode = class extends BaseConstraint {\n  impliedBasis = $ark.intrinsic.Array.internal;\n  tuple = sequenceInnerToTuple(this.inner);\n  prefixLength = this.prefix?.length ?? 0;\n  defaultablesLength = this.defaultables?.length ?? 0;\n  optionalsLength = this.optionals?.length ?? 0;\n  postfixLength = this.postfix?.length ?? 0;\n  defaultablesAndOptionals = [];\n  prevariadic = this.tuple.filter((el) => {\n    if (el.kind === \"defaultables\" || el.kind === \"optionals\") {\n      this.defaultablesAndOptionals.push(el.node);\n      return true;\n    }\n    return el.kind === \"prefix\";\n  });\n  variadicOrPostfix = conflatenate(this.variadic && [this.variadic], this.postfix);\n  // have to wait until prevariadic and variadicOrPostfix are set to calculate\n  flatRefs = this.addFlatRefs();\n  addFlatRefs() {\n    appendUniqueFlatRefs(this.flatRefs, this.prevariadic.flatMap((element, i) => append(element.node.flatRefs.map((ref) => flatRef([`${i}`, ...ref.path], ref.node)), flatRef([`${i}`], element.node))));\n    appendUniqueFlatRefs(this.flatRefs, this.variadicOrPostfix.flatMap((element) => (\n      // a postfix index can't be directly represented as a type\n      // key, so we just use the same matcher for variadic\n      append(element.flatRefs.map((ref) => flatRef([$ark.intrinsic.nonNegativeIntegerString.internal, ...ref.path], ref.node)), flatRef([$ark.intrinsic.nonNegativeIntegerString.internal], element))\n    )));\n    return this.flatRefs;\n  }\n  isVariadicOnly = this.prevariadic.length + this.postfixLength === 0;\n  minVariadicLength = this.inner.minVariadicLength ?? 0;\n  minLength = this.prefixLength + this.minVariadicLength + this.postfixLength;\n  minLengthNode = this.minLength === 0 ? null : this.$.node(\"minLength\", this.minLength);\n  maxLength = this.variadic ? null : this.tuple.length;\n  maxLengthNode = this.maxLength === null ? null : this.$.node(\"maxLength\", this.maxLength);\n  impliedSiblings = this.minLengthNode ? this.maxLengthNode ? [this.minLengthNode, this.maxLengthNode] : [this.minLengthNode] : this.maxLengthNode ? [this.maxLengthNode] : [];\n  defaultValueMorphs = getDefaultableMorphs(this);\n  defaultValueMorphsReference = this.defaultValueMorphs.length ? registeredReference(this.defaultValueMorphs) : void 0;\n  elementAtIndex(data, index) {\n    if (index < this.prevariadic.length)\n      return this.tuple[index];\n    const firstPostfixIndex = data.length - this.postfixLength;\n    if (index >= firstPostfixIndex)\n      return { kind: \"postfix\", node: this.postfix[index - firstPostfixIndex] };\n    return {\n      kind: \"variadic\",\n      node: this.variadic ?? throwInternalError(`Unexpected attempt to access index ${index} on ${this}`)\n    };\n  }\n  // minLength/maxLength should be checked by Intersection before either traversal\n  traverseAllows = (data, ctx) => {\n    for (let i = 0; i < data.length; i++) {\n      if (!this.elementAtIndex(data, i).node.traverseAllows(data[i], ctx))\n        return false;\n    }\n    return true;\n  };\n  traverseApply = (data, ctx) => {\n    let i = 0;\n    for (; i < data.length; i++) {\n      traverseKey(i, () => this.elementAtIndex(data, i).node.traverseApply(data[i], ctx), ctx);\n    }\n  };\n  get element() {\n    return this.cacheGetter(\"element\", this.$.node(\"union\", this.children));\n  }\n  // minLength/maxLength compilation should be handled by Intersection\n  compile(js) {\n    this.prefix?.forEach((node2, i) => js.traverseKey(`${i}`, `data[${i}]`, node2));\n    this.defaultablesAndOptionals.forEach((node2, i) => {\n      const dataIndex = `${i + this.prefixLength}`;\n      js.if(`${dataIndex} >= ${js.data}.length`, () => js.traversalKind === \"Allows\" ? js.return(true) : js.return());\n      js.traverseKey(dataIndex, `data[${dataIndex}]`, node2);\n    });\n    if (this.variadic) {\n      if (this.postfix) {\n        js.const(\"firstPostfixIndex\", `${js.data}.length${this.postfix ? `- ${this.postfix.length}` : \"\"}`);\n      }\n      js.for(`i < ${this.postfix ? \"firstPostfixIndex\" : \"data.length\"}`, () => js.traverseKey(\"i\", \"data[i]\", this.variadic), this.prevariadic.length);\n      this.postfix?.forEach((node2, i) => {\n        const keyExpression = `firstPostfixIndex + ${i}`;\n        js.traverseKey(keyExpression, `data[${keyExpression}]`, node2);\n      });\n    }\n    if (js.traversalKind === \"Allows\")\n      js.return(true);\n  }\n  _transform(mapper, ctx) {\n    ctx.path.push($ark.intrinsic.nonNegativeIntegerString.internal);\n    const result = super._transform(mapper, ctx);\n    ctx.path.pop();\n    return result;\n  }\n  // this depends on tuple so needs to come after it\n  expression = this.description;\n  reduceJsonSchema(schema2) {\n    if (this.prefix)\n      schema2.prefixItems = this.prefix.map((node2) => node2.toJsonSchema());\n    if (this.optionals) {\n      return JsonSchema.throwUnjsonifiableError(`Optional tuple element${this.optionalsLength > 1 ? \"s\" : \"\"} ${this.optionals.join(\", \")}`);\n    }\n    if (this.variadic) {\n      schema2.items = this.variadic?.toJsonSchema();\n      if (this.minLength)\n        schema2.minItems = this.minLength;\n      if (this.maxLength)\n        schema2.maxItems = this.maxLength;\n    } else {\n      schema2.items = false;\n      delete schema2.minItems;\n      delete schema2.maxItems;\n    }\n    if (this.postfix) {\n      return JsonSchema.throwUnjsonifiableError(`Postfix tuple element${this.postfixLength > 1 ? \"s\" : \"\"} ${this.postfix.join(\", \")}`);\n    }\n    return schema2;\n  }\n};\nvar defaultableMorphsCache = {};\nvar getDefaultableMorphs = (node2) => {\n  if (!node2.defaultables)\n    return [];\n  const morphs = [];\n  let cacheKey = \"[\";\n  const lastDefaultableIndex = node2.prefixLength + node2.defaultablesLength - 1;\n  for (let i = node2.prefixLength; i <= lastDefaultableIndex; i++) {\n    const [elementNode, defaultValue] = node2.defaultables[i - node2.prefixLength];\n    morphs.push(computeDefaultValueMorph(i, elementNode, defaultValue));\n    cacheKey += `${i}: ${elementNode.id} = ${defaultValueSerializer(defaultValue)}, `;\n  }\n  cacheKey += \"]\";\n  return defaultableMorphsCache[cacheKey] ??= morphs;\n};\nvar Sequence = {\n  implementation: implementation21,\n  Node: SequenceNode\n};\nvar sequenceInnerToTuple = (inner) => {\n  const tuple = [];\n  inner.prefix?.forEach((node2) => tuple.push({ kind: \"prefix\", node: node2 }));\n  inner.defaultables?.forEach(([node2, defaultValue]) => tuple.push({ kind: \"defaultables\", node: node2, default: defaultValue }));\n  inner.optionals?.forEach((node2) => tuple.push({ kind: \"optionals\", node: node2 }));\n  if (inner.variadic)\n    tuple.push({ kind: \"variadic\", node: inner.variadic });\n  inner.postfix?.forEach((node2) => tuple.push({ kind: \"postfix\", node: node2 }));\n  return tuple;\n};\nvar sequenceTupleToInner = (tuple) => tuple.reduce((result, element) => {\n  if (element.kind === \"variadic\")\n    result.variadic = element.node;\n  else if (element.kind === \"defaultables\") {\n    result.defaultables = append(result.defaultables, [\n      [element.node, element.default]\n    ]);\n  } else\n    result[element.kind] = append(result[element.kind], element.node);\n  return result;\n}, {});\nvar postfixAfterOptionalOrDefaultableMessage = \"A postfix required element cannot follow an optional or defaultable element\";\nvar postfixWithoutVariadicMessage = \"A postfix element requires a variadic element\";\nvar _intersectSequences = (s) => {\n  const [lHead, ...lTail] = s.l;\n  const [rHead, ...rTail] = s.r;\n  if (!lHead || !rHead)\n    return s;\n  const lHasPostfix = lTail.at(-1)?.kind === \"postfix\";\n  const rHasPostfix = rTail.at(-1)?.kind === \"postfix\";\n  const kind = lHead.kind === \"prefix\" || rHead.kind === \"prefix\" ? \"prefix\" : lHead.kind === \"postfix\" || rHead.kind === \"postfix\" ? \"postfix\" : lHead.kind === \"variadic\" && rHead.kind === \"variadic\" ? \"variadic\" : lHasPostfix || rHasPostfix ? \"prefix\" : lHead.kind === \"defaultables\" || rHead.kind === \"defaultables\" ? \"defaultables\" : \"optionals\";\n  if (lHead.kind === \"prefix\" && rHead.kind === \"variadic\" && rHasPostfix) {\n    const postfixBranchResult = _intersectSequences({\n      ...s,\n      fixedVariants: [],\n      r: rTail.map((element) => ({ ...element, kind: \"prefix\" }))\n    });\n    if (postfixBranchResult.disjoint.length === 0)\n      s.fixedVariants.push(postfixBranchResult);\n  } else if (rHead.kind === \"prefix\" && lHead.kind === \"variadic\" && lHasPostfix) {\n    const postfixBranchResult = _intersectSequences({\n      ...s,\n      fixedVariants: [],\n      l: lTail.map((element) => ({ ...element, kind: \"prefix\" }))\n    });\n    if (postfixBranchResult.disjoint.length === 0)\n      s.fixedVariants.push(postfixBranchResult);\n  }\n  const result = intersectOrPipeNodes(lHead.node, rHead.node, s.ctx);\n  if (result instanceof Disjoint) {\n    if (kind === \"prefix\" || kind === \"postfix\") {\n      s.disjoint.push(...result.withPrefixKey(\n        // ideally we could handle disjoint paths more precisely here,\n        // but not trivial to serialize postfix elements as keys\n        kind === \"prefix\" ? s.result.length : `-${lTail.length + 1}`,\n        \"required\"\n      ));\n      s.result = [...s.result, { kind, node: $ark.intrinsic.never.internal }];\n    } else if (kind === \"optionals\" || kind === \"defaultables\") {\n      return s;\n    } else {\n      return _intersectSequences({\n        ...s,\n        fixedVariants: [],\n        // if there were any optional elements, there will be no postfix elements\n        // so this mapping will never occur (which would be illegal otherwise)\n        l: lTail.map((element) => ({ ...element, kind: \"prefix\" })),\n        r: lTail.map((element) => ({ ...element, kind: \"prefix\" }))\n      });\n    }\n  } else if (kind === \"defaultables\") {\n    if (lHead.kind === \"defaultables\" && rHead.kind === \"defaultables\" && lHead.default !== rHead.default) {\n      throwParseError(writeDefaultIntersectionMessage(lHead.default, rHead.default));\n    }\n    s.result = [\n      ...s.result,\n      {\n        kind,\n        node: result,\n        default: lHead.kind === \"defaultables\" ? lHead.default : rHead.kind === \"defaultables\" ? rHead.default : throwInternalError(`Unexpected defaultable intersection from ${lHead.kind} and ${rHead.kind} elements.`)\n      }\n    ];\n  } else\n    s.result = [...s.result, { kind, node: result }];\n  const lRemaining = s.l.length;\n  const rRemaining = s.r.length;\n  if (lHead.kind !== \"variadic\" || lRemaining >= rRemaining && (rHead.kind === \"variadic\" || rRemaining === 1))\n    s.l = lTail;\n  if (rHead.kind !== \"variadic\" || rRemaining >= lRemaining && (lHead.kind === \"variadic\" || lRemaining === 1))\n    s.r = rTail;\n  return _intersectSequences(s);\n};\n\n// ../schema/out/structure/structure.js\nvar createStructuralWriter = (childStringProp) => (node2) => {\n  if (node2.props.length || node2.index) {\n    const parts = node2.index?.map((index) => index[childStringProp]) ?? [];\n    node2.props.forEach((prop) => parts.push(prop[childStringProp]));\n    if (node2.undeclared)\n      parts.push(`+ (undeclared): ${node2.undeclared}`);\n    const objectLiteralDescription = `{ ${parts.join(\", \")} }`;\n    return node2.sequence ? `${objectLiteralDescription} & ${node2.sequence.description}` : objectLiteralDescription;\n  }\n  return node2.sequence?.description ?? \"{}\";\n};\nvar structuralDescription = createStructuralWriter(\"description\");\nvar structuralExpression = createStructuralWriter(\"expression\");\nvar implementation22 = implementNode({\n  kind: \"structure\",\n  hasAssociatedError: false,\n  normalize: (schema2) => schema2,\n  applyConfig: (schema2, config) => {\n    if (!schema2.undeclared && config.onUndeclaredKey !== \"ignore\") {\n      return {\n        ...schema2,\n        undeclared: config.onUndeclaredKey\n      };\n    }\n    return schema2;\n  },\n  keys: {\n    required: {\n      child: true,\n      parse: constraintKeyParser(\"required\"),\n      reduceIo: (ioKind, inner, nodes) => {\n        inner.required = append(inner.required, nodes.map((node2) => node2[ioKind]));\n        return;\n      }\n    },\n    optional: {\n      child: true,\n      parse: constraintKeyParser(\"optional\"),\n      reduceIo: (ioKind, inner, nodes) => {\n        if (ioKind === \"in\") {\n          inner.optional = nodes.map((node2) => node2.in);\n          return;\n        }\n        nodes.forEach((node2) => inner[node2.outProp.kind] = append(inner[node2.outProp.kind], node2.outProp.out));\n      }\n    },\n    index: {\n      child: true,\n      parse: constraintKeyParser(\"index\")\n    },\n    sequence: {\n      child: true,\n      parse: constraintKeyParser(\"sequence\")\n    },\n    undeclared: {\n      parse: (behavior) => behavior === \"ignore\" ? void 0 : behavior,\n      reduceIo: (ioKind, inner, value2) => {\n        if (value2 !== \"delete\")\n          return;\n        if (ioKind === \"in\")\n          delete inner.undeclared;\n        else\n          inner.undeclared = \"reject\";\n      }\n    }\n  },\n  defaults: {\n    description: structuralDescription\n  },\n  intersections: {\n    structure: (l, r, ctx) => {\n      const lInner = { ...l.inner };\n      const rInner = { ...r.inner };\n      const disjointResult = new Disjoint();\n      if (l.undeclared) {\n        const lKey = l.keyof();\n        r.requiredKeys.forEach((k) => {\n          if (!lKey.allows(k)) {\n            disjointResult.add(\"presence\", $ark.intrinsic.never.internal, r.propsByKey[k].value, {\n              path: [k]\n            });\n          }\n        });\n        if (rInner.optional)\n          rInner.optional = rInner.optional.filter((n) => lKey.allows(n.key));\n        if (rInner.index) {\n          rInner.index = rInner.index.flatMap((n) => {\n            if (n.signature.extends(lKey))\n              return n;\n            const indexOverlap = intersectNodesRoot(lKey, n.signature, ctx.$);\n            if (indexOverlap instanceof Disjoint)\n              return [];\n            const normalized = normalizeIndex(indexOverlap, n.value, ctx.$);\n            if (normalized.required) {\n              rInner.required = conflatenate(rInner.required, normalized.required);\n            }\n            if (normalized.optional) {\n              rInner.optional = conflatenate(rInner.optional, normalized.optional);\n            }\n            return normalized.index ?? [];\n          });\n        }\n      }\n      if (r.undeclared) {\n        const rKey = r.keyof();\n        l.requiredKeys.forEach((k) => {\n          if (!rKey.allows(k)) {\n            disjointResult.add(\"presence\", l.propsByKey[k].value, $ark.intrinsic.never.internal, {\n              path: [k]\n            });\n          }\n        });\n        if (lInner.optional)\n          lInner.optional = lInner.optional.filter((n) => rKey.allows(n.key));\n        if (lInner.index) {\n          lInner.index = lInner.index.flatMap((n) => {\n            if (n.signature.extends(rKey))\n              return n;\n            const indexOverlap = intersectNodesRoot(rKey, n.signature, ctx.$);\n            if (indexOverlap instanceof Disjoint)\n              return [];\n            const normalized = normalizeIndex(indexOverlap, n.value, ctx.$);\n            if (normalized.required) {\n              lInner.required = conflatenate(lInner.required, normalized.required);\n            }\n            if (normalized.optional) {\n              lInner.optional = conflatenate(lInner.optional, normalized.optional);\n            }\n            return normalized.index ?? [];\n          });\n        }\n      }\n      const baseInner = {};\n      if (l.undeclared || r.undeclared) {\n        baseInner.undeclared = l.undeclared === \"reject\" || r.undeclared === \"reject\" ? \"reject\" : \"delete\";\n      }\n      const childIntersectionResult = intersectConstraints({\n        kind: \"structure\",\n        baseInner,\n        l: flattenConstraints(lInner),\n        r: flattenConstraints(rInner),\n        roots: [],\n        ctx\n      });\n      if (childIntersectionResult instanceof Disjoint)\n        disjointResult.push(...childIntersectionResult);\n      if (disjointResult.length)\n        return disjointResult;\n      return childIntersectionResult;\n    }\n  }\n});\nvar StructureNode = class extends BaseConstraint {\n  impliedBasis = $ark.intrinsic.object.internal;\n  impliedSiblings = this.children.flatMap((n) => n.impliedSiblings ?? []);\n  props = conflatenate(this.required, this.optional);\n  propsByKey = flatMorph(this.props, (i, node2) => [node2.key, node2]);\n  propsByKeyReference = registeredReference(this.propsByKey);\n  expression = structuralExpression(this);\n  requiredKeys = this.required?.map((node2) => node2.key) ?? [];\n  optionalKeys = this.optional?.map((node2) => node2.key) ?? [];\n  literalKeys = [...this.requiredKeys, ...this.optionalKeys];\n  _keyof;\n  keyof() {\n    if (this._keyof)\n      return this._keyof;\n    let branches = this.$.units(this.literalKeys).branches;\n    this.index?.forEach(({ signature }) => {\n      branches = branches.concat(signature.branches);\n    });\n    return this._keyof = this.$.node(\"union\", branches);\n  }\n  map(flatMapProp) {\n    return this.$.node(\"structure\", this.props.flatMap(flatMapProp).reduce((structureInner, mapped) => {\n      const originalProp = this.propsByKey[mapped.key];\n      if (isNode(mapped)) {\n        if (mapped.kind !== \"required\" && mapped.kind !== \"optional\") {\n          return throwParseError(`Map result must have kind \"required\" or \"optional\" (was ${mapped.kind})`);\n        }\n        structureInner[mapped.kind] = append(structureInner[mapped.kind], mapped);\n        return structureInner;\n      }\n      const mappedKind = mapped.kind ?? originalProp?.kind ?? \"required\";\n      const mappedPropInner = flatMorph(mapped, (k, v) => k in Optional.implementation.keys ? [k, v] : []);\n      structureInner[mappedKind] = append(structureInner[mappedKind], this.$.node(mappedKind, mappedPropInner));\n      return structureInner;\n    }, {}));\n  }\n  assertHasKeys(keys) {\n    const invalidKeys = keys.filter((k) => !typeOrTermExtends(k, this.keyof()));\n    if (invalidKeys.length) {\n      return throwParseError(writeInvalidKeysMessage(this.expression, invalidKeys));\n    }\n  }\n  get(indexer, ...path) {\n    let value2;\n    let required = false;\n    const key = indexerToKey(indexer);\n    if ((typeof key === \"string\" || typeof key === \"symbol\") && this.propsByKey[key]) {\n      value2 = this.propsByKey[key].value;\n      required = this.propsByKey[key].required;\n    }\n    this.index?.forEach((n) => {\n      if (typeOrTermExtends(key, n.signature))\n        value2 = value2?.and(n.value) ?? n.value;\n    });\n    if (this.sequence && typeOrTermExtends(key, $ark.intrinsic.nonNegativeIntegerString)) {\n      if (hasArkKind(key, \"root\")) {\n        if (this.sequence.variadic)\n          value2 = value2?.and(this.sequence.element) ?? this.sequence.element;\n      } else {\n        const index = Number.parseInt(key);\n        if (index < this.sequence.prevariadic.length) {\n          const fixedElement = this.sequence.prevariadic[index].node;\n          value2 = value2?.and(fixedElement) ?? fixedElement;\n          required ||= index < this.sequence.prefixLength;\n        } else if (this.sequence.variadic) {\n          const nonFixedElement = this.$.node(\"union\", this.sequence.variadicOrPostfix);\n          value2 = value2?.and(nonFixedElement) ?? nonFixedElement;\n        }\n      }\n    }\n    if (!value2) {\n      if (this.sequence?.variadic && hasArkKind(key, \"root\") && key.extends($ark.intrinsic.number)) {\n        return throwParseError(writeNumberIndexMessage(key.expression, this.sequence.expression));\n      }\n      return throwParseError(writeInvalidKeysMessage(this.expression, [key]));\n    }\n    const result = value2.get(...path);\n    return required ? result : result.or($ark.intrinsic.undefined);\n  }\n  pick(...keys) {\n    this.assertHasKeys(keys);\n    return this.$.node(\"structure\", this.filterKeys(\"pick\", keys));\n  }\n  omit(...keys) {\n    this.assertHasKeys(keys);\n    return this.$.node(\"structure\", this.filterKeys(\"omit\", keys));\n  }\n  optionalize() {\n    const { required, ...inner } = this.inner;\n    return this.$.node(\"structure\", {\n      ...inner,\n      optional: this.props.map((prop) => prop.hasKind(\"required\") ? this.$.node(\"optional\", prop.inner) : prop)\n    });\n  }\n  require() {\n    const { optional, ...inner } = this.inner;\n    return this.$.node(\"structure\", {\n      ...inner,\n      required: this.props.map((prop) => prop.hasKind(\"optional\") ? {\n        key: prop.key,\n        value: prop.value\n      } : prop)\n    });\n  }\n  merge(r) {\n    const inner = this.filterKeys(\"omit\", [r.keyof()]);\n    if (r.required)\n      inner.required = append(inner.required, r.required);\n    if (r.optional)\n      inner.optional = append(inner.optional, r.optional);\n    if (r.index)\n      inner.index = append(inner.index, r.index);\n    if (r.sequence)\n      inner.sequence = r.sequence;\n    if (r.undeclared)\n      inner.undeclared = r.undeclared;\n    else\n      delete inner.undeclared;\n    return this.$.node(\"structure\", inner);\n  }\n  filterKeys(operation, keys) {\n    const result = makeRootAndArrayPropertiesMutable(this.inner);\n    const shouldKeep = (key) => {\n      const matchesKey = keys.some((k) => typeOrTermExtends(key, k));\n      return operation === \"pick\" ? matchesKey : !matchesKey;\n    };\n    if (result.required)\n      result.required = result.required.filter((prop) => shouldKeep(prop.key));\n    if (result.optional)\n      result.optional = result.optional.filter((prop) => shouldKeep(prop.key));\n    if (result.index)\n      result.index = result.index.filter((index) => shouldKeep(index.signature));\n    return result;\n  }\n  traverseAllows = (data, ctx) => this._traverse(\"Allows\", data, ctx);\n  traverseApply = (data, ctx) => this._traverse(\"Apply\", data, ctx);\n  _traverse = (traversalKind, data, ctx) => {\n    const errorCount = ctx?.currentErrorCount ?? 0;\n    for (let i = 0; i < this.props.length; i++) {\n      if (traversalKind === \"Allows\") {\n        if (!this.props[i].traverseAllows(data, ctx))\n          return false;\n      } else {\n        this.props[i].traverseApply(data, ctx);\n        if (ctx.failFast && ctx.currentErrorCount > errorCount)\n          return false;\n      }\n    }\n    if (this.sequence) {\n      if (traversalKind === \"Allows\") {\n        if (!this.sequence.traverseAllows(data, ctx))\n          return false;\n      } else {\n        this.sequence.traverseApply(data, ctx);\n        if (ctx.failFast && ctx.currentErrorCount > errorCount)\n          return false;\n      }\n    }\n    if (this.index || this.undeclared === \"reject\") {\n      const keys = Object.keys(data);\n      keys.push(...Object.getOwnPropertySymbols(data));\n      for (let i = 0; i < keys.length; i++) {\n        const k = keys[i];\n        if (this.index) {\n          for (const node2 of this.index) {\n            if (node2.signature.traverseAllows(k, ctx)) {\n              if (traversalKind === \"Allows\") {\n                const result = traverseKey(k, () => node2.value.traverseAllows(data[k], ctx), ctx);\n                if (!result)\n                  return false;\n              } else {\n                traverseKey(k, () => node2.value.traverseApply(data[k], ctx), ctx);\n                if (ctx.failFast && ctx.currentErrorCount > errorCount)\n                  return false;\n              }\n            }\n          }\n        }\n        if (this.undeclared === \"reject\" && !this.declaresKey(k)) {\n          if (traversalKind === \"Allows\")\n            return false;\n          ctx.errorFromNodeContext({\n            // TODO: this should have its own error code\n            code: \"predicate\",\n            expected: \"removed\",\n            actual: \"\",\n            relativePath: [k],\n            meta: this.meta\n          });\n          if (ctx.failFast)\n            return false;\n        }\n      }\n    }\n    if (this.structuralMorph && ctx && !ctx.hasError())\n      ctx.queueMorphs([this.structuralMorph]);\n    return true;\n  };\n  get defaultable() {\n    return this.cacheGetter(\"defaultable\", this.optional?.filter((o) => o.hasDefault()) ?? []);\n  }\n  declaresKey = (k) => k in this.propsByKey || this.index?.some((n) => n.signature.allows(k)) || this.sequence !== void 0 && $ark.intrinsic.nonNegativeIntegerString.allows(k);\n  _compileDeclaresKey(js) {\n    const parts = [];\n    if (this.props.length)\n      parts.push(`k in ${this.propsByKeyReference}`);\n    this.index?.forEach((index) => parts.push(js.invoke(index.signature, { kind: \"Allows\", arg: \"k\" })));\n    if (this.sequence)\n      parts.push(\"$ark.intrinsic.nonNegativeIntegerString.allows(k)\");\n    return parts.join(\" || \") || \"false\";\n  }\n  get structuralMorph() {\n    return this.cacheGetter(\"structuralMorph\", getPossibleMorph(this));\n  }\n  structuralMorphRef = this.structuralMorph && registeredReference(this.structuralMorph);\n  compile(js) {\n    if (js.traversalKind === \"Apply\")\n      js.initializeErrorCount();\n    this.props.forEach((prop) => {\n      js.check(prop);\n      if (js.traversalKind === \"Apply\")\n        js.returnIfFailFast();\n    });\n    if (this.sequence) {\n      js.check(this.sequence);\n      if (js.traversalKind === \"Apply\")\n        js.returnIfFailFast();\n    }\n    if (this.index || this.undeclared === \"reject\") {\n      js.const(\"keys\", \"Object.keys(data)\");\n      js.line(\"keys.push(...Object.getOwnPropertySymbols(data))\");\n      js.for(\"i < keys.length\", () => this.compileExhaustiveEntry(js));\n    }\n    if (js.traversalKind === \"Allows\")\n      return js.return(true);\n    if (this.structuralMorphRef) {\n      js.if(\"ctx && !ctx.hasError()\", () => {\n        js.line(`ctx.queueMorphs([`);\n        precompileMorphs(js, this);\n        return js.line(\"])\");\n      });\n    }\n  }\n  compileExhaustiveEntry(js) {\n    js.const(\"k\", \"keys[i]\");\n    this.index?.forEach((node2) => {\n      js.if(`${js.invoke(node2.signature, { arg: \"k\", kind: \"Allows\" })}`, () => js.traverseKey(\"k\", \"data[k]\", node2.value));\n    });\n    if (this.undeclared === \"reject\") {\n      js.if(`!(${this._compileDeclaresKey(js)})`, () => {\n        if (js.traversalKind === \"Allows\")\n          return js.return(false);\n        return js.line(\n          // TODO: should have its own error code\n          `ctx.errorFromNodeContext({ code: \"predicate\", expected: \"removed\", actual: \"\", relativePath: [k], meta: ${this.compiledMeta} })`\n        ).if(\"ctx.failFast\", () => js.return());\n      });\n    }\n    return js;\n  }\n  reduceJsonSchema(schema2) {\n    switch (schema2.type) {\n      case \"object\":\n        return this.reduceObjectJsonSchema(schema2);\n      case \"array\":\n        if (this.props.length || this.index) {\n          return JsonSchema.throwUnjsonifiableError(`Additional properties on array ${this.expression}`);\n        }\n        return this.sequence?.reduceJsonSchema(schema2) ?? schema2;\n      default:\n        return JsonSchema.throwInternalOperandError(\"structure\", schema2);\n    }\n  }\n  reduceObjectJsonSchema(schema2) {\n    if (this.props.length) {\n      schema2.properties = {};\n      this.props.forEach((prop) => {\n        if (typeof prop.key === \"symbol\") {\n          return JsonSchema.throwUnjsonifiableError(`Symbolic key ${prop.serializedKey}`);\n        }\n        schema2.properties[prop.key] = prop.value.toJsonSchema();\n      });\n      if (this.requiredKeys.length)\n        schema2.required = this.requiredKeys;\n    }\n    this.index?.forEach((index) => {\n      if (index.signature.equals($ark.intrinsic.string))\n        return schema2.additionalProperties = index.value.toJsonSchema();\n      if (!index.signature.extends($ark.intrinsic.string)) {\n        return JsonSchema.throwUnjsonifiableError(`Symbolic index signature ${index.signature.exclude($ark.intrinsic.string)}`);\n      }\n      index.signature.branches.forEach((keyBranch) => {\n        if (!keyBranch.hasKind(\"intersection\") || keyBranch.inner.pattern?.length !== 1) {\n          return JsonSchema.throwUnjsonifiableError(`Index signature ${keyBranch}`);\n        }\n        schema2.patternProperties ??= {};\n        schema2.patternProperties[keyBranch.inner.pattern[0].rule] = index.value.toJsonSchema();\n      });\n    });\n    if (this.undeclared && !schema2.additionalProperties)\n      schema2.additionalProperties = false;\n    return schema2;\n  }\n};\nvar defaultableMorphsCache2 = {};\nvar constructStructuralMorphCacheKey = (node2) => {\n  let cacheKey = \"\";\n  for (let i = 0; i < node2.defaultable.length; i++)\n    cacheKey += node2.defaultable[i].defaultValueMorphRef;\n  if (node2.sequence?.defaultValueMorphsReference)\n    cacheKey += node2.sequence?.defaultValueMorphsReference;\n  if (node2.undeclared === \"delete\") {\n    cacheKey += \"delete !(\";\n    node2.required?.forEach((n) => cacheKey += n.compiledKey + \" | \");\n    node2.optional?.forEach((n) => cacheKey += n.compiledKey + \" | \");\n    node2.index?.forEach((index) => cacheKey += index.signature.id + \" | \");\n    if (node2.sequence) {\n      if (node2.sequence.maxLength === null)\n        cacheKey += intrinsic.nonNegativeIntegerString.id;\n      else {\n        cacheKey += node2.sequence.tuple.forEach((_, i) => cacheKey += i + \" | \");\n      }\n    }\n    cacheKey += \")\";\n  }\n  return cacheKey;\n};\nvar getPossibleMorph = (node2) => {\n  const cacheKey = constructStructuralMorphCacheKey(node2);\n  if (!cacheKey)\n    return void 0;\n  if (defaultableMorphsCache2[cacheKey])\n    return defaultableMorphsCache2[cacheKey];\n  const $arkStructuralMorph = (data, ctx) => {\n    for (let i = 0; i < node2.defaultable.length; i++) {\n      if (!(node2.defaultable[i].key in data))\n        node2.defaultable[i].defaultValueMorph(data, ctx);\n    }\n    if (node2.sequence?.defaultables) {\n      for (let i = data.length - node2.sequence.prefixLength; i < node2.sequence.defaultables.length; i++)\n        node2.sequence.defaultValueMorphs[i](data, ctx);\n    }\n    if (node2.undeclared === \"delete\") {\n      for (const k in data)\n        if (!node2.declaresKey(k))\n          delete data[k];\n    }\n    return data;\n  };\n  return defaultableMorphsCache2[cacheKey] = $arkStructuralMorph;\n};\nvar precompileMorphs = (js, node2) => {\n  const requiresContext = node2.defaultable.some((node3) => node3.defaultValueMorph.length === 2) || node2.sequence?.defaultValueMorphs.some((morph) => morph.length === 2);\n  const args2 = `(data${requiresContext ? \", ctx\" : \"\"})`;\n  return js.block(`${args2} => `, (js2) => {\n    for (let i = 0; i < node2.defaultable.length; i++) {\n      const { serializedKey, defaultValueMorphRef } = node2.defaultable[i];\n      js2.if(`!(${serializedKey} in data)`, (js3) => js3.line(`${defaultValueMorphRef}${args2}`));\n    }\n    if (node2.sequence?.defaultables) {\n      js2.for(`i < ${node2.sequence.defaultables.length}`, (js3) => js3.set(`data[i]`, 5), `data.length - ${node2.sequence.prefixLength}`);\n    }\n    if (node2.undeclared === \"delete\") {\n      js2.forIn(\"data\", (js3) => js3.if(`!(${node2._compileDeclaresKey(js3)})`, (js4) => js4.line(`delete data[k]`)));\n    }\n    return js2.return(\"data\");\n  });\n};\nvar Structure = {\n  implementation: implementation22,\n  Node: StructureNode\n};\nvar indexerToKey = (indexable) => {\n  if (hasArkKind(indexable, \"root\") && indexable.hasKind(\"unit\"))\n    indexable = indexable.unit;\n  if (typeof indexable === \"number\")\n    indexable = `${indexable}`;\n  return indexable;\n};\nvar writeNumberIndexMessage = (indexExpression, sequenceExpression) => `${indexExpression} is not allowed as an array index on ${sequenceExpression}. Use the 'nonNegativeIntegerString' keyword instead.`;\nvar normalizeIndex = (signature, value2, $) => {\n  const [enumerableBranches, nonEnumerableBranches] = spliterate(signature.branches, (k) => k.hasKind(\"unit\"));\n  if (!enumerableBranches.length)\n    return { index: $.node(\"index\", { signature, value: value2 }) };\n  const normalized = {};\n  enumerableBranches.forEach((n) => {\n    const prop = $.node(\"required\", { key: n.unit, value: value2 });\n    normalized[prop.kind] = append(normalized[prop.kind], prop);\n  });\n  if (nonEnumerableBranches.length) {\n    normalized.index = $.node(\"index\", {\n      signature: nonEnumerableBranches,\n      value: value2\n    });\n  }\n  return normalized;\n};\nvar typeKeyToString = (k) => hasArkKind(k, \"root\") ? k.expression : printable(k);\nvar writeInvalidKeysMessage = (o, keys) => `Key${keys.length === 1 ? \"\" : \"s\"} ${keys.map(typeKeyToString).join(\", \")} ${keys.length === 1 ? \"does\" : \"do\"} not exist on ${o}`;\n\n// ../schema/out/kinds.js\nvar nodeImplementationsByKind = {\n  ...boundImplementationsByKind,\n  alias: Alias.implementation,\n  domain: Domain.implementation,\n  unit: Unit.implementation,\n  proto: Proto.implementation,\n  union: Union.implementation,\n  morph: Morph.implementation,\n  intersection: Intersection.implementation,\n  divisor: Divisor.implementation,\n  pattern: Pattern.implementation,\n  predicate: Predicate.implementation,\n  required: Required.implementation,\n  optional: Optional.implementation,\n  index: Index.implementation,\n  sequence: Sequence.implementation,\n  structure: Structure.implementation\n};\n$ark.defaultConfig = withAlphabetizedKeys(Object.assign(flatMorph(nodeImplementationsByKind, (kind, implementation23) => [\n  kind,\n  implementation23.defaults\n]), {\n  jitless: envHasCsp(),\n  clone: deepClone,\n  onUndeclaredKey: \"ignore\",\n  exactOptionalPropertyTypes: true,\n  numberAllowsNaN: false,\n  dateAllowsInvalid: false,\n  onFail: null,\n  keywords: {}\n}));\n$ark.resolvedConfig = mergeConfigs($ark.defaultConfig, $ark.config);\nvar nodeClassesByKind = {\n  ...boundClassesByKind,\n  alias: Alias.Node,\n  domain: Domain.Node,\n  unit: Unit.Node,\n  proto: Proto.Node,\n  union: Union.Node,\n  morph: Morph.Node,\n  intersection: Intersection.Node,\n  divisor: Divisor.Node,\n  pattern: Pattern.Node,\n  predicate: Predicate.Node,\n  required: Required.Node,\n  optional: Optional.Node,\n  index: Index.Node,\n  sequence: Sequence.Node,\n  structure: Structure.Node\n};\n\n// ../schema/out/module.js\nvar RootModule = class extends DynamicBase {\n  // ensure `[arkKind]` is non-enumerable so it doesn't get spread on import/export\n  get [arkKind]() {\n    return \"module\";\n  }\n};\nvar bindModule = (module, $) => new RootModule(flatMorph(module, (alias, value2) => [\n  alias,\n  hasArkKind(value2, \"module\") ? bindModule(value2, $) : $.bindReference(value2)\n]));\n\n// ../schema/out/scope.js\nvar schemaBranchesOf = (schema2) => isArray(schema2) ? schema2 : \"branches\" in schema2 && isArray(schema2.branches) ? schema2.branches : void 0;\nvar throwMismatchedNodeRootError = (expected, actual) => throwParseError(`Node of kind ${actual} is not valid as a ${expected} definition`);\nvar writeDuplicateAliasError = (alias) => `#${alias} duplicates public alias ${alias}`;\nvar scopesByName = {};\n$ark.ambient ??= {};\nvar rawUnknownUnion;\nvar rootScopeFnName = \"function $\";\nvar precompile = (references) => bindPrecompilation(references, precompileReferences(references));\nvar bindPrecompilation = (references, precompiler) => {\n  const precompilation = precompiler.write(rootScopeFnName);\n  const compiledTraversals = precompiler.compile()();\n  for (const node2 of references) {\n    if (node2.precompilation) {\n      continue;\n    }\n    node2.traverseAllows = compiledTraversals[`${node2.id}Allows`].bind(compiledTraversals);\n    if (node2.isRoot() && !node2.allowsRequiresContext) {\n      node2.allows = node2.traverseAllows;\n    }\n    node2.traverseApply = compiledTraversals[`${node2.id}Apply`].bind(compiledTraversals);\n    if (compiledTraversals[`${node2.id}Optimistic`]) {\n      ;\n      node2.traverseOptimistic = compiledTraversals[`${node2.id}Optimistic`].bind(compiledTraversals);\n    }\n    node2.precompilation = precompilation;\n  }\n};\nvar precompileReferences = (references) => new CompiledFunction().return(references.reduce((js, node2) => {\n  const allowsCompiler = new NodeCompiler({ kind: \"Allows\" }).indent();\n  node2.compile(allowsCompiler);\n  const allowsJs = allowsCompiler.write(`${node2.id}Allows`);\n  const applyCompiler = new NodeCompiler({ kind: \"Apply\" }).indent();\n  node2.compile(applyCompiler);\n  const applyJs = applyCompiler.write(`${node2.id}Apply`);\n  const result = `${js}${allowsJs},\n${applyJs},\n`;\n  if (!node2.hasKind(\"union\"))\n    return result;\n  const optimisticCompiler = new NodeCompiler({\n    kind: \"Allows\",\n    optimistic: true\n  }).indent();\n  node2.compile(optimisticCompiler);\n  const optimisticJs = optimisticCompiler.write(`${node2.id}Optimistic`);\n  return `${result}${optimisticJs},\n`;\n}, \"{\\n\") + \"}\");\nvar BaseScope = class {\n  config;\n  resolvedConfig;\n  name;\n  get [arkKind]() {\n    return \"scope\";\n  }\n  referencesById = {};\n  references = [];\n  resolutions = {};\n  exportedNames = [];\n  aliases = {};\n  resolved = false;\n  nodesByHash = {};\n  intrinsic;\n  constructor(def, config) {\n    this.config = mergeConfigs($ark.config, config);\n    this.resolvedConfig = mergeConfigs($ark.resolvedConfig, config);\n    this.name = this.resolvedConfig.name ?? `anonymousScope${Object.keys(scopesByName).length}`;\n    if (this.name in scopesByName)\n      throwParseError(`A Scope already named ${this.name} already exists`);\n    scopesByName[this.name] = this;\n    const aliasEntries = Object.entries(def).map((entry) => this.preparseOwnAliasEntry(...entry));\n    aliasEntries.forEach(([k, v]) => {\n      let name = k;\n      if (k[0] === \"#\") {\n        name = k.slice(1);\n        if (name in this.aliases)\n          throwParseError(writeDuplicateAliasError(name));\n        this.aliases[name] = v;\n      } else {\n        if (name in this.aliases)\n          throwParseError(writeDuplicateAliasError(k));\n        this.aliases[name] = v;\n        this.exportedNames.push(name);\n      }\n      if (!hasArkKind(v, \"module\") && !hasArkKind(v, \"generic\") && // TODO: proto thunk defs?\n      !isThunk(v)) {\n        const preparsed = this.preparseOwnDefinitionFormat(v, { alias: name });\n        if (hasArkKind(preparsed, \"root\"))\n          this.resolutions[name] = this.bindReference(preparsed);\n        else\n          this.resolutions[name] = this.createParseContext(preparsed).id;\n      }\n    });\n    rawUnknownUnion ??= this.node(\"union\", {\n      branches: [\n        \"string\",\n        \"number\",\n        \"object\",\n        \"bigint\",\n        \"symbol\",\n        { unit: true },\n        { unit: false },\n        { unit: void 0 },\n        { unit: null }\n      ]\n    }, { prereduced: true });\n    this.nodesByHash[rawUnknownUnion.hash] = this.node(\"intersection\", {}, { prereduced: true });\n    this.intrinsic = $ark.intrinsic ? flatMorph($ark.intrinsic, (k, v) => (\n      // don't include cyclic aliases from JSON scope\n      k.startsWith(\"json\") ? [] : [k, this.bindReference(v)]\n    )) : {};\n  }\n  cacheGetter(name, value2) {\n    Object.defineProperty(this, name, { value: value2 });\n    return value2;\n  }\n  get internal() {\n    return this;\n  }\n  // json is populated when the scope is exported, so ensure it is populated\n  // before allowing external access\n  _json;\n  get json() {\n    if (!this._json)\n      this.export();\n    return this._json;\n  }\n  defineSchema(def) {\n    return def;\n  }\n  generic = (...params) => {\n    const $ = this;\n    return (def, possibleHkt) => new GenericRoot(params, possibleHkt ? new LazyGenericBody(def) : def, $, $, possibleHkt ?? null);\n  };\n  units = (values, opts) => {\n    const uniqueValues = [];\n    for (const value2 of values)\n      if (!uniqueValues.includes(value2))\n        uniqueValues.push(value2);\n    const branches = uniqueValues.map((unit) => this.node(\"unit\", { unit }, opts));\n    return this.node(\"union\", branches, {\n      ...opts,\n      prereduced: true\n    });\n  };\n  lazyResolutions = [];\n  lazilyResolve(resolve, syntheticAlias) {\n    const node2 = this.node(\"alias\", {\n      reference: syntheticAlias ?? \"synthetic\",\n      resolve\n    }, { prereduced: true });\n    if (!this.resolved)\n      this.lazyResolutions.push(node2);\n    return node2;\n  }\n  schema = (schema2, opts) => this.finalize(this.parseSchema(schema2, opts));\n  parseSchema = (schema2, opts) => this.node(schemaKindOf(schema2), schema2, opts);\n  preparseNode(kinds, schema2, opts) {\n    let kind = typeof kinds === \"string\" ? kinds : schemaKindOf(schema2, kinds);\n    if (isNode(schema2) && schema2.kind === kind)\n      return schema2;\n    if (kind === \"alias\" && !opts?.prereduced) {\n      const { reference: reference2 } = Alias.implementation.normalize(schema2, this);\n      if (reference2.startsWith(\"$\")) {\n        const resolution = this.resolveRoot(reference2.slice(1));\n        schema2 = resolution;\n        kind = resolution.kind;\n      }\n    } else if (kind === \"union\" && hasDomain(schema2, \"object\")) {\n      const branches = schemaBranchesOf(schema2);\n      if (branches?.length === 1) {\n        schema2 = branches[0];\n        kind = schemaKindOf(schema2);\n      }\n    }\n    if (isNode(schema2) && schema2.kind === kind)\n      return schema2;\n    const impl = nodeImplementationsByKind[kind];\n    const normalizedSchema = impl.normalize?.(schema2, this) ?? schema2;\n    if (isNode(normalizedSchema)) {\n      return normalizedSchema.kind === kind ? normalizedSchema : throwMismatchedNodeRootError(kind, normalizedSchema.kind);\n    }\n    return {\n      ...opts,\n      $: this,\n      kind,\n      def: normalizedSchema,\n      prefix: opts.alias ?? kind\n    };\n  }\n  bindReference(reference2) {\n    let bound;\n    if (isNode(reference2)) {\n      bound = reference2.$ === this ? reference2 : new reference2.constructor(reference2.attachments, this);\n    } else {\n      bound = reference2.$ === this ? reference2 : new GenericRoot(reference2.params, reference2.bodyDef, reference2.$, this, reference2.hkt);\n    }\n    if (!this.resolved) {\n      Object.assign(this.referencesById, bound.referencesById);\n    }\n    return bound;\n  }\n  resolveRoot(name) {\n    return this.maybeResolveRoot(name) ?? throwParseError(writeUnresolvableMessage(name));\n  }\n  maybeResolveRoot(name) {\n    const result = this.maybeResolve(name);\n    if (hasArkKind(result, \"generic\"))\n      return;\n    return result;\n  }\n  /** If name is a valid reference to a submodule alias, return its resolution  */\n  maybeResolveSubalias(name) {\n    return maybeResolveSubalias(this.aliases, name) ?? maybeResolveSubalias(this.ambient, name);\n  }\n  get ambient() {\n    return $ark.ambient;\n  }\n  maybeResolve(name) {\n    const cached2 = this.resolutions[name];\n    if (cached2) {\n      if (typeof cached2 !== \"string\")\n        return this.bindReference(cached2);\n      const v = nodesByRegisteredId[cached2];\n      if (hasArkKind(v, \"root\"))\n        return this.resolutions[name] = v;\n      if (hasArkKind(v, \"context\")) {\n        if (v.phase === \"resolving\") {\n          return this.node(\"alias\", { reference: `$${name}` }, { prereduced: true });\n        }\n        if (v.phase === \"resolved\") {\n          return throwInternalError(`Unexpected resolved context for was uncached by its scope: ${printable(v)}`);\n        }\n        v.phase = \"resolving\";\n        const node2 = this.bindReference(this.parseOwnDefinitionFormat(v.def, v));\n        v.phase = \"resolved\";\n        nodesByRegisteredId[node2.id] = node2;\n        nodesByRegisteredId[v.id] = node2;\n        return this.resolutions[name] = node2;\n      }\n      return throwInternalError(`Unexpected nodesById entry for ${cached2}: ${printable(v)}`);\n    }\n    let def = this.aliases[name] ?? this.ambient?.[name];\n    if (!def)\n      return this.maybeResolveSubalias(name);\n    def = this.normalizeRootScopeValue(def);\n    if (hasArkKind(def, \"generic\"))\n      return this.resolutions[name] = this.bindReference(def);\n    if (hasArkKind(def, \"module\")) {\n      if (def.root)\n        return this.resolutions[name] = this.bindReference(def.root);\n      else\n        return throwParseError(writeMissingSubmoduleAccessMessage(name));\n    }\n    return this.resolutions[name] = this.parse(def, {\n      alias: name\n    });\n  }\n  createParseContext(input) {\n    const id = input.id ?? registerNodeId(input.prefix);\n    return nodesByRegisteredId[id] = Object.assign(input, {\n      [arkKind]: \"context\",\n      $: this,\n      id,\n      phase: \"unresolved\"\n    });\n  }\n  traversal(root) {\n    return new Traversal(root, this.resolvedConfig);\n  }\n  import(...names) {\n    return new RootModule(flatMorph(this.export(...names), (alias, value2) => [\n      `#${alias}`,\n      value2\n    ]));\n  }\n  precompilation;\n  _exportedResolutions;\n  _exports;\n  export(...names) {\n    if (!this._exports) {\n      this._exports = {};\n      for (const name of this.exportedNames) {\n        const def = this.aliases[name];\n        this._exports[name] = hasArkKind(def, \"module\") ? bindModule(def, this) : bootstrapAliasReferences(this.maybeResolve(name));\n      }\n      this.lazyResolutions.forEach((node2) => node2.resolution);\n      this._exportedResolutions = resolutionsOfModule(this, this._exports);\n      this._json = resolutionsToJson(this._exportedResolutions);\n      Object.assign(this.resolutions, this._exportedResolutions);\n      this.references = Object.values(this.referencesById);\n      if (!this.resolvedConfig.jitless) {\n        const precompiler = precompileReferences(this.references);\n        this.precompilation = precompiler.write(rootScopeFnName);\n        bindPrecompilation(this.references, precompiler);\n      }\n      this.resolved = true;\n    }\n    const namesToExport = names.length ? names : this.exportedNames;\n    return new RootModule(flatMorph(namesToExport, (_, name) => [\n      name,\n      this._exports[name]\n    ]));\n  }\n  resolve(name) {\n    return this.export()[name];\n  }\n  node = (kinds, nodeSchema, opts = {}) => {\n    const ctxOrNode = this.preparseNode(kinds, nodeSchema, opts);\n    if (isNode(ctxOrNode))\n      return this.bindReference(ctxOrNode);\n    const ctx = this.createParseContext(ctxOrNode);\n    const node2 = parseNode(ctx);\n    const bound = this.bindReference(node2);\n    return nodesByRegisteredId[ctx.id] = bound;\n  };\n  parse = (def, opts = {}) => this.finalize(this.parseDefinition(def, opts));\n  parseDefinition(def, opts = {}) {\n    if (hasArkKind(def, \"root\"))\n      return this.bindReference(def);\n    const ctxInputOrNode = this.preparseOwnDefinitionFormat(def, opts);\n    if (hasArkKind(ctxInputOrNode, \"root\"))\n      return this.bindReference(ctxInputOrNode);\n    const ctx = this.createParseContext(ctxInputOrNode);\n    nodesByRegisteredId[ctx.id] = ctx;\n    let node2 = this.bindReference(this.parseOwnDefinitionFormat(def, ctx));\n    if (node2.isCyclic)\n      node2 = withId(node2, ctx.id);\n    nodesByRegisteredId[ctx.id] = node2;\n    return node2;\n  }\n  finalize(node2) {\n    bootstrapAliasReferences(node2);\n    if (!node2.precompilation && !this.resolvedConfig.jitless)\n      precompile(node2.references);\n    return node2;\n  }\n};\nvar SchemaScope = class extends BaseScope {\n  parseOwnDefinitionFormat(def, ctx) {\n    return parseNode(ctx);\n  }\n  preparseOwnDefinitionFormat(schema2, opts) {\n    return this.preparseNode(schemaKindOf(schema2), schema2, opts);\n  }\n  preparseOwnAliasEntry(k, v) {\n    return [k, v];\n  }\n  normalizeRootScopeValue(v) {\n    return v;\n  }\n};\nvar bootstrapAliasReferences = (resolution) => {\n  resolution.references.filter((node2) => node2.hasKind(\"alias\")).forEach((aliasNode) => {\n    Object.assign(aliasNode.referencesById, aliasNode.resolution.referencesById);\n    resolution.references.forEach((ref) => {\n      if (aliasNode.id in ref.referencesById)\n        Object.assign(ref.referencesById, aliasNode.referencesById);\n    });\n  });\n  return resolution;\n};\nvar resolutionsToJson = (resolutions) => flatMorph(resolutions, (k, v) => [\n  k,\n  hasArkKind(v, \"root\") || hasArkKind(v, \"generic\") ? v.json : hasArkKind(v, \"module\") ? resolutionsToJson(v) : throwInternalError(`Unexpected resolution ${printable(v)}`)\n]);\nvar maybeResolveSubalias = (base, name) => {\n  const dotIndex = name.indexOf(\".\");\n  if (dotIndex === -1)\n    return;\n  const dotPrefix = name.slice(0, dotIndex);\n  const prefixSchema = base[dotPrefix];\n  if (prefixSchema === void 0)\n    return;\n  if (!hasArkKind(prefixSchema, \"module\"))\n    return throwParseError(writeNonSubmoduleDotMessage(dotPrefix));\n  const subalias = name.slice(dotIndex + 1);\n  const resolution = prefixSchema[subalias];\n  if (resolution === void 0)\n    return maybeResolveSubalias(prefixSchema, subalias);\n  if (hasArkKind(resolution, \"root\") || hasArkKind(resolution, \"generic\"))\n    return resolution;\n  if (hasArkKind(resolution, \"module\")) {\n    return resolution.root ?? throwParseError(writeMissingSubmoduleAccessMessage(name));\n  }\n  throwInternalError(`Unexpected resolution for alias '${name}': ${printable(resolution)}`);\n};\nvar schemaScope = (aliases, config) => new SchemaScope(aliases, config);\nvar rootSchemaScope = new SchemaScope({});\nvar resolutionsOfModule = ($, typeSet) => {\n  const result = {};\n  for (const k in typeSet) {\n    const v = typeSet[k];\n    if (hasArkKind(v, \"module\")) {\n      const innerResolutions = resolutionsOfModule($, v);\n      const prefixedResolutions = flatMorph(innerResolutions, (innerK, innerV) => [`${k}.${innerK}`, innerV]);\n      Object.assign(result, prefixedResolutions);\n    } else if (hasArkKind(v, \"root\") || hasArkKind(v, \"generic\"))\n      result[k] = v;\n    else\n      throwInternalError(`Unexpected scope resolution ${printable(v)}`);\n  }\n  return result;\n};\nvar writeUnresolvableMessage = (token) => `'${token}' is unresolvable`;\nvar writeNonSubmoduleDotMessage = (name) => `'${name}' must reference a module to be accessed using dot syntax`;\nvar writeMissingSubmoduleAccessMessage = (name) => `Reference to submodule '${name}' must specify an alias`;\nrootSchemaScope.export();\nvar rootSchema = rootSchemaScope.schema;\nvar node = rootSchemaScope.node;\nvar defineSchema = rootSchemaScope.defineSchema;\nvar genericNode = rootSchemaScope.generic;\n\n// ../schema/out/structure/shared.js\nvar arrayIndexSource = `^(?:0|[1-9]\\\\d*)$`;\nvar arrayIndexMatcher = new RegExp(arrayIndexSource);\nvar arrayIndexMatcherReference = registeredReference(arrayIndexMatcher);\n\n// ../schema/out/intrinsic.js\nvar intrinsicBases = schemaScope({\n  bigint: \"bigint\",\n  // since we know this won't be reduced, it can be safely cast to a union\n  boolean: [{ unit: false }, { unit: true }],\n  false: { unit: false },\n  never: [],\n  null: { unit: null },\n  number: \"number\",\n  object: \"object\",\n  string: \"string\",\n  symbol: \"symbol\",\n  true: { unit: true },\n  unknown: {},\n  undefined: { unit: void 0 },\n  Array,\n  Date\n}, { prereducedAliases: true }).export();\n$ark.intrinsic = { ...intrinsicBases };\nvar intrinsicRoots = schemaScope({\n  integer: {\n    domain: \"number\",\n    divisor: 1\n  },\n  lengthBoundable: [\"string\", Array],\n  key: [\"string\", \"symbol\"],\n  nonNegativeIntegerString: { domain: \"string\", pattern: arrayIndexSource }\n}, { prereducedAliases: true }).export();\nObject.assign($ark.intrinsic, intrinsicRoots);\nvar intrinsicJson = schemaScope({\n  jsonPrimitive: [\n    \"string\",\n    \"number\",\n    { unit: true },\n    { unit: false },\n    { unit: null }\n  ],\n  jsonObject: {\n    domain: \"object\",\n    index: {\n      signature: \"string\",\n      value: \"$jsonData\"\n    }\n  },\n  jsonData: [\"$jsonPrimitive\", \"$jsonObject\"]\n}, { prereducedAliases: true }).export();\nvar intrinsic = {\n  ...intrinsicBases,\n  ...intrinsicRoots,\n  ...intrinsicJson,\n  emptyStructure: node(\"structure\", {}, { prereduced: true })\n};\n$ark.intrinsic = { ...intrinsic };\n\n// config.ts\nvar configure = configureSchema;\n\n// parser/shift/operand/date.ts\nvar isDateLiteral = (value2) => typeof value2 === \"string\" && value2[0] === \"d\" && (value2[1] === \"'\" || value2[1] === '\"') && value2.at(-1) === value2[1];\nvar isValidDate = (d) => d.toString() !== \"Invalid Date\";\nvar extractDateLiteralSource = (literal) => literal.slice(2, -1);\nvar writeInvalidDateMessage = (source) => `'${source}' could not be parsed by the Date constructor`;\nvar tryParseDate = (source, errorOnFail) => maybeParseDate(source, errorOnFail);\nvar maybeParseDate = (source, errorOnFail) => {\n  const stringParsedDate = new Date(source);\n  if (isValidDate(stringParsedDate)) return stringParsedDate;\n  const epochMillis = tryParseNumber(source);\n  if (epochMillis !== void 0) {\n    const numberParsedDate = new Date(epochMillis);\n    if (isValidDate(numberParsedDate)) return numberParsedDate;\n  }\n  return errorOnFail ? throwParseError(\n    errorOnFail === true ? writeInvalidDateMessage(source) : errorOnFail\n  ) : void 0;\n};\n\n// parser/shift/operand/enclosed.ts\nvar parseEnclosed = (s, enclosing) => {\n  const enclosed = s.scanner.shiftUntil(\n    untilLookaheadIsClosing[enclosingTokens[enclosing]]\n  );\n  if (s.scanner.lookahead === \"\")\n    return s.error(writeUnterminatedEnclosedMessage(enclosed, enclosing));\n  s.scanner.shift();\n  if (enclosing === \"/\") {\n    try {\n      new RegExp(enclosed);\n    } catch (e) {\n      throwParseError(String(e));\n    }\n    s.root = s.ctx.$.node(\n      \"intersection\",\n      {\n        domain: \"string\",\n        pattern: enclosed\n      },\n      { prereduced: true }\n    );\n  } else if (isKeyOf(enclosing, enclosingQuote))\n    s.root = s.ctx.$.node(\"unit\", { unit: enclosed });\n  else {\n    const date = tryParseDate(enclosed, writeInvalidDateMessage(enclosed));\n    s.root = s.ctx.$.node(\"unit\", { meta: enclosed, unit: date });\n  }\n};\nvar enclosingQuote = {\n  \"'\": 1,\n  '\"': 1\n};\nvar enclosingChar = {\n  \"/\": 1,\n  \"'\": 1,\n  '\"': 1\n};\nvar enclosingTokens = {\n  \"d'\": \"'\",\n  'd\"': '\"',\n  \"'\": \"'\",\n  '\"': '\"',\n  \"/\": \"/\"\n};\nvar untilLookaheadIsClosing = {\n  \"'\": (scanner) => scanner.lookahead === `'`,\n  '\"': (scanner) => scanner.lookahead === `\"`,\n  \"/\": (scanner) => scanner.lookahead === `/`\n};\nvar enclosingCharDescriptions = {\n  '\"': \"double-quote\",\n  \"'\": \"single-quote\",\n  \"/\": \"forward slash\"\n};\nvar writeUnterminatedEnclosedMessage = (fragment, enclosingStart) => `${enclosingStart}${fragment} requires a closing ${enclosingCharDescriptions[enclosingTokens[enclosingStart]]}`;\n\n// parser/ast/validate.ts\nvar writePrefixedPrivateReferenceMessage = (name) => `Private type references should not include '#'. Use '${name}' instead.`;\nvar shallowOptionalMessage = \"Optional definitions like 'string?' are only valid as properties in an object or tuple\";\nvar shallowDefaultableMessage = \"Defaultable definitions like 'number = 0' are only valid as properties in an object or tuple\";\n\n// parser/reduce/shared.ts\nvar minComparators = {\n  \">\": true,\n  \">=\": true\n};\nvar maxComparators = {\n  \"<\": true,\n  \"<=\": true\n};\nvar invertedComparators = {\n  \"<\": \">\",\n  \">\": \"<\",\n  \"<=\": \">=\",\n  \">=\": \"<=\",\n  \"==\": \"==\"\n};\nvar writeUnmatchedGroupCloseMessage = (unscanned) => `Unmatched )${unscanned === \"\" ? \"\" : ` before ${unscanned}`}`;\nvar writeUnclosedGroupMessage = (missingChar) => `Missing ${missingChar}`;\nvar writeOpenRangeMessage = (min, comparator) => `Left bounds are only valid when paired with right bounds (try ...${comparator}${min})`;\nvar writeUnpairableComparatorMessage = (comparator) => `Left-bounded expressions must specify their limits using < or <= (was ${comparator})`;\nvar writeMultipleLeftBoundsMessage = (openLimit, openComparator, limit, comparator) => `An expression may have at most one left bound (parsed ${openLimit}${invertedComparators[openComparator]}, ${limit}${invertedComparators[comparator]})`;\n\n// parser/shift/operand/genericArgs.ts\nvar parseGenericArgs = (name, g, s) => _parseGenericArgs(name, g, s, []);\nvar _parseGenericArgs = (name, g, s, argNodes) => {\n  const argState = s.parseUntilFinalizer();\n  argNodes.push(argState.root);\n  if (argState.finalizer === \">\") {\n    if (argNodes.length !== g.params.length) {\n      return s.error(\n        writeInvalidGenericArgCountMessage(\n          name,\n          g.names,\n          argNodes.map((arg) => arg.expression)\n        )\n      );\n    }\n    return argNodes;\n  }\n  if (argState.finalizer === \",\") return _parseGenericArgs(name, g, s, argNodes);\n  return argState.error(writeUnclosedGroupMessage(\">\"));\n};\nvar writeInvalidGenericArgCountMessage = (name, params, argDefs) => `${name}<${params.join(\", \")}> requires exactly ${params.length} args (got ${argDefs.length}${argDefs.length === 0 ? \"\" : `: ${argDefs.join(\", \")}`})`;\n\n// parser/shift/operand/unenclosed.ts\nvar parseUnenclosed = (s) => {\n  const token = s.scanner.shiftUntilNextTerminator();\n  if (token === \"keyof\") s.addPrefix(\"keyof\");\n  else s.root = unenclosedToNode(s, token);\n};\nvar parseGenericInstantiation = (name, g, s) => {\n  s.scanner.shiftUntilNonWhitespace();\n  const lookahead = s.scanner.shift();\n  if (lookahead !== \"<\")\n    return s.error(writeInvalidGenericArgCountMessage(name, g.names, []));\n  const parsedArgs = parseGenericArgs(name, g, s);\n  return g(...parsedArgs);\n};\nvar unenclosedToNode = (s, token) => maybeParseReference(s, token) ?? maybeParseUnenclosedLiteral(s, token) ?? s.error(\n  token === \"\" ? s.scanner.lookahead === \"#\" ? writePrefixedPrivateReferenceMessage(\n    s.shiftedByOne().scanner.shiftUntilNextTerminator()\n  ) : writeMissingOperandMessage(s) : writeUnresolvableMessage(token)\n);\nvar maybeParseReference = (s, token) => {\n  if (s.ctx.args?.[token]) {\n    const arg = s.ctx.args[token];\n    if (typeof arg !== \"string\") return arg;\n    return s.ctx.$.node(\"alias\", { reference: arg }, { prereduced: true });\n  }\n  const resolution = s.ctx.$.maybeResolve(token);\n  if (hasArkKind(resolution, \"root\")) return resolution;\n  if (resolution === void 0) return;\n  if (hasArkKind(resolution, \"generic\"))\n    return parseGenericInstantiation(token, resolution, s);\n  return throwParseError(`Unexpected resolution ${printable(resolution)}`);\n};\nvar maybeParseUnenclosedLiteral = (s, token) => {\n  const maybeNumber = tryParseWellFormedNumber(token);\n  if (maybeNumber !== void 0)\n    return s.ctx.$.node(\"unit\", { unit: maybeNumber });\n  const maybeBigint = tryParseWellFormedBigint(token);\n  if (maybeBigint !== void 0)\n    return s.ctx.$.node(\"unit\", { unit: maybeBigint });\n};\nvar writeMissingOperandMessage = (s) => {\n  const operator = s.previousOperator();\n  return operator ? writeMissingRightOperandMessage(operator, s.scanner.unscanned) : writeExpressionExpectedMessage(s.scanner.unscanned);\n};\nvar writeMissingRightOperandMessage = (token, unscanned = \"\") => `Token '${token}' requires a right operand${unscanned ? ` before '${unscanned}'` : \"\"}`;\nvar writeExpressionExpectedMessage = (unscanned) => `Expected an expression${unscanned ? ` before '${unscanned}'` : \"\"}`;\n\n// parser/shift/operand/operand.ts\nvar parseOperand = (s) => s.scanner.lookahead === \"\" ? s.error(writeMissingOperandMessage(s)) : s.scanner.lookahead === \"(\" ? s.shiftedByOne().reduceGroupOpen() : s.scanner.lookaheadIsIn(enclosingChar) ? parseEnclosed(s, s.scanner.shift()) : s.scanner.lookaheadIsIn(whitespaceChars) ? parseOperand(s.shiftedByOne()) : s.scanner.lookahead === \"d\" ? s.scanner.nextLookahead in enclosingQuote ? parseEnclosed(\n  s,\n  `${s.scanner.shift()}${s.scanner.shift()}`\n) : parseUnenclosed(s) : parseUnenclosed(s);\n\n// parser/shift/scanner.ts\nvar ArkTypeScanner = class _ArkTypeScanner extends Scanner {\n  shiftUntilNextTerminator() {\n    this.shiftUntilNonWhitespace();\n    return this.shiftUntil(\n      () => this.lookahead in _ArkTypeScanner.terminatingChars\n    );\n  }\n  static terminatingChars = {\n    \"<\": 1,\n    \">\": 1,\n    \"=\": 1,\n    \"|\": 1,\n    \"&\": 1,\n    \")\": 1,\n    \"[\": 1,\n    \"%\": 1,\n    \",\": 1,\n    \":\": 1,\n    \"?\": 1,\n    \"#\": 1,\n    ...whitespaceChars\n  };\n  static finalizingLookaheads = {\n    \">\": 1,\n    \",\": 1,\n    \"\": 1,\n    \"=\": 1,\n    \"?\": 1\n  };\n  static lookaheadIsFinalizing = (lookahead, unscanned) => lookahead === \">\" ? unscanned[0] === \"=\" ? (\n    // >== would only occur in an expression like Array<number>==5\n    // otherwise, >= would only occur as part of a bound like number>=5\n    unscanned[1] === \"=\"\n  ) : unscanned.trimStart() === \"\" || isKeyOf(unscanned.trimStart()[0], _ArkTypeScanner.terminatingChars) : lookahead === \"=\" ? unscanned[0] !== \"=\" : lookahead === \",\" || lookahead === \"?\";\n};\n\n// parser/shift/operator/bounds.ts\nvar parseBound = (s, start) => {\n  const comparator = shiftComparator(s, start);\n  if (s.root.hasKind(\"unit\")) {\n    if (typeof s.root.unit === \"number\") {\n      s.reduceLeftBound(s.root.unit, comparator);\n      s.unsetRoot();\n      return;\n    }\n    if (s.root.unit instanceof Date) {\n      const literal = `d'${s.root.description ?? s.root.unit.toISOString()}'`;\n      s.unsetRoot();\n      s.reduceLeftBound(literal, comparator);\n      return;\n    }\n  }\n  return parseRightBound(s, comparator);\n};\nvar comparatorStartChars = {\n  \"<\": 1,\n  \">\": 1,\n  \"=\": 1\n};\nvar shiftComparator = (s, start) => s.scanner.lookaheadIs(\"=\") ? `${start}${s.scanner.shift()}` : start;\nvar getBoundKinds = (comparator, limit, root, boundKind) => {\n  if (root.extends($ark.intrinsic.number)) {\n    if (typeof limit !== \"number\") {\n      return throwParseError(\n        writeInvalidLimitMessage(comparator, limit, boundKind)\n      );\n    }\n    return comparator === \"==\" ? [\"min\", \"max\"] : comparator[0] === \">\" ? [\"min\"] : [\"max\"];\n  }\n  if (root.extends($ark.intrinsic.lengthBoundable)) {\n    if (typeof limit !== \"number\") {\n      return throwParseError(\n        writeInvalidLimitMessage(comparator, limit, boundKind)\n      );\n    }\n    return comparator === \"==\" ? [\"exactLength\"] : comparator[0] === \">\" ? [\"minLength\"] : [\"maxLength\"];\n  }\n  if (root.extends($ark.intrinsic.Date)) {\n    return comparator === \"==\" ? [\"after\", \"before\"] : comparator[0] === \">\" ? [\"after\"] : [\"before\"];\n  }\n  return throwParseError(writeUnboundableMessage(root.expression));\n};\nvar openLeftBoundToRoot = (leftBound) => ({\n  rule: isDateLiteral(leftBound.limit) ? extractDateLiteralSource(leftBound.limit) : leftBound.limit,\n  exclusive: leftBound.comparator.length === 1\n});\nvar parseRightBound = (s, comparator) => {\n  const previousRoot = s.unsetRoot();\n  const previousScannerIndex = s.scanner.location;\n  s.parseOperand();\n  const limitNode = s.unsetRoot();\n  const limitToken = s.scanner.sliceChars(\n    previousScannerIndex,\n    s.scanner.location\n  );\n  s.root = previousRoot;\n  if (!limitNode.hasKind(\"unit\") || typeof limitNode.unit !== \"number\" && !(limitNode.unit instanceof Date))\n    return s.error(writeInvalidLimitMessage(comparator, limitToken, \"right\"));\n  const limit = limitNode.unit;\n  const exclusive = comparator.length === 1;\n  const boundKinds = getBoundKinds(\n    comparator,\n    typeof limit === \"number\" ? limit : limitToken,\n    previousRoot,\n    \"right\"\n  );\n  for (const kind of boundKinds) {\n    s.constrainRoot(\n      kind,\n      comparator === \"==\" ? { rule: limit } : { rule: limit, exclusive }\n    );\n  }\n  if (!s.branches.leftBound) return;\n  if (!isKeyOf(comparator, maxComparators))\n    return s.error(writeUnpairableComparatorMessage(comparator));\n  const lowerBoundKind = getBoundKinds(\n    s.branches.leftBound.comparator,\n    s.branches.leftBound.limit,\n    previousRoot,\n    \"left\"\n  );\n  s.constrainRoot(lowerBoundKind[0], openLeftBoundToRoot(s.branches.leftBound));\n  s.branches.leftBound = null;\n};\nvar writeInvalidLimitMessage = (comparator, limit, boundKind) => `Comparator ${boundKind === \"left\" ? invertedComparators[comparator] : comparator} must be ${boundKind === \"left\" ? \"preceded\" : \"followed\"} by a corresponding literal (was ${limit})`;\n\n// parser/shift/operator/brand.ts\nvar parseBrand = (s) => {\n  s.scanner.shiftUntilNonWhitespace();\n  const brandName = s.scanner.shiftUntilNextTerminator();\n  s.root = s.root.brand(brandName);\n};\n\n// parser/shift/operator/divisor.ts\nvar parseDivisor = (s) => {\n  const divisorToken = s.scanner.shiftUntilNextTerminator();\n  const divisor = tryParseInteger(divisorToken, {\n    errorOnFail: writeInvalidDivisorMessage(divisorToken)\n  });\n  if (divisor === 0) s.error(writeInvalidDivisorMessage(0));\n  s.root = s.root.constrain(\"divisor\", divisor);\n};\nvar writeInvalidDivisorMessage = (divisor) => `% operator must be followed by a non-zero integer literal (was ${divisor})`;\n\n// parser/shift/operator/operator.ts\nvar parseOperator = (s) => {\n  const lookahead = s.scanner.shift();\n  return lookahead === \"\" ? s.finalize(\"\") : lookahead === \"[\" ? s.scanner.shift() === \"]\" ? s.setRoot(s.root.array()) : s.error(incompleteArrayTokenMessage) : lookahead === \"|\" ? s.scanner.lookahead === \">\" ? s.shiftedByOne().pushRootToBranch(\"|>\") : s.pushRootToBranch(lookahead) : lookahead === \"&\" ? s.pushRootToBranch(lookahead) : lookahead === \")\" ? s.finalizeGroup() : ArkTypeScanner.lookaheadIsFinalizing(lookahead, s.scanner.unscanned) ? s.finalize(lookahead) : isKeyOf(lookahead, comparatorStartChars) ? parseBound(s, lookahead) : lookahead === \"%\" ? parseDivisor(s) : lookahead === \"#\" ? parseBrand(s) : lookahead in whitespaceChars ? parseOperator(s) : s.error(writeUnexpectedCharacterMessage(lookahead));\n};\nvar writeUnexpectedCharacterMessage = (char, shouldBe = \"\") => `'${char}' is not allowed here${shouldBe && ` (should be ${shouldBe})`}`;\nvar incompleteArrayTokenMessage = `Missing expected ']'`;\n\n// parser/shift/operator/default.ts\nvar parseDefault = (s) => {\n  const baseNode = s.unsetRoot();\n  s.parseOperand();\n  const defaultNode = s.unsetRoot();\n  if (!defaultNode.hasKind(\"unit\"))\n    return s.error(writeNonLiteralDefaultMessage(defaultNode.expression));\n  const defaultValue = defaultNode.unit instanceof Date ? () => new Date(defaultNode.unit) : defaultNode.unit;\n  return [baseNode, \"=\", defaultValue];\n};\nvar writeNonLiteralDefaultMessage = (defaultDef) => `Default value '${defaultDef}' must a literal value`;\n\n// parser/string.ts\nvar parseString = (def, ctx) => {\n  const aliasResolution = ctx.$.maybeResolveRoot(def);\n  if (aliasResolution) return aliasResolution;\n  if (def.endsWith(\"[]\")) {\n    const possibleElementResolution = ctx.$.maybeResolveRoot(def.slice(0, -2));\n    if (possibleElementResolution) return possibleElementResolution.array();\n  }\n  const s = new DynamicState(new ArkTypeScanner(def), ctx);\n  const node2 = fullStringParse(s);\n  if (s.finalizer === \">\") throwParseError(writeUnexpectedCharacterMessage(\">\"));\n  return node2;\n};\nvar fullStringParse = (s) => {\n  s.parseOperand();\n  let result = parseUntilFinalizer(s).root;\n  if (!result) {\n    return throwInternalError(\n      `Root was unexpectedly unset after parsing string '${s.scanner.scanned}'`\n    );\n  }\n  if (s.finalizer === \"=\") result = parseDefault(s);\n  else if (s.finalizer === \"?\") result = [result, \"?\"];\n  s.scanner.shiftUntilNonWhitespace();\n  if (s.scanner.lookahead) {\n    throwParseError(writeUnexpectedCharacterMessage(s.scanner.lookahead));\n  }\n  return result;\n};\nvar parseUntilFinalizer = (s) => {\n  while (s.finalizer === void 0) next(s);\n  return s;\n};\nvar next = (s) => s.hasRoot() ? s.parseOperator() : s.parseOperand();\n\n// parser/reduce/dynamic.ts\nvar DynamicState = class _DynamicState {\n  // set root type to `any` so that all constraints can be applied\n  root;\n  branches = {\n    prefixes: [],\n    leftBound: null,\n    intersection: null,\n    union: null,\n    pipe: null\n  };\n  finalizer;\n  groups = [];\n  scanner;\n  ctx;\n  constructor(scanner, ctx) {\n    this.scanner = scanner;\n    this.ctx = ctx;\n  }\n  error(message) {\n    return throwParseError(message);\n  }\n  hasRoot() {\n    return this.root !== void 0;\n  }\n  setRoot(root) {\n    this.root = root;\n  }\n  unsetRoot() {\n    const value2 = this.root;\n    this.root = void 0;\n    return value2;\n  }\n  constrainRoot(...args2) {\n    this.root = this.root.constrain(args2[0], args2[1]);\n  }\n  finalize(finalizer) {\n    if (this.groups.length) return this.error(writeUnclosedGroupMessage(\")\"));\n    this.finalizeBranches();\n    this.finalizer = finalizer;\n  }\n  reduceLeftBound(limit, comparator) {\n    const invertedComparator = invertedComparators[comparator];\n    if (!isKeyOf(invertedComparator, minComparators))\n      return this.error(writeUnpairableComparatorMessage(comparator));\n    if (this.branches.leftBound) {\n      return this.error(\n        writeMultipleLeftBoundsMessage(\n          this.branches.leftBound.limit,\n          this.branches.leftBound.comparator,\n          limit,\n          invertedComparator\n        )\n      );\n    }\n    this.branches.leftBound = {\n      comparator: invertedComparator,\n      limit\n    };\n  }\n  finalizeBranches() {\n    this.assertRangeUnset();\n    if (this.branches.pipe) {\n      this.pushRootToBranch(\"|>\");\n      this.root = this.branches.pipe;\n      return;\n    }\n    if (this.branches.union) {\n      this.pushRootToBranch(\"|\");\n      this.root = this.branches.union;\n      return;\n    }\n    if (this.branches.intersection) {\n      this.pushRootToBranch(\"&\");\n      this.root = this.branches.intersection;\n      return;\n    }\n    this.applyPrefixes();\n  }\n  finalizeGroup() {\n    this.finalizeBranches();\n    const topBranchState = this.groups.pop();\n    if (!topBranchState)\n      return this.error(writeUnmatchedGroupCloseMessage(this.scanner.unscanned));\n    this.branches = topBranchState;\n  }\n  addPrefix(prefix) {\n    this.branches.prefixes.push(prefix);\n  }\n  applyPrefixes() {\n    while (this.branches.prefixes.length) {\n      const lastPrefix = this.branches.prefixes.pop();\n      this.root = lastPrefix === \"keyof\" ? this.root.keyof() : throwInternalError(`Unexpected prefix '${lastPrefix}'`);\n    }\n  }\n  pushRootToBranch(token) {\n    this.assertRangeUnset();\n    this.applyPrefixes();\n    const root = this.root;\n    this.root = void 0;\n    this.branches.intersection = this.branches.intersection?.rawAnd(root) ?? root;\n    if (token === \"&\") return;\n    this.branches.union = this.branches.union?.rawOr(this.branches.intersection) ?? this.branches.intersection;\n    this.branches.intersection = null;\n    if (token === \"|\") return;\n    this.branches.pipe = this.branches.pipe?.rawPipeOnce(this.branches.union) ?? this.branches.union;\n    this.branches.union = null;\n  }\n  parseUntilFinalizer() {\n    return parseUntilFinalizer(new _DynamicState(this.scanner, this.ctx));\n  }\n  parseOperator() {\n    return parseOperator(this);\n  }\n  parseOperand() {\n    return parseOperand(this);\n  }\n  assertRangeUnset() {\n    if (this.branches.leftBound) {\n      return this.error(\n        writeOpenRangeMessage(\n          this.branches.leftBound.limit,\n          this.branches.leftBound.comparator\n        )\n      );\n    }\n  }\n  reduceGroupOpen() {\n    this.groups.push(this.branches);\n    this.branches = {\n      prefixes: [],\n      leftBound: null,\n      union: null,\n      intersection: null,\n      pipe: null\n    };\n  }\n  previousOperator() {\n    return this.branches.leftBound?.comparator ?? this.branches.prefixes.at(-1) ?? (this.branches.intersection ? \"&\" : this.branches.union ? \"|\" : this.branches.pipe ? \"|>\" : void 0);\n  }\n  shiftedByOne() {\n    this.scanner.shift();\n    return this;\n  }\n};\n\n// generic.ts\nvar Generic = GenericRoot;\nvar emptyGenericParameterMessage = \"An empty string is not a valid generic parameter name\";\nvar parseGenericParamName = (scanner, result, ctx) => {\n  scanner.shiftUntilNonWhitespace();\n  const name = scanner.shiftUntilNextTerminator();\n  if (name === \"\") {\n    if (scanner.lookahead === \"\" && result.length) return result;\n    return throwParseError(emptyGenericParameterMessage);\n  }\n  scanner.shiftUntilNonWhitespace();\n  return _parseOptionalConstraint(scanner, name, result, ctx);\n};\nvar extendsToken = \"extends \";\nvar _parseOptionalConstraint = (scanner, name, result, ctx) => {\n  scanner.shiftUntilNonWhitespace();\n  if (scanner.unscanned.startsWith(extendsToken))\n    scanner.jumpForward(extendsToken.length);\n  else {\n    if (scanner.lookahead === \",\") scanner.shift();\n    result.push(name);\n    return parseGenericParamName(scanner, result, ctx);\n  }\n  const s = parseUntilFinalizer(new DynamicState(scanner, ctx));\n  result.push([name, s.root]);\n  return parseGenericParamName(scanner, result, ctx);\n};\n\n// match.ts\nvar InternalMatchParser = class extends Callable {\n  $;\n  constructor($) {\n    super((...args2) => new InternalChainedMatchParser($)(...args2), {\n      bind: $\n    });\n    this.$ = $;\n  }\n  in(def) {\n    return new InternalChainedMatchParser(\n      this.$,\n      def === void 0 ? void 0 : this.$.parse(def)\n    );\n  }\n  at(key, cases) {\n    return new InternalChainedMatchParser(this.$).at(key, cases);\n  }\n  case(when, then) {\n    return new InternalChainedMatchParser(this.$).case(when, then);\n  }\n};\nvar InternalChainedMatchParser = class extends Callable {\n  $;\n  in;\n  key;\n  branches = [];\n  constructor($, In) {\n    super(\n      (cases) => this.caseEntries(\n        Object.entries(cases).map(\n          ([k, v]) => k === \"default\" ? [k, v] : [this.$.parse(k), v]\n        )\n      )\n    );\n    this.$ = $;\n    this.in = In;\n  }\n  at(key, cases) {\n    if (this.key) throwParseError(doubleAtMessage);\n    if (this.branches.length) throwParseError(chainedAtMessage);\n    this.key = key;\n    return cases ? this.match(cases) : this;\n  }\n  case(def, resolver) {\n    return this.caseEntry(this.$.parse(def), resolver);\n  }\n  caseEntry(node2, resolver) {\n    const wrappableNode = this.key ? this.$.parse({ [this.key]: node2 }) : node2;\n    const branch = wrappableNode.pipe(resolver);\n    this.branches.push(branch);\n    return this;\n  }\n  match(cases) {\n    return this(cases);\n  }\n  strings(cases) {\n    return this.caseEntries(\n      Object.entries(cases).map(\n        ([k, v]) => k === \"default\" ? [k, v] : [this.$.node(\"unit\", { unit: k }), v]\n      )\n    );\n  }\n  caseEntries(entries) {\n    for (let i = 0; i < entries.length; i++) {\n      const [k, v] = entries[i];\n      if (k === \"default\") {\n        if (i !== entries.length - 1) {\n          throwParseError(\n            `default may only be specified as the last key of a switch definition`\n          );\n        }\n        return this.default(v);\n      }\n      if (typeof v !== \"function\") {\n        return throwParseError(\n          `Value for case \"${k}\" must be a function (was ${domainOf(v)})`\n        );\n      }\n      this.caseEntry(k, v);\n    }\n    return this;\n  }\n  default(defaultCase) {\n    if (typeof defaultCase === \"function\")\n      this.case(intrinsic.unknown, defaultCase);\n    const schema2 = {\n      branches: this.branches,\n      ordered: true\n    };\n    if (defaultCase === \"never\" || defaultCase === \"assert\")\n      schema2.meta = { onFail: throwOnDefault };\n    const cases = this.$.node(\"union\", schema2);\n    if (!this.in) return this.$.finalize(cases);\n    let inputValidatedCases = this.in.pipe(cases);\n    if (defaultCase === \"never\" || defaultCase === \"assert\") {\n      inputValidatedCases = inputValidatedCases.configureReferences(\n        {\n          onFail: throwOnDefault\n        },\n        \"self\"\n      );\n    }\n    return this.$.finalize(inputValidatedCases);\n  }\n};\nvar throwOnDefault = (errors) => errors.throw();\nvar chainedAtMessage = `A key matcher must be specified before the first case i.e. match.at('foo') or match.in<object>().at('bar')`;\nvar doubleAtMessage = `At most one key matcher may be specified per expression`;\n\n// parser/property.ts\nvar parseProperty = (def, ctx) => {\n  if (isArray(def)) {\n    if (def[1] === \"=\")\n      return [ctx.$.parseOwnDefinitionFormat(def[0], ctx), \"=\", def[2]];\n    if (def[1] === \"?\")\n      return [ctx.$.parseOwnDefinitionFormat(def[0], ctx), \"?\"];\n  }\n  return parseInnerDefinition(def, ctx);\n};\nvar invalidOptionalKeyKindMessage = `Only required keys may make their values optional, e.g. { [mySymbol]: ['number', '?'] }`;\nvar invalidDefaultableKeyKindMessage = `Only required keys may specify default values, e.g. { value: 'number = 0' }`;\n\n// parser/objectLiteral.ts\nvar parseObjectLiteral = (def, ctx) => {\n  let spread;\n  const structure = {};\n  const defEntries = stringAndSymbolicEntriesOf(def);\n  for (const [k, v] of defEntries) {\n    const parsedKey = preparseKey(k);\n    if (parsedKey.kind === \"spread\") {\n      if (!isEmptyObject(structure))\n        return throwParseError(nonLeadingSpreadError);\n      const operand = ctx.$.parseOwnDefinitionFormat(v, ctx);\n      if (operand.equals(intrinsic.object)) continue;\n      if (!operand.hasKind(\"intersection\") || // still error on attempts to spread proto nodes like ...Date\n      !operand.basis?.equals(intrinsic.object)) {\n        return throwParseError(\n          writeInvalidSpreadTypeMessage(operand.expression)\n        );\n      }\n      spread = operand.structure;\n      continue;\n    }\n    if (parsedKey.kind === \"undeclared\") {\n      if (v !== \"reject\" && v !== \"delete\" && v !== \"ignore\")\n        throwParseError(writeInvalidUndeclaredBehaviorMessage(v));\n      structure.undeclared = v;\n      continue;\n    }\n    const parsedValue = parseProperty(v, ctx);\n    const parsedEntryKey = parsedKey;\n    if (parsedKey.kind === \"required\") {\n      if (!isArray(parsedValue)) {\n        appendNamedProp(\n          structure,\n          \"required\",\n          {\n            key: parsedKey.normalized,\n            value: parsedValue\n          },\n          ctx\n        );\n      } else {\n        appendNamedProp(\n          structure,\n          \"optional\",\n          parsedValue[1] === \"=\" ? {\n            key: parsedKey.normalized,\n            value: parsedValue[0],\n            default: parsedValue[2]\n          } : {\n            key: parsedKey.normalized,\n            value: parsedValue[0]\n          },\n          ctx\n        );\n      }\n      continue;\n    }\n    if (isArray(parsedValue)) {\n      if (parsedValue[1] === \"?\") throwParseError(invalidOptionalKeyKindMessage);\n      if (parsedValue[1] === \"=\")\n        throwParseError(invalidDefaultableKeyKindMessage);\n    }\n    if (parsedKey.kind === \"optional\") {\n      appendNamedProp(\n        structure,\n        \"optional\",\n        {\n          key: parsedKey.normalized,\n          value: parsedValue\n        },\n        ctx\n      );\n      continue;\n    }\n    const signature = ctx.$.parseOwnDefinitionFormat(\n      parsedEntryKey.normalized,\n      ctx\n    );\n    const normalized = normalizeIndex(signature, parsedValue, ctx.$);\n    if (normalized.index)\n      structure.index = append(structure.index, normalized.index);\n    if (normalized.required)\n      structure.required = append(structure.required, normalized.required);\n  }\n  const structureNode = ctx.$.node(\"structure\", structure);\n  return ctx.$.parseSchema({\n    domain: \"object\",\n    structure: spread?.merge(structureNode) ?? structureNode\n  });\n};\nvar appendNamedProp = (structure, kind, inner, ctx) => {\n  structure[kind] = append(\n    // doesn't seem like this cast should be necessary\n    structure[kind],\n    ctx.$.node(kind, inner)\n  );\n};\nvar writeInvalidUndeclaredBehaviorMessage = (actual) => `Value of '+' key must be 'reject', 'delete', or 'ignore' (was ${printable(actual)})`;\nvar nonLeadingSpreadError = \"Spread operator may only be used as the first key in an object\";\nvar preparseKey = (key) => typeof key === \"symbol\" ? { kind: \"required\", normalized: key } : key.at(-1) === \"?\" ? key.at(-2) === escapeChar ? { kind: \"required\", normalized: `${key.slice(0, -2)}?` } : {\n  kind: \"optional\",\n  normalized: key.slice(0, -1)\n} : key[0] === \"[\" && key.at(-1) === \"]\" ? { kind: \"index\", normalized: key.slice(1, -1) } : key[0] === escapeChar && key[1] === \"[\" && key.at(-1) === \"]\" ? { kind: \"required\", normalized: key.slice(1) } : key === \"...\" ? { kind: \"spread\" } : key === \"+\" ? { kind: \"undeclared\" } : {\n  kind: \"required\",\n  normalized: key === \"\\\\...\" ? \"...\" : key === \"\\\\+\" ? \"+\" : key\n};\nvar writeInvalidSpreadTypeMessage = (def) => `Spread operand must resolve to an object literal type (was ${def})`;\n\n// parser/tupleExpressions.ts\nvar maybeParseTupleExpression = (def, ctx) => isIndexZeroExpression(def) ? indexZeroParsers[def[0]](def, ctx) : isIndexOneExpression(def) ? indexOneParsers[def[1]](def, ctx) : null;\nvar parseKeyOfTuple = (def, ctx) => ctx.$.parseOwnDefinitionFormat(def[1], ctx).keyof();\nvar parseBranchTuple = (def, ctx) => {\n  if (def[2] === void 0)\n    return throwParseError(writeMissingRightOperandMessage(def[1], \"\"));\n  const l = ctx.$.parseOwnDefinitionFormat(def[0], ctx);\n  const r = ctx.$.parseOwnDefinitionFormat(def[2], ctx);\n  if (def[1] === \"|\") return ctx.$.node(\"union\", { branches: [l, r] });\n  const result = def[1] === \"&\" ? intersectNodesRoot(l, r, ctx.$) : pipeNodesRoot(l, r, ctx.$);\n  if (result instanceof Disjoint) return result.throw();\n  return result;\n};\nvar parseArrayTuple = (def, ctx) => ctx.$.parseOwnDefinitionFormat(def[0], ctx).array();\nvar parseMorphTuple = (def, ctx) => {\n  if (typeof def[2] !== \"function\") {\n    return throwParseError(\n      writeMalformedFunctionalExpressionMessage(\"=>\", def[2])\n    );\n  }\n  return ctx.$.parseOwnDefinitionFormat(def[0], ctx).pipe(def[2]);\n};\nvar writeMalformedFunctionalExpressionMessage = (operator, value2) => `${operator === \":\" ? \"Narrow\" : \"Morph\"} expression requires a function following '${operator}' (was ${typeof value2})`;\nvar parseNarrowTuple = (def, ctx) => {\n  if (typeof def[2] !== \"function\") {\n    return throwParseError(\n      writeMalformedFunctionalExpressionMessage(\":\", def[2])\n    );\n  }\n  return ctx.$.parseOwnDefinitionFormat(def[0], ctx).constrain(\n    \"predicate\",\n    def[2]\n  );\n};\nvar parseAttributeTuple = (def, ctx) => ctx.$.parseOwnDefinitionFormat(def[0], ctx).configureReferences(\n  def[2],\n  \"shallow\"\n);\nvar defineIndexOneParsers = (parsers) => parsers;\nvar postfixParsers = defineIndexOneParsers({\n  \"[]\": parseArrayTuple,\n  \"?\": () => throwParseError(shallowOptionalMessage)\n});\nvar infixParsers = defineIndexOneParsers({\n  \"|\": parseBranchTuple,\n  \"&\": parseBranchTuple,\n  \":\": parseNarrowTuple,\n  \"=>\": parseMorphTuple,\n  \"|>\": parseBranchTuple,\n  \"@\": parseAttributeTuple,\n  // since object and tuple literals parse there via `parseProperty`,\n  // they must be shallow if parsed directly as a tuple expression\n  \"=\": () => throwParseError(shallowDefaultableMessage)\n});\nvar indexOneParsers = { ...postfixParsers, ...infixParsers };\nvar isIndexOneExpression = (def) => indexOneParsers[def[1]] !== void 0;\nvar defineIndexZeroParsers = (parsers) => parsers;\nvar indexZeroParsers = defineIndexZeroParsers({\n  keyof: parseKeyOfTuple,\n  instanceof: (def, ctx) => {\n    if (typeof def[1] !== \"function\") {\n      return throwParseError(\n        writeInvalidConstructorMessage(objectKindOrDomainOf(def[1]))\n      );\n    }\n    const branches = def.slice(1).map(\n      (ctor) => typeof ctor === \"function\" ? ctx.$.node(\"proto\", { proto: ctor }) : throwParseError(\n        writeInvalidConstructorMessage(objectKindOrDomainOf(ctor))\n      )\n    );\n    return branches.length === 1 ? branches[0] : ctx.$.node(\"union\", { branches });\n  },\n  \"===\": (def, ctx) => ctx.$.units(def.slice(1))\n});\nvar isIndexZeroExpression = (def) => indexZeroParsers[def[0]] !== void 0;\nvar writeInvalidConstructorMessage = (actual) => `Expected a constructor following 'instanceof' operator (was ${actual})`;\n\n// parser/tupleLiteral.ts\nvar parseTupleLiteral = (def, ctx) => {\n  let sequences = [{}];\n  let i = 0;\n  while (i < def.length) {\n    let spread = false;\n    if (def[i] === \"...\" && i < def.length - 1) {\n      spread = true;\n      i++;\n    }\n    const parsedProperty = parseProperty(def[i], ctx);\n    const [valueNode, operator, possibleDefaultValue] = !isArray(parsedProperty) ? [parsedProperty] : parsedProperty;\n    i++;\n    if (spread) {\n      if (!valueNode.extends($ark.intrinsic.Array))\n        return throwParseError(writeNonArraySpreadMessage(valueNode.expression));\n      sequences = sequences.flatMap(\n        (base) => (\n          // since appendElement mutates base, we have to shallow-ish clone it for each branch\n          valueNode.distribute(\n            (branch) => appendSpreadBranch(makeRootAndArrayPropertiesMutable(base), branch)\n          )\n        )\n      );\n    } else {\n      sequences = sequences.map((base) => {\n        if (operator === \"?\") return appendOptionalElement(base, valueNode);\n        if (operator === \"=\")\n          return appendDefaultableElement(base, valueNode, possibleDefaultValue);\n        return appendRequiredElement(base, valueNode);\n      });\n    }\n  }\n  return ctx.$.parseSchema(\n    sequences.map(\n      (sequence) => isEmptyObject(sequence) ? {\n        proto: Array,\n        exactLength: 0\n      } : {\n        proto: Array,\n        sequence\n      }\n    )\n  );\n};\nvar appendRequiredElement = (base, element) => {\n  if (base.defaultables || base.optionals) {\n    return throwParseError(\n      base.variadic ? (\n        // e.g. [boolean = true, ...string[], number]\n        postfixAfterOptionalOrDefaultableMessage\n      ) : requiredPostOptionalMessage\n    );\n  }\n  if (base.variadic) {\n    base.postfix = append(base.postfix, element);\n  } else {\n    base.prefix = append(base.prefix, element);\n  }\n  return base;\n};\nvar appendOptionalElement = (base, element) => {\n  if (base.variadic)\n    return throwParseError(optionalOrDefaultableAfterVariadicMessage);\n  base.optionals = append(base.optionals, element);\n  return base;\n};\nvar appendDefaultableElement = (base, element, value2) => {\n  if (base.variadic)\n    return throwParseError(optionalOrDefaultableAfterVariadicMessage);\n  if (base.optionals)\n    return throwParseError(defaultablePostOptionalMessage);\n  base.defaultables = append(base.defaultables, [[element, value2]]);\n  return base;\n};\nvar appendVariadicElement = (base, element) => {\n  if (base.postfix) throwParseError(multipleVariadicMesage);\n  if (base.variadic) {\n    if (!base.variadic.equals(element)) {\n      throwParseError(multipleVariadicMesage);\n    }\n  } else {\n    base.variadic = element.internal;\n  }\n  return base;\n};\nvar appendSpreadBranch = (base, branch) => {\n  const spread = branch.select({ method: \"find\", kind: \"sequence\" });\n  if (!spread) {\n    return appendVariadicElement(base, $ark.intrinsic.unknown);\n  }\n  spread.prefix?.forEach((node2) => appendRequiredElement(base, node2));\n  spread.optionals?.forEach((node2) => appendOptionalElement(base, node2));\n  if (spread.variadic) appendVariadicElement(base, spread.variadic);\n  spread.postfix?.forEach((node2) => appendRequiredElement(base, node2));\n  return base;\n};\nvar writeNonArraySpreadMessage = (operand) => `Spread element must be an array (was ${operand})`;\nvar multipleVariadicMesage = \"A tuple may have at most one variadic element\";\nvar requiredPostOptionalMessage = \"A required element may not follow an optional element\";\nvar optionalOrDefaultableAfterVariadicMessage = \"An optional element may not follow a variadic element\";\nvar defaultablePostOptionalMessage = \"A defaultable element may not follow an optional element without a default\";\n\n// parser/definition.ts\nvar parseCache = {};\nvar parseInnerDefinition = (def, ctx) => {\n  if (typeof def === \"string\") {\n    if (ctx.args && Object.keys(ctx.args).some((k) => def.includes(k))) {\n      return parseString(def, ctx);\n    }\n    const scopeCache = parseCache[ctx.$.name] ??= {};\n    return scopeCache[def] ??= parseString(def, ctx);\n  }\n  return hasDomain(def, \"object\") ? parseObject(def, ctx) : throwParseError(writeBadDefinitionTypeMessage(domainOf(def)));\n};\nvar parseObject = (def, ctx) => {\n  const objectKind = objectKindOf(def);\n  switch (objectKind) {\n    case void 0:\n      if (hasArkKind(def, \"root\")) return def;\n      return parseObjectLiteral(def, ctx);\n    case \"Array\":\n      return parseTuple(def, ctx);\n    case \"RegExp\":\n      return ctx.$.node(\n        \"intersection\",\n        {\n          domain: \"string\",\n          pattern: def\n        },\n        { prereduced: true }\n      );\n    case \"Function\": {\n      const resolvedDef = isThunk(def) ? def() : def;\n      if (hasArkKind(resolvedDef, \"root\")) return resolvedDef;\n      return throwParseError(writeBadDefinitionTypeMessage(\"Function\"));\n    }\n    default:\n      return throwParseError(\n        writeBadDefinitionTypeMessage(objectKind ?? printable(def))\n      );\n  }\n};\nvar parseTuple = (def, ctx) => maybeParseTupleExpression(def, ctx) ?? parseTupleLiteral(def, ctx);\nvar writeBadDefinitionTypeMessage = (actual) => `Type definitions must be strings or objects (was ${actual})`;\n\n// type.ts\nvar InternalTypeParser = class extends Callable {\n  constructor($) {\n    const attach = Object.assign(\n      {\n        errors: ArkErrors,\n        hkt: Hkt,\n        $,\n        raw: $.parse,\n        module: $.constructor.module,\n        scope: $.constructor.scope,\n        define: $.define,\n        match: $.match,\n        generic: $.generic,\n        schema: $.schema,\n        // this won't be defined during bootstrapping, but externally always will be\n        keywords: $.ambient,\n        unit: $.unit,\n        enumerated: $.enumerated,\n        instanceOf: $.instanceOf,\n        valueOf: $.valueOf,\n        or: $.or,\n        and: $.and,\n        merge: $.merge,\n        pipe: $.pipe\n      },\n      // also won't be defined during bootstrapping\n      $.ambientAttachments\n    );\n    super(\n      (...args2) => {\n        if (args2.length === 1) {\n          return $.parse(args2[0]);\n        }\n        if (args2.length === 2 && typeof args2[0] === \"string\" && args2[0][0] === \"<\" && args2[0].at(-1) === \">\") {\n          const paramString = args2[0].slice(1, -1);\n          const params = $.parseGenericParams(paramString, {});\n          return new GenericRoot(\n            params,\n            args2[1],\n            $,\n            $,\n            null\n          );\n        }\n        return $.parse(args2);\n      },\n      {\n        bind: $,\n        attach\n      }\n    );\n  }\n};\nvar Type = BaseRoot;\n\n// scope.ts\nvar $arkTypeRegistry = $ark;\nvar InternalScope = class _InternalScope extends BaseScope {\n  get ambientAttachments() {\n    if (!$arkTypeRegistry.typeAttachments) return;\n    return this.cacheGetter(\n      \"ambientAttachments\",\n      flatMorph($arkTypeRegistry.typeAttachments, (k, v) => [\n        k,\n        this.bindReference(v)\n      ])\n    );\n  }\n  preparseOwnAliasEntry(alias, def) {\n    const firstParamIndex = alias.indexOf(\"<\");\n    if (firstParamIndex === -1) {\n      if (hasArkKind(def, \"module\") || hasArkKind(def, \"generic\"))\n        return [alias, def];\n      const qualifiedName = this.name === \"ark\" ? alias : alias === \"root\" ? this.name : `${this.name}.${alias}`;\n      const config = this.resolvedConfig.keywords?.[qualifiedName];\n      if (config) def = [def, \"@\", config];\n      return [alias, def];\n    }\n    if (alias.at(-1) !== \">\") {\n      throwParseError(\n        `'>' must be the last character of a generic declaration in a scope`\n      );\n    }\n    const name = alias.slice(0, firstParamIndex);\n    const paramString = alias.slice(firstParamIndex + 1, -1);\n    return [\n      name,\n      // use a thunk definition for the generic so that we can parse\n      // constraints within the current scope\n      () => {\n        const params = this.parseGenericParams(paramString, { alias: name });\n        const generic2 = parseGeneric(params, def, this);\n        return generic2;\n      }\n    ];\n  }\n  parseGenericParams(def, opts) {\n    return parseGenericParamName(\n      new ArkTypeScanner(def),\n      [],\n      this.createParseContext({\n        ...opts,\n        def,\n        prefix: \"generic\"\n      })\n    );\n  }\n  normalizeRootScopeValue(resolution) {\n    if (isThunk(resolution) && !hasArkKind(resolution, \"generic\"))\n      return resolution();\n    return resolution;\n  }\n  preparseOwnDefinitionFormat(def, opts) {\n    return {\n      ...opts,\n      def,\n      prefix: opts.alias ?? \"type\"\n    };\n  }\n  parseOwnDefinitionFormat(def, ctx) {\n    const isScopeAlias = ctx.alias && ctx.alias in this.aliases;\n    if (!isScopeAlias && !ctx.args) ctx.args = { this: ctx.id };\n    const result = parseInnerDefinition(def, ctx);\n    if (isArray(result)) {\n      if (result[1] === \"=\") return throwParseError(shallowDefaultableMessage);\n      if (result[1] === \"?\") return throwParseError(shallowOptionalMessage);\n    }\n    return result;\n  }\n  unit = (value2) => this.units([value2]);\n  valueOf = (tsEnum) => this.units(enumValues(tsEnum));\n  enumerated = (...values) => this.units(values);\n  instanceOf = (ctor) => this.node(\"proto\", { proto: ctor }, { prereduced: true });\n  or = (...defs) => this.schema(defs.map((def) => this.parse(def)));\n  and = (...defs) => defs.reduce(\n    (node2, def) => node2.and(this.parse(def)),\n    this.intrinsic.unknown\n  );\n  merge = (...defs) => defs.reduce(\n    (node2, def) => node2.merge(this.parse(def)),\n    this.intrinsic.object\n  );\n  pipe = (...morphs) => this.intrinsic.unknown.pipe(...morphs);\n  match = new InternalMatchParser(this);\n  declare = () => ({\n    type: this.type\n  });\n  define(def) {\n    return def;\n  }\n  type = new InternalTypeParser(this);\n  static scope = (def, config = {}) => new _InternalScope(def, config);\n  static module = (def, config = {}) => this.scope(def, config).export();\n};\nvar scope = Object.assign(InternalScope.scope, {\n  define: (def) => def\n});\nvar Scope = InternalScope;\n\n// keywords/builtins.ts\nvar MergeHkt = class extends Hkt {\n  description = 'merge an object\\'s properties onto another like `Merge(User, { isAdmin: \"true\" })`';\n};\nvar Merge = genericNode(\n  [\"base\", intrinsic.object],\n  [\"props\", intrinsic.object]\n)((args2) => args2.base.merge(args2.props), MergeHkt);\nvar arkBuiltins = Scope.module({\n  Key: intrinsic.key,\n  Merge\n});\n\n// keywords/Array.ts\nvar liftFromHkt = class extends Hkt {\n};\nvar liftFrom = genericNode(\"element\")((args2) => {\n  const nonArrayElement = args2.element.exclude(intrinsic.Array);\n  const lifted = nonArrayElement.array();\n  return nonArrayElement.rawOr(lifted).pipe(liftArray).distribute(\n    (branch) => branch.assertHasKind(\"morph\").declareOut(lifted),\n    rootSchema\n  );\n}, liftFromHkt);\nvar arkArray = Scope.module(\n  {\n    root: intrinsic.Array,\n    readonly: \"root\",\n    index: intrinsic.nonNegativeIntegerString,\n    liftFrom\n  },\n  {\n    name: \"Array\"\n  }\n);\n\n// keywords/FormData.ts\nvar value = rootSchema([\"string\", registry.FileConstructor]);\nvar parsedFormDataValue = value.rawOr(value.array());\nvar parsed = rootSchema({\n  meta: \"an object representing parsed form data\",\n  domain: \"object\",\n  index: {\n    signature: \"string\",\n    value: parsedFormDataValue\n  }\n});\nvar arkFormData = Scope.module(\n  {\n    root: [\"instanceof\", FormData],\n    value,\n    parsed,\n    parse: rootSchema({\n      in: FormData,\n      morphs: (data) => {\n        const result = {};\n        for (const [k, v] of data) {\n          if (k in result) {\n            const existing = result[k];\n            if (typeof existing === \"string\" || existing instanceof registry.FileConstructor)\n              result[k] = [existing, v];\n            else existing.push(v);\n          } else result[k] = v;\n        }\n        return result;\n      },\n      declaredOut: parsed\n    })\n  },\n  {\n    name: \"FormData\"\n  }\n);\n\n// keywords/TypedArray.ts\nvar TypedArray = Scope.module(\n  {\n    Int8: [\"instanceof\", Int8Array],\n    Uint8: [\"instanceof\", Uint8Array],\n    Uint8Clamped: [\"instanceof\", Uint8ClampedArray],\n    Int16: [\"instanceof\", Int16Array],\n    Uint16: [\"instanceof\", Uint16Array],\n    Int32: [\"instanceof\", Int32Array],\n    Uint32: [\"instanceof\", Uint32Array],\n    Float32: [\"instanceof\", Float32Array],\n    Float64: [\"instanceof\", Float64Array],\n    BigInt64: [\"instanceof\", BigInt64Array],\n    BigUint64: [\"instanceof\", BigUint64Array]\n  },\n  {\n    name: \"TypedArray\"\n  }\n);\n\n// keywords/constructors.ts\nvar omittedPrototypes = {\n  Boolean: 1,\n  Number: 1,\n  String: 1\n};\nvar arkPrototypes = Scope.module({\n  ...flatMorph(\n    { ...ecmascriptConstructors, ...platformConstructors },\n    (k, v) => k in omittedPrototypes ? [] : [k, [\"instanceof\", v]]\n  ),\n  Array: arkArray,\n  TypedArray,\n  FormData: arkFormData\n});\n\n// keywords/number.ts\nvar epoch = rootSchema({\n  domain: {\n    domain: \"number\",\n    meta: \"a number representing a Unix timestamp\"\n  },\n  divisor: {\n    rule: 1,\n    meta: `an integer representing a Unix timestamp`\n  },\n  min: {\n    rule: -864e13,\n    meta: `a Unix timestamp after -8640000000000000`\n  },\n  max: {\n    rule: 864e13,\n    meta: \"a Unix timestamp before 8640000000000000\"\n  },\n  meta: \"an integer representing a safe Unix timestamp\"\n});\nvar integer = rootSchema({\n  domain: \"number\",\n  divisor: 1\n});\nvar number = Scope.module(\n  {\n    root: intrinsic.number,\n    integer,\n    epoch,\n    safe: rootSchema({\n      domain: {\n        domain: \"number\",\n        numberAllowsNaN: false\n      },\n      min: Number.MIN_SAFE_INTEGER,\n      max: Number.MAX_SAFE_INTEGER\n    }),\n    NaN: [\"===\", Number.NaN],\n    Infinity: [\"===\", Number.POSITIVE_INFINITY],\n    NegativeInfinity: [\"===\", Number.NEGATIVE_INFINITY]\n  },\n  {\n    name: \"number\"\n  }\n);\n\n// keywords/string.ts\nvar regexStringNode = (regex, description) => node(\"intersection\", {\n  domain: \"string\",\n  pattern: {\n    rule: regex.source,\n    flags: regex.flags,\n    meta: description\n  }\n});\nvar stringIntegerRoot = regexStringNode(\n  wellFormedIntegerMatcher,\n  \"a well-formed integer string\"\n);\nvar stringInteger = Scope.module(\n  {\n    root: stringIntegerRoot,\n    parse: rootSchema({\n      in: stringIntegerRoot,\n      morphs: (s, ctx) => {\n        const parsed2 = Number.parseInt(s);\n        return Number.isSafeInteger(parsed2) ? parsed2 : ctx.error(\n          \"an integer in the range Number.MIN_SAFE_INTEGER to Number.MAX_SAFE_INTEGER\"\n        );\n      },\n      declaredOut: intrinsic.integer\n    })\n  },\n  {\n    name: \"string.integer\"\n  }\n);\nvar hex = regexStringNode(/^[0-9a-fA-F]+$/, \"hex characters only\");\nvar base64 = Scope.module(\n  {\n    root: regexStringNode(\n      /^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$/,\n      \"base64-encoded\"\n    ),\n    url: regexStringNode(\n      /^(?:[A-Za-z0-9_-]{4})*(?:[A-Za-z0-9_-]{2}(?:==|%3D%3D)?|[A-Za-z0-9_-]{3}(?:=|%3D)?)?$/,\n      \"base64url-encoded\"\n    )\n  },\n  {\n    name: \"string.base64\"\n  }\n);\nvar preformattedCapitalize = regexStringNode(/^[A-Z].*$/, \"capitalized\");\nvar capitalize2 = Scope.module(\n  {\n    root: rootSchema({\n      in: \"string\",\n      morphs: (s) => s.charAt(0).toUpperCase() + s.slice(1),\n      declaredOut: preformattedCapitalize\n    }),\n    preformatted: preformattedCapitalize\n  },\n  {\n    name: \"string.capitalize\"\n  }\n);\nvar isLuhnValid = (creditCardInput) => {\n  const sanitized = creditCardInput.replace(/[- ]+/g, \"\");\n  let sum = 0;\n  let digit;\n  let tmpNum;\n  let shouldDouble = false;\n  for (let i = sanitized.length - 1; i >= 0; i--) {\n    digit = sanitized.substring(i, i + 1);\n    tmpNum = Number.parseInt(digit, 10);\n    if (shouldDouble) {\n      tmpNum *= 2;\n      if (tmpNum >= 10) sum += tmpNum % 10 + 1;\n      else sum += tmpNum;\n    } else sum += tmpNum;\n    shouldDouble = !shouldDouble;\n  }\n  return !!(sum % 10 === 0 ? sanitized : false);\n};\nvar creditCardMatcher = /^(?:4[0-9]{12}(?:[0-9]{3,6})?|5[1-5][0-9]{14}|(222[1-9]|22[3-9][0-9]|2[3-6][0-9]{2}|27[01][0-9]|2720)[0-9]{12}|6(?:011|5[0-9][0-9])[0-9]{12,15}|3[47][0-9]{13}|3(?:0[0-5]|[68][0-9])[0-9]{11}|(?:2131|1800|35\\d{3})\\d{11}|6[27][0-9]{14}|^(81[0-9]{14,17}))$/;\nvar creditCard = rootSchema({\n  domain: \"string\",\n  pattern: {\n    meta: \"a credit card number\",\n    rule: creditCardMatcher.source\n  },\n  predicate: {\n    meta: \"a credit card number\",\n    predicate: isLuhnValid\n  }\n});\nvar iso8601Matcher = /^([+-]?\\d{4}(?!\\d{2}\\b))((-?)((0[1-9]|1[0-2])(\\3([12]\\d|0[1-9]|3[01]))?|W([0-4]\\d|5[0-3])(-?[1-7])?|(00[1-9]|0[1-9]\\d|[12]\\d{2}|3([0-5]\\d|6[1-6])))([T]((([01]\\d|2[0-3])((:?)[0-5]\\d)?|24:?00)([.,]\\d+(?!:))?)?(\\17[0-5]\\d([.,]\\d+)?)?([zZ]|([+-])([01]\\d|2[0-3]):?([0-5]\\d)?)?)?)?$/;\nvar isParsableDate = (s) => !Number.isNaN(new Date(s).valueOf());\nvar parsableDate = rootSchema({\n  domain: \"string\",\n  predicate: {\n    meta: \"a parsable date\",\n    predicate: isParsableDate\n  }\n}).assertHasKind(\"intersection\");\nvar epochRoot = stringInteger.root.internal.narrow((s, ctx) => {\n  const n = Number.parseInt(s);\n  const out = number.epoch(n);\n  if (out instanceof ArkErrors) {\n    ctx.errors.merge(out);\n    return false;\n  }\n  return true;\n}).configure(\n  {\n    description: \"an integer string representing a safe Unix timestamp\"\n  },\n  \"self\"\n).assertHasKind(\"intersection\");\nvar epoch2 = Scope.module(\n  {\n    root: epochRoot,\n    parse: rootSchema({\n      in: epochRoot,\n      morphs: (s) => new Date(s),\n      declaredOut: intrinsic.Date\n    })\n  },\n  {\n    name: \"string.date.epoch\"\n  }\n);\nvar isoRoot = regexStringNode(\n  iso8601Matcher,\n  \"an ISO 8601 (YYYY-MM-DDTHH:mm:ss.sssZ) date\"\n).internal.assertHasKind(\"intersection\");\nvar iso = Scope.module(\n  {\n    root: isoRoot,\n    parse: rootSchema({\n      in: isoRoot,\n      morphs: (s) => new Date(s),\n      declaredOut: intrinsic.Date\n    })\n  },\n  {\n    name: \"string.date.iso\"\n  }\n);\nvar stringDate = Scope.module(\n  {\n    root: parsableDate,\n    parse: rootSchema({\n      declaredIn: parsableDate,\n      in: \"string\",\n      morphs: (s, ctx) => {\n        const date = new Date(s);\n        if (Number.isNaN(date.valueOf())) return ctx.error(\"a parsable date\");\n        return date;\n      },\n      declaredOut: intrinsic.Date\n    }),\n    iso,\n    epoch: epoch2\n  },\n  {\n    name: \"string.date\"\n  }\n);\nvar email = regexStringNode(\n  // https://www.regular-expressions.info/email.html\n  /^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}$/,\n  \"an email address\"\n);\nvar ipv4Segment = \"(?:[0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])\";\nvar ipv4Address = `(${ipv4Segment}[.]){3}${ipv4Segment}`;\nvar ipv4Matcher = new RegExp(`^${ipv4Address}$`);\nvar ipv6Segment = \"(?:[0-9a-fA-F]{1,4})\";\nvar ipv6Matcher = new RegExp(\n  `^((?:${ipv6Segment}:){7}(?:${ipv6Segment}|:)|(?:${ipv6Segment}:){6}(?:${ipv4Address}|:${ipv6Segment}|:)|(?:${ipv6Segment}:){5}(?::${ipv4Address}|(:${ipv6Segment}){1,2}|:)|(?:${ipv6Segment}:){4}(?:(:${ipv6Segment}){0,1}:${ipv4Address}|(:${ipv6Segment}){1,3}|:)|(?:${ipv6Segment}:){3}(?:(:${ipv6Segment}){0,2}:${ipv4Address}|(:${ipv6Segment}){1,4}|:)|(?:${ipv6Segment}:){2}(?:(:${ipv6Segment}){0,3}:${ipv4Address}|(:${ipv6Segment}){1,5}|:)|(?:${ipv6Segment}:){1}(?:(:${ipv6Segment}){0,4}:${ipv4Address}|(:${ipv6Segment}){1,6}|:)|(?::((?::${ipv6Segment}){0,5}:${ipv4Address}|(?::${ipv6Segment}){1,7}|:)))(%[0-9a-zA-Z.]{1,})?$`\n);\nvar ip = Scope.module(\n  {\n    root: [\"v4 | v6\", \"@\", \"an IP address\"],\n    v4: regexStringNode(ipv4Matcher, \"an IPv4 address\"),\n    v6: regexStringNode(ipv6Matcher, \"an IPv6 address\")\n  },\n  {\n    name: \"string.ip\"\n  }\n);\nvar jsonStringDescription = \"a JSON string\";\nvar writeJsonSyntaxErrorProblem = (error) => {\n  if (!(error instanceof SyntaxError)) throw error;\n  return `must be ${jsonStringDescription} (${error})`;\n};\nvar jsonRoot = rootSchema({\n  meta: jsonStringDescription,\n  domain: \"string\",\n  predicate: {\n    meta: jsonStringDescription,\n    predicate: (s, ctx) => {\n      try {\n        JSON.parse(s);\n        return true;\n      } catch (e) {\n        return ctx.reject({\n          code: \"predicate\",\n          expected: jsonStringDescription,\n          problem: writeJsonSyntaxErrorProblem(e)\n        });\n      }\n    }\n  }\n});\nvar parseJson = (s, ctx) => {\n  if (s.length === 0) {\n    return ctx.error({\n      code: \"predicate\",\n      expected: jsonStringDescription,\n      actual: \"empty\"\n    });\n  }\n  try {\n    return JSON.parse(s);\n  } catch (e) {\n    return ctx.error({\n      code: \"predicate\",\n      expected: jsonStringDescription,\n      problem: writeJsonSyntaxErrorProblem(e)\n    });\n  }\n};\nvar json = Scope.module(\n  {\n    root: jsonRoot,\n    parse: rootSchema({\n      meta: \"safe JSON string parser\",\n      in: \"string\",\n      morphs: parseJson,\n      declaredOut: intrinsic.jsonObject\n    })\n  },\n  {\n    name: \"string.json\"\n  }\n);\nvar preformattedLower = regexStringNode(/^[a-z]*$/, \"only lowercase letters\");\nvar lower = Scope.module(\n  {\n    root: rootSchema({\n      in: \"string\",\n      morphs: (s) => s.toLowerCase(),\n      declaredOut: preformattedLower\n    }),\n    preformatted: preformattedLower\n  },\n  {\n    name: \"string.lower\"\n  }\n);\nvar normalizedForms = [\"NFC\", \"NFD\", \"NFKC\", \"NFKD\"];\nvar preformattedNodes = flatMorph(\n  normalizedForms,\n  (i, form) => [\n    form,\n    rootSchema({\n      domain: \"string\",\n      predicate: (s) => s.normalize(form) === s,\n      meta: `${form}-normalized unicode`\n    })\n  ]\n);\nvar normalizeNodes = flatMorph(\n  normalizedForms,\n  (i, form) => [\n    form,\n    rootSchema({\n      in: \"string\",\n      morphs: (s) => s.normalize(form),\n      declaredOut: preformattedNodes[form]\n    })\n  ]\n);\nvar NFC = Scope.module(\n  {\n    root: normalizeNodes.NFC,\n    preformatted: preformattedNodes.NFC\n  },\n  {\n    name: \"string.normalize.NFC\"\n  }\n);\nvar NFD = Scope.module(\n  {\n    root: normalizeNodes.NFD,\n    preformatted: preformattedNodes.NFD\n  },\n  {\n    name: \"string.normalize.NFD\"\n  }\n);\nvar NFKC = Scope.module(\n  {\n    root: normalizeNodes.NFKC,\n    preformatted: preformattedNodes.NFKC\n  },\n  {\n    name: \"string.normalize.NFKC\"\n  }\n);\nvar NFKD = Scope.module(\n  {\n    root: normalizeNodes.NFKD,\n    preformatted: preformattedNodes.NFKD\n  },\n  {\n    name: \"string.normalize.NFKD\"\n  }\n);\nvar normalize = Scope.module(\n  {\n    root: \"NFC\",\n    NFC,\n    NFD,\n    NFKC,\n    NFKD\n  },\n  {\n    name: \"string.normalize\"\n  }\n);\nvar numericRoot = regexStringNode(\n  numericStringMatcher,\n  \"a well-formed numeric string\"\n);\nvar numeric = Scope.module(\n  {\n    root: numericRoot,\n    parse: rootSchema({\n      in: numericRoot,\n      morphs: (s) => Number.parseFloat(s),\n      declaredOut: intrinsic.number\n    })\n  },\n  {\n    name: \"string.numeric\"\n  }\n);\nvar semverMatcher = /^(0|[1-9]\\d*)\\.(0|[1-9]\\d*)\\.(0|[1-9]\\d*)(?:-((?:0|[1-9]\\d*|\\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\\.(?:0|[1-9]\\d*|\\d*[a-zA-Z-][0-9a-zA-Z-]*))*))?(?:\\+([0-9a-zA-Z-]+(?:\\.[0-9a-zA-Z-]+)*))?$/;\nvar semver = regexStringNode(\n  semverMatcher,\n  \"a semantic version (see https://semver.org/)\"\n);\nvar preformattedTrim = regexStringNode(\n  // no leading or trailing whitespace\n  /^\\S.*\\S$|^\\S?$/,\n  \"trimmed\"\n);\nvar trim = Scope.module(\n  {\n    root: rootSchema({\n      in: \"string\",\n      morphs: (s) => s.trim(),\n      declaredOut: preformattedTrim\n    }),\n    preformatted: preformattedTrim\n  },\n  {\n    name: \"string.trim\"\n  }\n);\nvar preformattedUpper = regexStringNode(/^[A-Z]*$/, \"only uppercase letters\");\nvar upper = Scope.module(\n  {\n    root: rootSchema({\n      in: \"string\",\n      morphs: (s) => s.toUpperCase(),\n      declaredOut: preformattedUpper\n    }),\n    preformatted: preformattedUpper\n  },\n  {\n    name: \"string.upper\"\n  }\n);\nvar isParsableUrl = (s) => {\n  if (URL.canParse) return URL.canParse(s);\n  try {\n    new URL(s);\n    return true;\n  } catch {\n    return false;\n  }\n};\nvar urlRoot = rootSchema({\n  domain: \"string\",\n  predicate: {\n    meta: \"a URL string\",\n    predicate: isParsableUrl\n  }\n});\nvar url = Scope.module(\n  {\n    root: urlRoot,\n    parse: rootSchema({\n      declaredIn: urlRoot,\n      in: \"string\",\n      morphs: (s, ctx) => {\n        try {\n          return new URL(s);\n        } catch {\n          return ctx.error(\"a URL string\");\n        }\n      },\n      declaredOut: rootSchema(URL)\n    })\n  },\n  {\n    name: \"string.url\"\n  }\n);\nvar uuid = Scope.module(\n  {\n    // the meta tuple expression ensures the error message does not delegate\n    // to the individual branches, which are too detailed\n    root: [\"versioned | nil | max\", \"@\", \"a UUID\"],\n    \"#nil\": \"'00000000-0000-0000-0000-000000000000'\",\n    \"#max\": \"'ffffffff-ffff-ffff-ffff-ffffffffffff'\",\n    \"#versioned\": /[0-9a-f]{8}-[0-9a-f]{4}-[1-8][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}/i,\n    v1: regexStringNode(\n      /^[0-9a-f]{8}-[0-9a-f]{4}-1[0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i,\n      \"a UUIDv1\"\n    ),\n    v2: regexStringNode(\n      /^[0-9a-f]{8}-[0-9a-f]{4}-2[0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i,\n      \"a UUIDv2\"\n    ),\n    v3: regexStringNode(\n      /^[0-9a-f]{8}-[0-9a-f]{4}-3[0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i,\n      \"a UUIDv3\"\n    ),\n    v4: regexStringNode(\n      /^[0-9a-f]{8}-[0-9a-f]{4}-4[0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i,\n      \"a UUIDv4\"\n    ),\n    v5: regexStringNode(\n      /^[0-9a-f]{8}-[0-9a-f]{4}-5[0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i,\n      \"a UUIDv5\"\n    ),\n    v6: regexStringNode(\n      /^[0-9a-f]{8}-[0-9a-f]{4}-6[0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i,\n      \"a UUIDv6\"\n    ),\n    v7: regexStringNode(\n      /^[0-9a-f]{8}-[0-9a-f]{4}-7[0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i,\n      \"a UUIDv7\"\n    ),\n    v8: regexStringNode(\n      /^[0-9a-f]{8}-[0-9a-f]{4}-8[0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i,\n      \"a UUIDv8\"\n    )\n  },\n  {\n    name: \"string.uuid\"\n  }\n);\nvar string = Scope.module(\n  {\n    root: intrinsic.string,\n    alpha: regexStringNode(/^[A-Za-z]*$/, \"only letters\"),\n    alphanumeric: regexStringNode(\n      /^[A-Za-z\\d]*$/,\n      \"only letters and digits 0-9\"\n    ),\n    hex,\n    base64,\n    capitalize: capitalize2,\n    creditCard,\n    date: stringDate,\n    digits: regexStringNode(/^\\d*$/, \"only digits 0-9\"),\n    email,\n    integer: stringInteger,\n    ip,\n    json,\n    lower,\n    normalize,\n    numeric,\n    semver,\n    trim,\n    upper,\n    url,\n    uuid\n  },\n  {\n    name: \"string\"\n  }\n);\n\n// keywords/ts.ts\nvar arkTsKeywords = Scope.module({\n  bigint: intrinsic.bigint,\n  boolean: intrinsic.boolean,\n  false: intrinsic.false,\n  never: intrinsic.never,\n  null: intrinsic.null,\n  number: intrinsic.number,\n  object: intrinsic.object,\n  string: intrinsic.string,\n  symbol: intrinsic.symbol,\n  true: intrinsic.true,\n  unknown: intrinsic.unknown,\n  undefined: intrinsic.undefined\n});\nvar unknown = Scope.module(\n  {\n    root: intrinsic.unknown,\n    any: intrinsic.unknown\n  },\n  {\n    name: \"unknown\"\n  }\n);\nvar json2 = Scope.module(\n  {\n    root: intrinsic.jsonObject,\n    stringify: node(\"morph\", {\n      in: intrinsic.jsonObject,\n      morphs: (data) => JSON.stringify(data),\n      declaredOut: intrinsic.string\n    })\n  },\n  {\n    name: \"object.json\"\n  }\n);\nvar object = Scope.module(\n  {\n    root: intrinsic.object,\n    json: json2\n  },\n  {\n    name: \"object\"\n  }\n);\nvar RecordHkt = class extends Hkt {\n  description = 'instantiate an object from an index signature and corresponding value type like `Record(\"string\", \"number\")`';\n};\nvar Record = genericNode([\"K\", intrinsic.key], \"V\")(\n  (args2) => ({\n    domain: \"object\",\n    index: {\n      signature: args2.K,\n      value: args2.V\n    }\n  }),\n  RecordHkt\n);\nvar PickHkt = class extends Hkt {\n  description = 'pick a set of properties from an object like `Pick(User, \"name | age\")`';\n};\nvar Pick = genericNode([\"T\", intrinsic.object], [\"K\", intrinsic.key])(\n  (args2) => args2.T.pick(args2.K),\n  PickHkt\n);\nvar OmitHkt = class extends Hkt {\n  description = 'omit a set of properties from an object like `Omit(User, \"age\")`';\n};\nvar Omit = genericNode([\"T\", intrinsic.object], [\"K\", intrinsic.key])(\n  (args2) => args2.T.omit(args2.K),\n  OmitHkt\n);\nvar PartialHkt = class extends Hkt {\n  description = \"make all named properties of an object optional like `Partial(User)`\";\n};\nvar Partial = genericNode([\"T\", intrinsic.object])(\n  (args2) => args2.T.partial(),\n  PartialHkt\n);\nvar RequiredHkt = class extends Hkt {\n  description = \"make all named properties of an object required like `Required(User)`\";\n};\nvar Required2 = genericNode([\"T\", intrinsic.object])(\n  (args2) => args2.T.required(),\n  RequiredHkt\n);\nvar ExcludeHkt = class extends Hkt {\n  description = 'exclude branches of a union like `Exclude(\"boolean\", \"true\")`';\n};\nvar Exclude = genericNode(\"T\", \"U\")(\n  (args2) => args2.T.exclude(args2.U),\n  ExcludeHkt\n);\nvar ExtractHkt = class extends Hkt {\n  description = 'extract branches of a union like `Extract(\"0 | false | 1\", \"number\")`';\n};\nvar Extract = genericNode(\"T\", \"U\")(\n  (args2) => args2.T.extract(args2.U),\n  ExtractHkt\n);\nvar arkTsGenerics = Scope.module({\n  Exclude,\n  Extract,\n  Omit,\n  Partial,\n  Pick,\n  Record,\n  Required: Required2\n});\n\n// keywords/keywords.ts\nvar ark = scope(\n  {\n    ...arkTsKeywords,\n    ...arkTsGenerics,\n    ...arkPrototypes,\n    ...arkBuiltins,\n    string,\n    number,\n    object,\n    unknown\n  },\n  { prereducedAliases: true, name: \"ark\" }\n);\nvar keywords = ark.export();\nObject.assign($arkTypeRegistry.ambient, keywords);\n$arkTypeRegistry.typeAttachments = {\n  string: keywords.string.root,\n  number: keywords.number.root,\n  bigint: keywords.bigint,\n  boolean: keywords.boolean,\n  symbol: keywords.symbol,\n  undefined: keywords.undefined,\n  null: keywords.null,\n  object: keywords.object.root,\n  unknown: keywords.unknown.root,\n  false: keywords.false,\n  true: keywords.true,\n  never: keywords.never,\n  arrayIndex: keywords.Array.index,\n  Key: keywords.Key,\n  Record: keywords.Record,\n  Array: keywords.Array.root,\n  Date: keywords.Date\n};\nvar type = Object.assign(\n  ark.type,\n  // assign attachments newly parsed in keywords\n  // future scopes add these directly from the\n  // registry when their TypeParsers are instantiated\n  $arkTypeRegistry.typeAttachments\n);\nvar match = ark.match;\nvar generic = ark.generic;\nvar schema = ark.schema;\nvar define = ark.define;\nvar declare = ark.declare;\n\n// module.ts\nvar Module = RootModule;\n"
export const typeDts =
	'declare module "arktype" {\nimport * as _ark_schema from \'@ark/schema\';\nimport { TypeMeta, arkKind, BaseMappedPropInner, OptionalMappedPropInner, Prop, InclusiveNumericRangeSchema, ExclusiveNumericRangeSchema, ExactLength, InclusiveDateRangeSchema, ExclusiveDateRangeSchema, Divisor, Pattern, BaseRoot, BaseParseContext, GenericAst, GenericRoot, genericParamNames, resolvableReferenceIn, writeUnresolvableMessage, writeNonSubmoduleDotMessage, emptyBrandNameMessage, writeUnboundableMessage, writeUnassignableDefaultValueMessage, writeIndivisibleMessage, writeNonStructuralOperandMessage, PrivateDeclaration, writeMissingSubmoduleAccessMessage, GenericParamAst, writeUnsatisfiedParameterConstraintMessage, writeInvalidPropertyKeyMessage, UndeclaredKeyBehavior, ArkSchemaScopeConfig, BaseNode, exportedNameOf, toInternalScope, RootSchema, NodeKind, RootKind, NodeSchema, BaseParseOptions, nodeOfKind, reducibleKindOf, PreparsedNodeResolution, writeDuplicateAliasError, BaseScope, AliasDefEntry, GenericParamDef, BaseParseContextInput, Morph, unwrapDefault, Predicate, Sequence, postfixAfterOptionalOrDefaultableMessage, ArkErrors, JsonSchema, NodeSelector, Disjoint, StandardSchemaV1, flatResolutionsOf, LazyGenericBody, RootModule, ArkError } from \'@ark/schema\';\nexport { ArkError, ArkErrors, ArkSchemaConfig, ArkSchemaScopeConfig, JsonSchema } from \'@ark/schema\';\nimport * as util from \'@ark/util\';\nimport { anyOrNever, array, arkKeyOf, arkIndexableOf, arkGet, toArkKey, merge, ErrorType, listable, Key, show, intersectUnion, inferred, optionalKeyOf, JsonStructure, Scanner, EscapeChar, WhitespaceChar, Stringifiable, requireKeys, ErrorMessage, Completion, defined, NumberLiteral, join, lastOf, BigintLiteral, trim as trim$1, typeToString, writeMalformedNumericLiteralMessage, Hkt, flattenListable, Brand, noSuggest, Constructor, satisfy, conform, Fn, ifEmptyObjectLiteral, Primitive, objectKindOrDomainOf, equals, requiredKeyOf, Callable, unset, numericStringKeyOf, isDisjoint, unionToTuple, propValueOf, Json, omit, pick, Digit, liftArray, EcmascriptObjects, PlatformObjects, isSafelyMappable, intersectArrays } from \'@ark/util\';\nexport { Hkt, inferred } from \'@ark/util\';\nimport { ArkSchemaConfig } from \'@ark/schema/config\';\n\ntype KeywordConfig = {\n    [k in keyof Ark.flat as parseConfigurableFlatAlias<k, Ark.flat[k]>]?: TypeMeta.Collapsible;\n};\ntype parseConfigurableFlatAlias<k extends string, v> = [\n    v\n] extends [anyOrNever] ? k : v extends {\n    [arkKind]: "generic" | "module";\n} ? never : k extends `${infer prefix}.root` ? prefix : k;\ninterface ArkConfig extends ArkSchemaConfig {\n    keywords?: KeywordConfig;\n}\ndeclare const configure: <config extends ArkConfig>(config: config) => config;\ndeclare global {\n    export interface ArkEnv {\n        $(): Ark;\n    }\n}\n/**\n * This mirrors the global ArkEnv namespace as a local export. We use it instead\n * of the global internally due to a bug in twoslash that prevents `ark/docs`\n * from building if we refer to the global directly.\n *\n * If, in the future, docs can build while arktype refers to `ArkEnv.$` directly,\n * this can be removed.\n */\ndeclare namespace ArkAmbient {\n    type $ = ReturnType<ArkEnv["$"]>;\n    type meta = ArkEnv.meta;\n    type prototypes = ArkEnv.prototypes;\n}\n\n/** @ts-ignore cast variance */\ninterface Type$6<out t extends object = object, $ = {}> extends Type<t, $> {\n    readonly(): t extends array ? Type$5<{\n        readonly [i in keyof t]: t[i];\n    }, $> : Type$6<{\n        readonly [k in keyof t]: t[k];\n    }, $>;\n    keyof(): instantiateType<arkKeyOf<t>, $>;\n    /**\n     * Get the `Type` of a property of this `Type<object>`.\n     * @example type({ foo: "string" }).get("foo") // Type<string>\n     */\n    get<const k1 extends arkIndexableOf<t>, r = instantiateType<arkGet<t, k1>, $>>(k1: k1 | type.cast<k1>): r extends infer _ ? _ : never;\n    get<const k1 extends arkIndexableOf<t>, const k2 extends arkIndexableOf<arkGet<t, k1>>, r = instantiateType<arkGet<arkGet<t, k1>, k2>, $>>(k1: k1 | type.cast<k1>, k2: k2 | type.cast<k2>): r extends infer _ ? _ : never;\n    get<const k1 extends arkIndexableOf<t>, const k2 extends arkIndexableOf<arkGet<t, k1>>, const k3 extends arkIndexableOf<arkGet<arkGet<t, k1>, k2>>, r = instantiateType<arkGet<arkGet<arkGet<t, k1>, k2>, k3>, $>>(k1: k1 | type.cast<k1>, k2: k2 | type.cast<k2>, k3: k3 | type.cast<k3>): r extends infer _ ? _ : never;\n    /**\n     * Create a copy of this `Type` with only the specified properties.\n     * @example type({ foo: "string", bar: "number" }).pick("foo") // Type<{ foo: string }>\n     */\n    pick<const key extends arkKeyOf<t> = never>(...keys: (key | type.cast<key>)[]): Type$6<{\n        [k in keyof t as Extract<toArkKey<t, k>, key>]: t[k];\n    }, $>;\n    /**\n     * Create a copy of this `Type` with all properties except the specified ones.\n     * @example type({ foo: "string", bar: "number" }).omit("foo") // Type<{ bar: number }>\n     */\n    omit<const key extends arkKeyOf<t> = never>(...keys: (key | type.cast<key>)[]): Type$6<{\n        [k in keyof t as Exclude<toArkKey<t, k>, key>]: t[k];\n    }, $>;\n    /**\n     * Merge another `Type` definition, overriding properties of this `Type` with the duplicate keys.\n     * @example type({ a: "1", b: "2" }).merge({ b: "3", c: "4" }) // Type<{ a: 1, b: 3, c: 4 }>\n     */\n    merge<const def, inferredDef = type.infer<def, $>, r = Type$6<merge<t, inferredDef>, $>>(def: type.validate<def, $> & (inferredDef extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredDef]>)): r extends infer _ ? _ : never;\n    /**\n     * Create a copy of this `Type` with all properties required.\n     * @example const T = type({ "foo?"": "string" }).required() // Type<{ foo: string }>\n     */\n    required(): Type$6<{\n        [k in keyof t]-?: t[k];\n    }, $>;\n    /**\n     * Create a copy of this `Type` with all properties optional.\n     * @example: const T = type({ foo: "string" }).optional() // Type<{ foo?: string }>\n     */\n    partial(): Type$6<{\n        [k in keyof t]?: t[k];\n    }, $>;\n    map<transformed extends listable<MappedTypeProp>, r = Type$6<constructMapped<t, transformed>, $>>(flatMapEntry: (entry: typePropOf<t, $>) => transformed): r extends infer _ ? _ : never;\n    /**\n     * List of property info of this `Type<object>`.\n     * @example type({ foo: "string = "" }).props // [{ kind: "required", key: "foo", value: Type<string>, default: "" }]\n     */\n    props: array<typePropOf<t, $>>;\n}\ntype typePropOf<o, $> = keyof o extends infer k ? k extends keyof o ? typeProp<o, k, $> : never : never;\ntype typeProp<o, k extends keyof o, $, t = o[k] & ({} | null)> = t extends Default<infer t, infer defaultValue> ? DefaultedTypeProp<k & Key, t, defaultValue, $> : BaseTypeProp<k extends optionalKeyOf<o> ? "optional" : "required", k & Key, t, $>;\ninterface BaseTypeProp<kind extends Prop.Kind = Prop.Kind, k extends Key = Key, \n/** @ts-ignore cast variance */\nout v = unknown, $ = {}> {\n    kind: kind;\n    key: k;\n    value: instantiateType<v, $>;\n    meta: ArkEnv.meta;\n    toJSON: () => JsonStructure;\n}\ninterface DefaultedTypeProp<k extends Key = Key, v = unknown, defaultValue = v, $ = {}> extends BaseTypeProp<"optional", k, v, $> {\n    default: defaultValue;\n}\ntype MappedTypeProp<k extends Key = Key, v = unknown> = BaseMappedTypeProp<k, v> | OptionalMappedTypeProp<k, v>;\ntype BaseMappedTypeProp<k extends Key, v> = merge<BaseMappedPropInner, {\n    key: k;\n    value: type.cast<v>;\n}>;\ntype OptionalMappedTypeProp<k extends Key, v> = merge<OptionalMappedPropInner, {\n    key: k;\n    value: type.cast<v>;\n    default?: v;\n}>;\ntype constructMapped<t, transformed extends listable<MappedTypeProp>> = show<intersectUnion<fromTypeProps<t, transformed extends array ? transformed : [transformed]>>>;\ntype fromTypeProps<t, props extends array<MappedTypeProp>> = show<{\n    [prop in props[number] as Extract<applyHomomorphicOptionality<t, prop>, {\n        kind: "required";\n    }>["key"]]: prop["value"][inferred];\n} & {\n    [prop in props[number] as Extract<applyHomomorphicOptionality<t, prop>, {\n        kind: "optional";\n        default?: never;\n    }>["key"]]?: prop["value"][inferred];\n} & {\n    [prop in props[number] as Extract<applyHomomorphicOptionality<t, prop>, {\n        kind: "optional";\n        default: unknown;\n    }>["key"]]: withDefault<prop["value"][inferred], prop["default" & keyof prop]>;\n}>;\ntype NonObjectMergeErrorMessage = "Merged type must be an object";\ntype applyHomomorphicOptionality<t, prop extends MappedTypeProp> = prop["kind"] extends string ? prop : prop & {\n    kind: prop["key"] extends optionalKeyOf<t> ? "optional" : "required";\n};\n\ninterface Type$5<\n/** @ts-ignore cast variance */\nout t extends readonly unknown[] = readonly unknown[], $ = {}> extends Type$6<t, $> {\n    atLeastLength(schema: InclusiveNumericRangeSchema): this;\n    atMostLength(schema: InclusiveNumericRangeSchema): this;\n    moreThanLength(schema: ExclusiveNumericRangeSchema): this;\n    lessThanLength(schema: ExclusiveNumericRangeSchema): this;\n    exactlyLength(schema: ExactLength.Schema): this;\n}\n\n/** @ts-ignore cast variance */\ninterface Type$4<out t extends globalThis.Date = globalThis.Date, $ = {}> extends Type$6<t, $> {\n    atOrAfter(schema: InclusiveDateRangeSchema): this;\n    atOrBefore(schema: InclusiveDateRangeSchema): this;\n    laterThan(schema: ExclusiveDateRangeSchema): this;\n    earlierThan(schema: ExclusiveDateRangeSchema): this;\n}\n\n/** @ts-ignore cast variance */\ninterface Type$3<out t extends number = number, $ = {}> extends Type<t, $> {\n    divisibleBy(schema: Divisor.Schema): this;\n    atLeast(schema: InclusiveNumericRangeSchema): this;\n    atMost(schema: InclusiveNumericRangeSchema): this;\n    moreThan(schema: ExclusiveNumericRangeSchema): this;\n    lessThan(schema: ExclusiveNumericRangeSchema): this;\n}\n\n/** @ts-ignore cast variance */\ninterface Type$2<out t extends string = string, $ = {}> extends Type<t, $> {\n    matching(schema: Pattern.Schema): this;\n    atLeastLength(schema: InclusiveNumericRangeSchema): this;\n    atMostLength(schema: InclusiveNumericRangeSchema): this;\n    moreThanLength(schema: ExclusiveNumericRangeSchema): this;\n    lessThanLength(schema: ExclusiveNumericRangeSchema): this;\n    exactlyLength(schema: ExactLength.Schema): this;\n}\n\ntype instantiateType<t, $> = [\n    t\n] extends [anyOrNever] ? Type<t, $> : [t] extends [object] ? [\n    t\n] extends [array] ? Type$5<t, $> : [t] extends [Date] ? Type$4<t, $> : Type$6<t, $> : [t] extends [string] ? Type$2<t, $> : [t] extends [number] ? Type$3<t, $> : Type<t, $>;\n\ntype StringifiablePrefixOperator = "keyof";\ndeclare const minComparators: {\n    readonly ">": true;\n    readonly ">=": true;\n};\ntype MinComparator = keyof typeof minComparators;\ndeclare const maxComparators: {\n    readonly "<": true;\n    readonly "<=": true;\n};\ntype MaxComparator = keyof typeof maxComparators;\ndeclare const comparators: {\n    ">": boolean;\n    ">=": boolean;\n    "<": boolean;\n    "<=": boolean;\n    "==": boolean;\n};\ntype Comparator = keyof typeof comparators;\ntype InvertedComparators = {\n    "<": ">";\n    ">": "<";\n    "<=": ">=";\n    ">=": "<=";\n    "==": "==";\n};\ntype BranchOperator = "&" | "|" | "|>";\ntype OpenLeftBound = {\n    limit: LimitLiteral;\n    comparator: MinComparator;\n};\ndeclare const writeUnmatchedGroupCloseMessage: <unscanned extends string>(unscanned: unscanned) => writeUnmatchedGroupCloseMessage<unscanned>;\ntype writeUnmatchedGroupCloseMessage<unscanned extends string> = `Unmatched )${unscanned extends "" ? "" : ` before ${unscanned}`}`;\ndeclare const writeUnclosedGroupMessage: <missingChar extends string>(missingChar: missingChar) => writeUnclosedGroupMessage<missingChar>;\ntype writeUnclosedGroupMessage<missingChar extends string> = `Missing ${missingChar}`;\ndeclare const writeOpenRangeMessage: <min extends LimitLiteral, comparator extends MinComparator>(min: min, comparator: comparator) => writeOpenRangeMessage<min, comparator>;\ntype writeOpenRangeMessage<min extends LimitLiteral, comparator extends MinComparator> = `Left bounds are only valid when paired with right bounds (try ...${comparator}${min})`;\ntype writeUnpairableComparatorMessage<comparator extends Comparator> = `Left-bounded expressions must specify their limits using < or <= (was ${comparator})`;\ndeclare const writeUnpairableComparatorMessage: <comparator extends Comparator>(comparator: comparator) => writeUnpairableComparatorMessage<comparator>;\ndeclare const writeMultipleLeftBoundsMessage: <openLimit extends LimitLiteral, openComparator extends MinComparator, limit extends LimitLiteral, comparator extends MinComparator>(openLimit: openLimit, openComparator: openComparator, limit: limit, comparator: comparator) => writeMultipleLeftBoundsMessage<openLimit, openComparator, limit, comparator>;\ntype writeMultipleLeftBoundsMessage<openLimit extends LimitLiteral, openComparator extends MinComparator, limit extends LimitLiteral, comparator extends MinComparator> = `An expression may have at most one left bound (parsed ${openLimit}${InvertedComparators[openComparator]}, ${limit}${InvertedComparators[comparator]})`;\n\ndeclare class ArkTypeScanner<lookahead extends string = string> extends Scanner<lookahead> {\n    shiftUntilNextTerminator(): string;\n    static terminatingChars: {\n        readonly " ": 1;\n        readonly "\\n": 1;\n        readonly "\\t": 1;\n        readonly "<": 1;\n        readonly ">": 1;\n        readonly "=": 1;\n        readonly "|": 1;\n        readonly "&": 1;\n        readonly ")": 1;\n        readonly "[": 1;\n        readonly "%": 1;\n        readonly ",": 1;\n        readonly ":": 1;\n        readonly "?": 1;\n        readonly "#": 1;\n    };\n    static finalizingLookaheads: {\n        readonly ">": 1;\n        readonly ",": 1;\n        readonly "": 1;\n        readonly "=": 1;\n        readonly "?": 1;\n    };\n    static lookaheadIsFinalizing: (lookahead: string, unscanned: string) => lookahead is ">" | "," | "=" | "?";\n}\ndeclare namespace ArkTypeScanner {\n    type lookaheadIsFinalizing<lookahead extends string, unscanned extends string> = lookahead extends ">" ? unscanned extends `=${infer nextUnscanned}` ? nextUnscanned extends `=${string}` ? true : false : ArkTypeScanner.skipWhitespace<unscanned> extends ("" | `${TerminatingChar}${string}`) ? true : false : lookahead extends "=" ? unscanned extends `=${string}` ? false : true : lookahead extends "," | "?" ? true : false;\n    type TerminatingChar = keyof typeof ArkTypeScanner.terminatingChars;\n    type FinalizingLookahead = keyof typeof ArkTypeScanner.finalizingLookaheads;\n    type InfixToken = Comparator | "|" | "&" | "%" | ":" | "=>" | "|>" | "#" | "@" | "=";\n    type PostfixToken = "[]" | "?";\n    type OperatorToken = InfixToken | PostfixToken;\n    type shift<lookahead extends string, unscanned extends string> = `${lookahead}${unscanned}`;\n    type shiftUntil<unscanned extends string, terminator extends string, scanned extends string = ""> = unscanned extends shift<infer lookahead, infer nextUnscanned> ? lookahead extends terminator ? scanned extends `${infer base}${EscapeChar}` ? shiftUntil<nextUnscanned, terminator, `${base}${lookahead}`> : [scanned, unscanned] : shiftUntil<nextUnscanned, terminator, `${scanned}${lookahead}`> : [scanned, ""];\n    type shiftUntilNot<unscanned extends string, nonTerminator extends string, scanned extends string = ""> = unscanned extends shift<infer lookahead, infer nextUnscanned> ? lookahead extends nonTerminator ? shiftUntilNot<nextUnscanned, nonTerminator, `${scanned}${lookahead}`> : [scanned, unscanned] : [scanned, ""];\n    type shiftUntilNextTerminator<unscanned extends string> = shiftUntil<unscanned, TerminatingChar>;\n    type skipWhitespace<unscanned extends string> = shiftUntilNot<unscanned, WhitespaceChar>[1];\n    type shiftResult<scanned extends string, unscanned extends string> = [\n        scanned,\n        unscanned\n    ];\n}\n\ntype astToString<ast> = ast extends InferredAst | DefAst ? ast[2] : ast extends PostfixExpression<infer operator, infer operand> ? operator extends "[]" ? `${astToString<operand>}[]` : never : ast extends InfixExpression<infer operator, infer l, infer r> ? operator extends "&" | "|" | "%" | Comparator ? `${astToString<l>} ${operator} ${astToString<r>}` : never : ast extends Stringifiable ? `${ast extends bigint ? `${ast}n` : ast}` : "...";\ntype writeConstrainedMorphMessage<constrainedAst> = `To constrain the output of ${astToString<constrainedAst>}, pipe like myMorph.to(\'number > 0\').\nTo constrain the input, intersect like myMorph.and(\'number > 0\').`;\n\ntype BranchState$1 = {\n    prefixes: StringifiablePrefixOperator[];\n    leftBound: OpenLeftBound | null;\n    intersection: BaseRoot | null;\n    union: BaseRoot | null;\n    pipe: BaseRoot | null;\n};\ntype DynamicStateWithRoot = requireKeys<DynamicState, "root">;\ndeclare class DynamicState {\n    root: BaseRoot | undefined;\n    branches: BranchState$1;\n    finalizer: ArkTypeScanner.FinalizingLookahead | undefined;\n    groups: BranchState$1[];\n    scanner: ArkTypeScanner;\n    ctx: BaseParseContext;\n    constructor(scanner: ArkTypeScanner, ctx: BaseParseContext);\n    error(message: string): never;\n    hasRoot(): this is DynamicStateWithRoot;\n    setRoot(root: BaseRoot): void;\n    unsetRoot(): this["root"];\n    constrainRoot(...args: Parameters<BaseRoot<any>["constrain"]>): void;\n    finalize(finalizer: ArkTypeScanner.FinalizingLookahead): void;\n    reduceLeftBound(limit: LimitLiteral, comparator: Comparator): void;\n    finalizeBranches(): void;\n    finalizeGroup(): void;\n    addPrefix(prefix: StringifiablePrefixOperator): void;\n    applyPrefixes(): void;\n    pushRootToBranch(token: BranchOperator): void;\n    parseUntilFinalizer(): DynamicStateWithRoot;\n    parseOperator(this: DynamicStateWithRoot): void;\n    parseOperand(): void;\n    private assertRangeUnset;\n    reduceGroupOpen(): void;\n    previousOperator(): MinComparator | StringifiablePrefixOperator | ArkTypeScanner.InfixToken | undefined;\n    shiftedByOne(): this;\n}\n\ntype StaticState = {\n    root: unknown;\n    branches: BranchState;\n    groups: BranchState[];\n    finalizer: ArkTypeScanner.FinalizingLookahead | ErrorMessage | undefined;\n    scanned: string;\n    unscanned: string;\n};\ntype BranchState = {\n    prefixes: StringifiablePrefixOperator[];\n    leftBound: OpenLeftBound | undefined;\n    intersection: unknown;\n    pipe: unknown;\n    union: unknown;\n};\ndeclare namespace state {\n    type initialize<def extends string> = from<{\n        root: undefined;\n        branches: initialBranches;\n        groups: [];\n        finalizer: undefined;\n        scanned: "";\n        unscanned: def;\n    }>;\n    type error<message extends string> = from<{\n        root: ErrorMessage<message>;\n        branches: initialBranches;\n        groups: [];\n        finalizer: ErrorMessage<message>;\n        scanned: "";\n        unscanned: "";\n    }>;\n    type completion<text extends string> = from<{\n        root: Completion<text>;\n        branches: initialBranches;\n        groups: [];\n        finalizer: Completion<text>;\n        scanned: "";\n        unscanned: "";\n    }>;\n    type initialBranches = branchesFrom<{\n        prefixes: [];\n        leftBound: undefined;\n        intersection: undefined;\n        pipe: undefined;\n        union: undefined;\n    }>;\n    type updateScanned<previousScanned extends string, previousUnscanned extends string, updatedUnscanned extends string> = previousUnscanned extends `${infer justScanned}${updatedUnscanned}` ? `${previousScanned}${justScanned}` : previousScanned;\n    type setRoot<s extends StaticState, root, unscanned extends string = s["unscanned"]> = from<{\n        root: root;\n        branches: s["branches"];\n        groups: s["groups"];\n        finalizer: s["finalizer"];\n        scanned: updateScanned<s["scanned"], s["unscanned"], unscanned>;\n        unscanned: unscanned;\n    }>;\n    type addPrefix<s extends StaticState, prefix extends StringifiablePrefixOperator, unscanned extends string = s["unscanned"]> = from<{\n        root: s["root"];\n        branches: {\n            prefixes: [...s["branches"]["prefixes"], prefix];\n            leftBound: s["branches"]["leftBound"];\n            intersection: s["branches"]["intersection"];\n            pipe: s["branches"]["pipe"];\n            union: s["branches"]["union"];\n        };\n        groups: s["groups"];\n        finalizer: s["finalizer"];\n        scanned: updateScanned<s["scanned"], s["unscanned"], unscanned>;\n        unscanned: unscanned;\n    }>;\n    type reduceBranch<s extends StaticState, token extends BranchOperator, unscanned extends string> = s["branches"]["leftBound"] extends {} ? openRangeError<s["branches"]["leftBound"]> : from<{\n        root: undefined;\n        branches: {\n            prefixes: [];\n            leftBound: undefined;\n            intersection: token extends "&" ? mergeToIntersection<s> : undefined;\n            union: token extends "|" ? mergeToUnion<s> : token extends "|>" ? undefined : s["branches"]["union"];\n            pipe: token extends "|>" ? mergeToPipe<s> : s["branches"]["pipe"];\n        };\n        groups: s["groups"];\n        finalizer: s["finalizer"];\n        scanned: updateScanned<s["scanned"], s["unscanned"], unscanned>;\n        unscanned: unscanned;\n    }>;\n    type reduceLeftBound<s extends StaticState, limit extends LimitLiteral, comparator extends Comparator, unscanned extends string> = comparator extends "<" | "<=" ? s["branches"]["leftBound"] extends {} ? state.error<writeMultipleLeftBoundsMessage<s["branches"]["leftBound"]["limit"], s["branches"]["leftBound"]["comparator"], limit, InvertedComparators[comparator]>> : from<{\n        root: undefined;\n        branches: {\n            prefixes: s["branches"]["prefixes"];\n            leftBound: {\n                limit: limit;\n                comparator: InvertedComparators[comparator];\n            };\n            intersection: s["branches"]["intersection"];\n            pipe: s["branches"]["pipe"];\n            union: s["branches"]["union"];\n        };\n        groups: s["groups"];\n        finalizer: s["finalizer"];\n        scanned: updateScanned<s["scanned"], s["unscanned"], unscanned>;\n        unscanned: unscanned;\n    }> : state.error<writeUnpairableComparatorMessage<comparator>>;\n    type reduceRange<s extends StaticState, minLimit extends LimitLiteral, minComparator extends MinComparator, maxComparator extends MaxComparator, maxLimit extends LimitLiteral, unscanned extends string> = state.from<{\n        root: [minLimit, minComparator, [s["root"], maxComparator, maxLimit]];\n        branches: {\n            prefixes: s["branches"]["prefixes"];\n            leftBound: undefined;\n            intersection: s["branches"]["intersection"];\n            pipe: s["branches"]["pipe"];\n            union: s["branches"]["union"];\n        };\n        groups: s["groups"];\n        finalizer: s["finalizer"];\n        scanned: updateScanned<s["scanned"], s["unscanned"], unscanned>;\n        unscanned: unscanned;\n    }>;\n    type reduceSingleBound<s extends StaticState, comparator extends Comparator, limit extends number | string, unscanned extends string> = state.from<{\n        root: [s["root"], comparator, limit];\n        branches: {\n            prefixes: s["branches"]["prefixes"];\n            leftBound: undefined;\n            intersection: s["branches"]["intersection"];\n            pipe: s["branches"]["pipe"];\n            union: s["branches"]["union"];\n        };\n        groups: s["groups"];\n        finalizer: s["finalizer"];\n        scanned: updateScanned<s["scanned"], s["unscanned"], unscanned>;\n        unscanned: unscanned;\n    }>;\n    type mergeToIntersection<s extends StaticState> = s["branches"]["intersection"] extends undefined ? mergePrefixes<s> : [s["branches"]["intersection"], "&", mergePrefixes<s>];\n    type mergeToUnion<s extends StaticState> = s["branches"]["union"] extends undefined ? mergeToIntersection<s> : [s["branches"]["union"], "|", mergeToIntersection<s>];\n    type mergeToPipe<s extends StaticState> = s["branches"]["pipe"] extends undefined ? mergeToUnion<s> : [s["branches"]["pipe"], "|>", mergeToUnion<s>];\n    type mergePrefixes<s extends StaticState, remaining extends unknown[] = s["branches"]["prefixes"]> = remaining extends [infer head, ...infer tail] ? [\n        head,\n        mergePrefixes<s, tail>\n    ] : s["root"];\n    type popGroup<stack extends BranchState[], top extends BranchState> = [\n        ...stack,\n        top\n    ];\n    type finalizeGroup<s extends StaticState, unscanned extends string> = s["branches"]["leftBound"] extends {} ? openRangeError<s["branches"]["leftBound"]> : s["groups"] extends popGroup<infer stack, infer top> ? from<{\n        groups: stack;\n        branches: top;\n        root: mergeToPipe<s>;\n        finalizer: s["finalizer"];\n        scanned: updateScanned<s["scanned"], s["unscanned"], unscanned>;\n        unscanned: unscanned;\n    }> : state.error<writeUnmatchedGroupCloseMessage<unscanned>>;\n    type reduceGroupOpen<s extends StaticState, unscanned extends string> = from<{\n        groups: [...s["groups"], s["branches"]];\n        branches: initialBranches;\n        root: undefined;\n        finalizer: s["finalizer"];\n        scanned: updateScanned<s["scanned"], s["unscanned"], unscanned>;\n        unscanned: unscanned;\n    }>;\n    type finalize<s extends StaticState, finalizer extends ArkTypeScanner.FinalizingLookahead> = s["groups"] extends [] ? s["branches"]["leftBound"] extends {} ? openRangeError<s["branches"]["leftBound"]> : from<{\n        root: mergeToPipe<s>;\n        groups: s["groups"];\n        branches: initialBranches;\n        finalizer: finalizer;\n        scanned: s["scanned"];\n        unscanned: s["unscanned"];\n    }> : state.error<writeUnclosedGroupMessage<")">>;\n    type openRangeError<range extends defined<BranchState["leftBound"]>> = state.error<writeOpenRangeMessage<range["limit"], range["comparator"]>>;\n    type previousOperator<s extends StaticState> = s["branches"]["leftBound"] extends {} ? s["branches"]["leftBound"]["comparator"] : s["branches"]["prefixes"] extends ([\n        ...unknown[],\n        infer tail extends string\n    ]) ? tail : s["branches"]["intersection"] extends {} ? "&" : s["branches"]["union"] extends {} ? "|" : undefined;\n    type scanTo<s extends StaticState, unscanned extends string> = from<{\n        root: s["root"];\n        branches: s["branches"];\n        groups: s["groups"];\n        finalizer: s["finalizer"];\n        scanned: updateScanned<s["scanned"], s["unscanned"], unscanned>;\n        unscanned: unscanned;\n    }>;\n    type from<s extends StaticState> = s;\n    type branchesFrom<b extends BranchState> = b;\n}\n\ntype StringLiteral<Text extends string = string> = DoubleQuotedStringLiteral<Text> | SingleQuotedStringLiteral<Text>;\ntype DoubleQuotedStringLiteral<Text extends string = string> = `"${Text}"`;\ntype SingleQuotedStringLiteral<Text extends string = string> = `\'${Text}\'`;\ndeclare const parseEnclosed: (s: DynamicState, enclosing: EnclosingStartToken) => void;\ntype parseEnclosed<s extends StaticState, enclosingStart extends EnclosingStartToken, unscanned extends string> = ArkTypeScanner.shiftUntil<unscanned, EnclosingTokens[enclosingStart]> extends ArkTypeScanner.shiftResult<infer scanned, infer nextUnscanned> ? nextUnscanned extends "" ? state.error<writeUnterminatedEnclosedMessage<scanned, enclosingStart>> : state.setRoot<s, InferredAst<enclosingStart extends EnclosingQuote ? scanned : enclosingStart extends "/" ? string : Date, `${enclosingStart}${scanned}${EnclosingTokens[enclosingStart]}`>, nextUnscanned extends ArkTypeScanner.shift<string, infer unscanned> ? unscanned : ""> : never;\ndeclare const enclosingQuote: {\n    readonly "\'": 1;\n    readonly \'"\': 1;\n};\ntype EnclosingQuote = keyof typeof enclosingQuote;\ndeclare const enclosingTokens: {\n    readonly "d\'": "\'";\n    readonly \'d"\': "\\"";\n    readonly "\'": "\'";\n    readonly \'"\': "\\"";\n    readonly "/": "/";\n};\ntype EnclosingTokens = typeof enclosingTokens;\ntype EnclosingStartToken = keyof EnclosingTokens;\ndeclare const enclosingCharDescriptions: {\n    readonly \'"\': "double-quote";\n    readonly "\'": "single-quote";\n    readonly "/": "forward slash";\n};\ntype enclosingCharDescriptions = typeof enclosingCharDescriptions;\ndeclare const writeUnterminatedEnclosedMessage: <fragment extends string, enclosingStart extends EnclosingStartToken>(fragment: fragment, enclosingStart: enclosingStart) => writeUnterminatedEnclosedMessage<fragment, enclosingStart>;\ntype writeUnterminatedEnclosedMessage<fragment extends string, enclosingStart extends EnclosingStartToken> = `${enclosingStart}${fragment} requires a closing ${enclosingCharDescriptions[EnclosingTokens[enclosingStart]]}`;\n\ndeclare const parseUnenclosed: (s: DynamicState) => void;\ntype parseUnenclosed<s extends StaticState, $, args> = ArkTypeScanner.shiftUntilNextTerminator<s["unscanned"]> extends (ArkTypeScanner.shiftResult<infer token, infer unscanned>) ? tryResolve<s, unscanned, token, $, args> extends state.from<infer s> ? s : never : never;\ntype parseResolution<s extends StaticState, unscanned extends string, alias extends string, resolution, $, args> = resolutionToAst<alias, resolution> extends infer ast ? ast extends GenericAst ? parseGenericInstantiation<alias, ast, state.scanTo<s, unscanned>, $, args> : state.setRoot<s, ast, unscanned> : never;\ndeclare const parseGenericInstantiation: (name: string, g: GenericRoot, s: DynamicState) => BaseRoot;\ntype parseGenericInstantiation<name extends string, g extends GenericAst, s extends StaticState, $, args> = ArkTypeScanner.skipWhitespace<s["unscanned"]> extends `<${infer unscanned}` ? parseGenericArgs<name, g, unscanned, $, args> extends infer result ? result extends ParsedArgs<infer argAsts, infer nextUnscanned> ? state.setRoot<s, GenericInstantiationAst<g, argAsts>, nextUnscanned> : result : never : state.error<writeInvalidGenericArgCountMessage<name, genericParamNames<g["paramsAst"]>, [\n]>>;\ntype tryResolve<s extends StaticState, unscanned extends string, token extends string, $, args> = token extends keyof args ? parseResolution<s, unscanned, token, args[token], $, args> : token extends keyof $ ? parseResolution<s, unscanned, token, $[token], $, args> : `#${token}` extends keyof $ ? parseResolution<s, unscanned, token, $[`#${token}`], $, args> : token extends keyof ArkAmbient.$ ? parseResolution<s, unscanned, token, ArkAmbient.$[token], $, args> : token extends NumberLiteral<infer n> ? state.setRoot<s, InferredAst<n, token>, unscanned> : token extends (`${infer submodule extends keyof $ & string}.${infer reference}`) ? tryResolveSubmodule<token, $[submodule], reference, s, unscanned, $, args, [\n    submodule\n]> : token extends (`${infer submodule extends keyof ArkAmbient.$ & string}.${infer reference}`) ? tryResolveSubmodule<token, ArkAmbient.$[submodule], reference, s, unscanned, $, args, [\n    submodule\n]> : token extends BigintLiteral<infer b> ? state.setRoot<s, InferredAst<b, token>, unscanned> : token extends "keyof" ? state.addPrefix<s, "keyof", unscanned> : unresolvableState<s, token, $, args, []>;\ntype tryResolveSubmodule<token extends string, resolution, reference extends string, s extends StaticState, unscanned extends string, $, args, submodulePath extends string[]> = resolution extends {\n    [arkKind]: "module";\n} ? reference extends keyof resolution ? parseResolution<s, unscanned, token, resolution[reference], $, args> : reference extends (`${infer nestedSubmodule extends keyof resolution & string}.${infer nestedReference}`) ? tryResolveSubmodule<token, resolution[nestedSubmodule], nestedReference, s, unscanned, $, args, [\n    ...submodulePath,\n    nestedSubmodule\n]> : unresolvableState<s, reference, resolution, {}, submodulePath> : state.error<writeNonSubmoduleDotMessage<lastOf<submodulePath>>>;\n/** Provide valid completions for the current token, or fallback to an\n * unresolvable error if there are none */\ntype unresolvableState<s extends StaticState, token extends string, resolutions, args, submodulePath extends string[]> = [\n    token,\n    s["unscanned"]\n] extends ([\n    "",\n    ArkTypeScanner.shift<"#", infer unscanned>\n]) ? ArkTypeScanner.shiftUntilNextTerminator<unscanned> extends (ArkTypeScanner.shiftResult<infer name, string>) ? state.error<writePrefixedPrivateReferenceMessage<name>> : never : validReferenceFromToken<token, resolutions, args, submodulePath> extends (never) ? state.error<writeUnresolvableMessage<qualifiedReference<token, submodulePath>>> : state.completion<`${s["scanned"]}${qualifiedReference<validReferenceFromToken<token, resolutions, args, submodulePath>, submodulePath>}`>;\ntype qualifiedReference<reference extends string, submodulePath extends string[]> = join<[...submodulePath, reference], ".">;\ntype validReferenceFromToken<token extends string, $, args, submodulePath extends string[]> = Extract<submodulePath["length"] extends 0 ? BaseCompletions<$, args> : resolvableReferenceIn<$>, `${token}${string}`>;\ntype writeMissingRightOperandMessage<token extends string, unscanned extends string = ""> = `Token \'${token}\' requires a right operand${unscanned extends "" ? "" : ` before \'${unscanned}\'`}`;\ndeclare const writeMissingRightOperandMessage: <token extends string, unscanned extends string>(token: token, unscanned?: unscanned) => writeMissingRightOperandMessage<token, unscanned>;\n\ndeclare const parseOperand: (s: DynamicState) => void;\ntype parseOperand<s extends StaticState, $, args> = s["unscanned"] extends (ArkTypeScanner.shift<infer lookahead, infer unscanned>) ? lookahead extends "(" ? state.reduceGroupOpen<s, unscanned> : lookahead extends EnclosingStartToken ? parseEnclosed<s, lookahead, unscanned> : lookahead extends WhitespaceChar ? parseOperand<state.scanTo<s, unscanned>, $, args> : lookahead extends "d" ? unscanned extends (ArkTypeScanner.shift<infer enclosing extends EnclosingQuote, infer nextUnscanned>) ? parseEnclosed<s, `d${enclosing}`, nextUnscanned> : parseUnenclosed<s, $, args> : parseUnenclosed<s, $, args> : state.completion<`${s["scanned"]}${BaseCompletions<$, args>}`>;\n\ntype UnitLiteralKeyword = "null" | "undefined" | "true" | "false";\ntype UnitLiteral = StringLiteral | BigintLiteral | NumberLiteral | DateLiteral | UnitLiteralKeyword;\ntype ParsedDefaultableProperty = readonly [BaseRoot, "=", unknown];\ndeclare const parseDefault: (s: DynamicStateWithRoot) => ParsedDefaultableProperty;\ntype parseDefault<root, unscanned extends string> = trim$1<unscanned> extends infer defaultValue extends UnitLiteral ? [\n    root,\n    "=",\n    defaultValue\n] : ErrorMessage<writeNonLiteralDefaultMessage<trim$1<unscanned>>>;\ndeclare const writeNonLiteralDefaultMessage: <defaultDef extends string>(defaultDef: defaultDef) => writeNonLiteralDefaultMessage<defaultDef>;\ntype writeNonLiteralDefaultMessage<defaultDef extends string> = `Default value \'${defaultDef}\' must a literal value`;\n\ndeclare const parseBound: (s: DynamicStateWithRoot, start: ComparatorStartChar) => void;\ntype parseBound<s extends StaticState, start extends ComparatorStartChar, unscanned extends string, $, args> = shiftComparator<start, unscanned> extends infer shiftResultOrError ? shiftResultOrError extends (ArkTypeScanner.shiftResult<infer comparator extends Comparator, infer nextUnscanned>) ? s["root"] extends (InferredAst<Date | number, `${infer limit extends number | DateLiteral}`>) ? state.reduceLeftBound<s, limit, comparator, nextUnscanned> : parseRightBound<state.scanTo<s, nextUnscanned>, comparator, $, args> : shiftResultOrError : never;\ntype OneCharComparator = ">" | "<";\ntype ComparatorStartChar = Comparator extends `${infer char}${string}` ? char : never;\ndeclare const shiftComparator: (s: DynamicState, start: ComparatorStartChar) => Comparator;\ntype shiftComparator<start extends ComparatorStartChar, unscanned extends string> = unscanned extends `=${infer nextUnscanned}` ? [`${start}=`, nextUnscanned] : [start & OneCharComparator, unscanned];\ndeclare const parseRightBound: (s: DynamicStateWithRoot, comparator: Comparator) => void;\ntype parseRightBound<s extends StaticState, comparator extends Comparator, $, args> = parseOperand<s, $, args> extends infer nextState extends StaticState ? nextState["root"] extends (InferredAst<unknown, `${infer limit extends number | DateLiteral}`>) ? s["branches"]["leftBound"] extends {} ? comparator extends MaxComparator ? state.reduceRange<s, s["branches"]["leftBound"]["limit"], s["branches"]["leftBound"]["comparator"], comparator, limit, nextState["unscanned"]> : state.error<writeUnpairableComparatorMessage<comparator>> : state.reduceSingleBound<s, comparator, limit, nextState["unscanned"]> : state.error<writeInvalidLimitMessage<comparator, astToString<nextState["root"]>, "right">> : never;\ndeclare const writeInvalidLimitMessage: <comparator extends Comparator, limit extends string | number, boundKind extends BoundExpressionKind>(comparator: comparator, limit: limit, boundKind: boundKind) => writeInvalidLimitMessage<comparator, limit, boundKind>;\ntype writeInvalidLimitMessage<comparator extends Comparator, limit extends string | number, boundKind extends BoundExpressionKind> = `Comparator ${boundKind extends "left" ? InvertedComparators[comparator] : comparator} must be ${boundKind extends "left" ? "preceded" : "followed"} by a corresponding literal (was ${limit})`;\ntype BoundExpressionKind = "left" | "right";\n\ndeclare const parseBrand: (s: DynamicStateWithRoot) => void;\ntype parseBrand<s extends StaticState, unscanned extends string> = ArkTypeScanner.shiftUntilNextTerminator<ArkTypeScanner.skipWhitespace<unscanned>> extends (ArkTypeScanner.shiftResult<`${infer brandName}`, infer nextUnscanned>) ? brandName extends "" ? state.error<emptyBrandNameMessage> : state.setRoot<s, [s["root"], "#", brandName], nextUnscanned> : never;\n\ndeclare const parseDivisor: (s: DynamicStateWithRoot) => void;\ntype parseDivisor<s extends StaticState, unscanned extends string> = ArkTypeScanner.shiftUntilNextTerminator<ArkTypeScanner.skipWhitespace<unscanned>> extends ArkTypeScanner.shiftResult<infer scanned, infer nextUnscanned> ? scanned extends `${infer divisor extends number}` ? divisor extends 0 ? state.error<writeInvalidDivisorMessage<0>> : state.setRoot<s, [s["root"], "%", divisor], nextUnscanned> : state.error<writeInvalidDivisorMessage<scanned>> : never;\ndeclare const writeInvalidDivisorMessage: <divisor extends string | number>(divisor: divisor) => writeInvalidDivisorMessage<divisor>;\ntype writeInvalidDivisorMessage<divisor extends string | number> = `% operator must be followed by a non-zero integer literal (was ${divisor})`;\n\ndeclare const parseOperator: (s: DynamicStateWithRoot) => void;\ntype parseOperator<s extends StaticState, $, args> = s["unscanned"] extends (ArkTypeScanner.shift<infer lookahead, infer unscanned>) ? lookahead extends "[" ? unscanned extends ArkTypeScanner.shift<"]", infer nextUnscanned> ? state.setRoot<s, [s["root"], "[]"], nextUnscanned> : state.error<incompleteArrayTokenMessage> : lookahead extends "|" ? unscanned extends ArkTypeScanner.shift<">", infer nextUnscanned> ? state.reduceBranch<s, "|>", nextUnscanned> : state.reduceBranch<s, lookahead, unscanned> : lookahead extends "&" ? state.reduceBranch<s, lookahead, unscanned> : lookahead extends ")" ? state.finalizeGroup<s, unscanned> : ArkTypeScanner.lookaheadIsFinalizing<lookahead, unscanned> extends true ? state.finalize<state.scanTo<s, unscanned>, lookahead & ArkTypeScanner.FinalizingLookahead> : lookahead extends ComparatorStartChar ? parseBound<s, lookahead, unscanned, $, args> : lookahead extends "%" ? parseDivisor<s, unscanned> : lookahead extends "#" ? parseBrand<s, unscanned> : lookahead extends WhitespaceChar ? parseOperator<state.scanTo<s, unscanned>, $, args> : state.error<writeUnexpectedCharacterMessage<lookahead>> : state.finalize<s, "">;\ndeclare const writeUnexpectedCharacterMessage: <char extends string, shouldBe extends string>(char: char, shouldBe?: shouldBe) => writeUnexpectedCharacterMessage<char, shouldBe>;\ntype writeUnexpectedCharacterMessage<char extends string, shouldBe extends string = ""> = `\'${char}\' is not allowed here${shouldBe extends "" ? "" : ` (should be ${shouldBe})`}`;\ndeclare const incompleteArrayTokenMessage = "Missing expected \']\'";\ntype incompleteArrayTokenMessage = typeof incompleteArrayTokenMessage;\n\ndeclare const parseString: (def: string, ctx: BaseParseContext) => InnerParseResult;\n/**\n * Try to parse the definition from right to left using the most common syntax.\n * This can be much more efficient for simple definitions.\n */\ntype parseString<def extends string, $, args> = def extends keyof $ ? resolutionToAst<def, $[def]> : def extends `${infer child}[]` ? child extends keyof $ ? [\n    resolutionToAst<child, $[child]>,\n    "[]"\n] : fullStringParse<state.initialize<def>, $, args> : fullStringParse<state.initialize<def>, $, args>;\ntype inferString<def extends string, $, args> = inferAstRoot<parseString<def, $, args>, $, args>;\ntype BaseCompletions<$, args, otherSuggestions extends string = never> = resolvableReferenceIn<$> | resolvableReferenceIn<ArkAmbient.$> | (keyof args & string) | StringifiablePrefixOperator | otherSuggestions;\ndeclare const fullStringParse: (s: DynamicState) => InnerParseResult;\ntype fullStringParse<s extends StaticState, $, args> = extractFinalizedResult<parseUntilFinalizer<s, $, args>>;\ndeclare const parseUntilFinalizer: (s: DynamicState) => DynamicStateWithRoot;\ntype parseUntilFinalizer<s extends StaticState, $, args> = s["finalizer"] extends undefined ? parseUntilFinalizer<next<s, $, args>, $, args> : s;\ndeclare const next: (s: DynamicState) => void;\ntype next<s extends StaticState, $, args> = s["root"] extends undefined ? parseOperand<s, $, args> : parseOperator<s, $, args>;\ntype extractFinalizedResult<s extends StaticState> = s["finalizer"] extends "" ? s["root"] : s["finalizer"] extends ErrorMessage ? s["finalizer"] : s["finalizer"] extends "?" ? [s["root"], "?"] : s["finalizer"] extends "=" ? parseDefault<s["root"], s["unscanned"]> : ErrorMessage<writeUnexpectedCharacterMessage<s["finalizer"] & string>>;\n\ndeclare const parseGenericArgs: (name: string, g: GenericRoot, s: DynamicState) => BaseRoot[];\ntype parseGenericArgs<name extends string, g extends GenericAst, unscanned extends string, $, args> = _parseGenericArgs<name, g, unscanned, $, args, [], []>;\ntype ParsedArgs<result extends unknown[] = unknown[], unscanned extends string = string> = {\n    result: result;\n    unscanned: unscanned;\n};\ndeclare const _parseGenericArgs: (name: string, g: GenericRoot, s: DynamicState, argNodes: BaseRoot[]) => BaseRoot[];\ntype _parseGenericArgs<name extends string, g extends GenericAst, unscanned extends string, $, args, argDefs extends string[], argAsts extends unknown[]> = parseUntilFinalizer<state.initialize<unscanned>, $, args> extends (infer finalArgState extends StaticState) ? {\n    defs: [\n        ...argDefs,\n        finalArgState["scanned"] extends `${infer def}${"," | ">"}` ? def : finalArgState["scanned"]\n    ];\n    asts: [...argAsts, finalArgState["root"]];\n    unscanned: finalArgState["unscanned"];\n} extends ({\n    defs: infer nextDefs extends string[];\n    asts: infer nextAsts extends unknown[];\n    unscanned: infer nextUnscanned extends string;\n}) ? finalArgState["finalizer"] extends ">" ? nextAsts["length"] extends g["paramsAst"]["length"] ? ParsedArgs<nextAsts, nextUnscanned> : state.error<writeInvalidGenericArgCountMessage<name, genericParamNames<g["paramsAst"]>, nextDefs>> : finalArgState["finalizer"] extends "," ? _parseGenericArgs<name, g, nextUnscanned, $, args, nextDefs, nextAsts> : finalArgState["finalizer"] extends ErrorMessage ? finalArgState : state.error<writeUnclosedGroupMessage<">">> : never : never;\ndeclare const writeInvalidGenericArgCountMessage: <name extends string, params extends array<string>, argDefs extends array<string>>(name: name, params: params, argDefs: argDefs) => writeInvalidGenericArgCountMessage<name, params, argDefs>;\ntype writeInvalidGenericArgCountMessage<name extends string, params extends array<string>, argDefs extends array<string>> = `${name}<${join<params, ", ">}> requires exactly ${params["length"]} args (got ${argDefs["length"]}${argDefs["length"] extends (0) ? "" : `: ${join<argDefs, ",">}`})`;\n\ntype validateRange<l, comparator extends Comparator, r, $, args> = [\n    l\n] extends [LimitLiteral] ? validateBound<r, comparator, l, "left", $, args> : [l] extends [[infer leftAst, Comparator, unknown]] ? ErrorMessage<writeDoubleRightBoundMessage<astToString<leftAst>>> : validateBound<l, comparator, r & LimitLiteral, "right", $, args>;\ntype validateBound<boundedAst, comparator extends Comparator, limit extends LimitLiteral, boundKind extends BoundExpressionKind, $, args> = inferAstRoot<boundedAst, $, args> extends infer bounded ? isNumericallyBoundable<bounded> extends true ? limit extends number ? validateAst<boundedAst, $, args> : ErrorMessage<writeInvalidLimitMessage<comparator, limit, boundKind>> : [bounded] extends [Date] ? validateAst<boundedAst, $, args> : [bounded] extends [InferredMorph] ? ErrorMessage<writeConstrainedMorphMessage<boundedAst>> : ErrorMessage<writeUnboundableMessage<typeToString<bounded>>> : never;\ntype isNumericallyBoundable<bounded> = [\n    bounded\n] extends [number] ? true : [bounded] extends [string] ? true : [bounded] extends [array] ? true : false;\ndeclare const writeDoubleRightBoundMessage: <root extends string>(root: root) => writeDoubleRightBoundMessage<root>;\ntype writeDoubleRightBoundMessage<root extends string> = `Expression ${root} must have at most one right bound`;\n\ntype validateDefault<baseAst, unitLiteral extends UnitLiteral, $, args> = validateAst<baseAst, $, args> extends infer e extends ErrorMessage ? e : type.infer<unitLiteral> extends inferAstIn<baseAst, $, args> ? undefined : ErrorMessage<writeUnassignableDefaultValueMessage<astToString<baseAst>, unitLiteral>>;\n\ntype validateDivisor<l, $, args> = inferAstRoot<l, $, args> extends infer data ? [\n    data\n] extends [number] ? validateAst<l, $, args> : [data] extends [InferredMorph] ? ErrorMessage<writeConstrainedMorphMessage<l>> : ErrorMessage<writeIndivisibleMessage<data>> : never;\n\ntype validateKeyof<operandAst, $, args> = inferAstRoot<operandAst, $, args> extends infer data ? [\n    data\n] extends [object] ? validateAst<operandAst, $, args> : ErrorMessage<writeNonStructuralOperandMessage<"keyof", typeToString<data>>> : never;\n\ntype validateAst<ast, $, args> = ast extends ErrorMessage ? ast : ast extends InferredAst ? validateInferredAst<ast[0], ast[2]> : ast extends DefAst ? ast[2] extends PrivateDeclaration<infer name> ? ErrorMessage<writePrefixedPrivateReferenceMessage<name>> : undefined : ast extends PostfixExpression<"[]" | "?", infer operand> ? validateAst<operand, $, args> : ast extends InfixExpression<infer operator, infer l, infer r> ? operator extends BranchOperator ? validateInfix<ast, $, args> : operator extends Comparator ? validateRange<l, operator, r, $, args> : operator extends "%" ? validateDivisor<l, $, args> : operator extends "=" ? validateDefault<l, r & UnitLiteral, $, args> : operator extends "#" ? validateAst<l, $, args> : ErrorMessage<writeUnexpectedExpressionMessage<astToString<ast>>> : ast extends ["keyof", infer operand] ? validateKeyof<operand, $, args> : ast extends GenericInstantiationAst<infer g, infer argAsts> ? validateGenericInstantiation<g, argAsts, $, args> : ErrorMessage<writeUnexpectedExpressionMessage<astToString<ast>>> & {\n    ast: ast;\n};\ntype writeUnexpectedExpressionMessage<expression extends string> = `Failed to parse the expression resulting from ${expression}`;\ndeclare const writePrefixedPrivateReferenceMessage: <name extends string>(name: name) => writePrefixedPrivateReferenceMessage<name>;\ntype writePrefixedPrivateReferenceMessage<name extends string> = `Private type references should not include \'#\'. Use \'${name}\' instead.`;\ntype validateInferredAst<inferred, def extends string> = def extends NumberLiteral ? number extends inferred ? ErrorMessage<writeMalformedNumericLiteralMessage<def, "number">> : undefined : def extends BigintLiteral ? bigint extends inferred ? ErrorMessage<writeMalformedNumericLiteralMessage<def, "bigint">> : undefined : [inferred] extends [anyOrNever] ? undefined : def extends PrivateDeclaration<infer name> ? ErrorMessage<writePrefixedPrivateReferenceMessage<name>> : inferred extends Generic ? ErrorMessage<writeInvalidGenericArgCountMessage<def, inferred["names"], []>> : inferred extends {\n    [arkKind]: "module";\n} ? "root" extends keyof inferred ? undefined : ErrorMessage<writeMissingSubmoduleAccessMessage<def>> : def extends ErrorMessage ? def : undefined;\ntype validateString<def extends string, $, args> = parseString<def, $, args> extends infer ast ? validateAst<ast, $, args> extends infer result extends ErrorMessage ? result extends Completion<infer text> ? text : result : def : never;\ntype validateInfix<ast extends InfixExpression, $, args> = validateAst<ast[0], $, args> extends infer e extends ErrorMessage ? e : validateAst<ast[2], $, args> extends infer e extends ErrorMessage ? e : undefined;\ndeclare const shallowOptionalMessage = "Optional definitions like \'string?\' are only valid as properties in an object or tuple";\ntype shallowOptionalMessage = typeof shallowOptionalMessage;\ndeclare const shallowDefaultableMessage = "Defaultable definitions like \'number = 0\' are only valid as properties in an object or tuple";\ntype shallowDefaultableMessage = typeof shallowDefaultableMessage;\n\ntype GenericInstantiationAst<generic extends GenericAst = GenericAst, argAsts extends unknown[] = unknown[]> = [generic, "<>", argAsts];\ntype inferGenericInstantiation<g extends GenericAst, argAsts extends unknown[], $, args> = g["bodyDef"] extends Hkt ? Hkt.apply<g["bodyDef"], {\n    [i in keyof argAsts]: inferExpression<argAsts[i], $, args>;\n}> : inferDefinition<g["bodyDef"], resolveScope<g["$"], $>, {\n    [i in keyof g["names"] & `${number}` as g["names"][i]]: inferExpression<argAsts[i & keyof argAsts], resolveScope<g["arg$"], $>, args>;\n}>;\ntype validateGenericInstantiation<g extends GenericAst, argAsts extends unknown[], $, args> = validateGenericArgs<g["paramsAst"], argAsts, $, args, []>;\ntype validateGenericArgs<params extends array<GenericParamAst>, argAsts extends array, $, args, indices extends 1[]> = argAsts extends readonly [infer arg, ...infer argsTail] ? validateAst<arg, $, args> extends infer e extends ErrorMessage ? e : inferAstRoot<arg, $, args> extends params[indices["length"]][1] ? validateGenericArgs<params, argsTail, $, args, [...indices, 1]> : ErrorMessage<writeUnsatisfiedParameterConstraintMessage<params[indices["length"]][0], typeToString<params[indices["length"]][1]>, astToString<arg>>> : undefined;\ntype resolveScope<g$, $> = g$ extends UnparsedScope ? $ : g$;\n\ntype inferAstRoot<ast, $, args> = ast extends array ? inferExpression<ast, $, args> : never;\ntype inferAstIn<ast, $, args> = distill.In<inferAstRoot<ast, $, args>>;\ntype DefAst<def = unknown, alias extends string = string> = [\n    def,\n    "def",\n    alias\n];\ntype InferredAst<t = unknown, def extends string = string> = [\n    t,\n    "inferred",\n    def\n];\ntype inferExpression<ast, $, args> = ast extends array ? ast extends InferredAst<infer resolution> ? resolution : ast extends DefAst<infer def> ? inferDefinition<def, $, args> : ast extends GenericInstantiationAst<infer g, infer argAsts> ? inferGenericInstantiation<g, argAsts, $, args> : ast[1] extends "[]" ? inferExpression<ast[0], $, args>[] : ast[1] extends "|" ? inferExpression<ast[0], $, args> | inferExpression<ast[2], $, args> : ast[1] extends "&" ? inferIntersection<inferExpression<ast[0], $, args>, inferExpression<ast[2], $, args>> : ast[1] extends "|>" ? inferPipe<inferExpression<ast[0], $, args>, inferExpression<ast[2], $, args>> : ast[1] extends "=" ? type.infer<ast[2]> extends infer defaultValue ? withDefault<inferExpression<ast[0], $, args>, defaultValue> : never : ast[1] extends "#" ? type.brand<inferExpression<ast[0], $, args>, ast[2]> : ast[1] extends Comparator ? ast[0] extends LimitLiteral ? inferExpression<ast[2], $, args> : inferExpression<ast[0], $, args> : ast[1] extends "%" ? inferExpression<ast[0], $, args> : ast[1] extends "?" ? inferExpression<ast[0], $, args> : ast[0] extends "keyof" ? arkKeyOf<inferExpression<ast[1], $, args>> : never : never;\ntype PostfixExpression<operator extends ArkTypeScanner.PostfixToken = ArkTypeScanner.PostfixToken, operand = unknown> = readonly [operand, operator];\ntype InfixExpression<operator extends ArkTypeScanner.InfixToken = ArkTypeScanner.InfixToken, l = unknown, r = unknown> = [l, operator, r];\n\ntype inferObjectLiteral<def extends object, $, args> = show<"..." extends keyof def ? merge<inferDefinition<def["..."], $, args>, _inferObjectLiteral<def, $, args>> : _inferObjectLiteral<def, $, args>>;\n/**\n * Infers the contents of an object literal, ignoring a spread definition\n */\ntype _inferObjectLiteral<def extends object, $, args> = {\n    -readonly [k in keyof def as nonOptionalKeyFromEntry<k, def[k], $, args>]: inferDefinition<def[k], $, args>;\n} & {\n    -readonly [k in keyof def as optionalKeyFromEntry<k, def[k]>]?: def[k] extends OptionalPropertyDefinition<infer baseDef> ? inferDefinition<baseDef, $, args> : inferDefinition<def[k], $, args>;\n};\ntype validateObjectLiteral<def, $, args> = {\n    [k in keyof def]: preparseKey<k> extends (infer parsedKey extends PreparsedKey) ? parsedKey extends PreparsedEntryKey<"index"> ? validateString<parsedKey["normalized"], $, args> extends (ErrorMessage<infer message>) ? ErrorType<message> : inferDefinition<parsedKey["normalized"], $, args> extends Key ? validateProperty<def[k], parsedKey["kind"], $, args> : ErrorMessage<writeInvalidPropertyKeyMessage<parsedKey["normalized"]>> : validateProperty<def[k], parsedKey["kind"], $, args> : never;\n};\ntype nonOptionalKeyFromEntry<k extends PropertyKey, v, $, args> = preparseKey<k> extends infer parsedKey ? parsedKey extends PreparsedEntryKey<"required"> ? [\n    v\n] extends [OptionalPropertyDefinition] ? [\n    v\n] extends [anyOrNever] ? parsedKey["normalized"] : never : parsedKey["normalized"] : parsedKey extends PreparsedEntryKey<"index"> ? inferDefinition<parsedKey["normalized"], $, args> & Key : never : never;\ntype optionalKeyFromEntry<k extends PropertyKey, v> = preparseKey<k> extends infer parsedKey ? parsedKey extends PreparsedEntryKey<"optional"> ? parsedKey["normalized"] : v extends OptionalPropertyDefinition ? k : never : never;\ntype normalizedKeyKind<kind extends EntryKeyKind> = kind extends "index" ? string : Key;\ntype PreparsedEntryKey<kind extends EntryKeyKind = EntryKeyKind, normalized extends normalizedKeyKind<kind> = normalizedKeyKind<kind>> = {\n    kind: kind;\n    normalized: normalized;\n};\ntype PreparsedSpecialKey<kind extends SpecialKeyKind = SpecialKeyKind> = {\n    kind: kind;\n};\ntype PreparsedKey = PreparsedEntryKey | PreparsedSpecialKey;\ndeclare namespace PreparsedKey {\n    type from<t extends PreparsedKey> = t;\n}\ntype ParsedKeyKind = EntryKeyKind | SpecialKeyKind;\ntype EntryKeyKind = "required" | "optional" | "index";\ntype SpecialKeyKind = "spread" | "undeclared";\ntype MetaKey = "..." | "+";\ntype IndexKey<def extends string = string> = `[${def}]`;\ndeclare const preparseKey: (key: Key) => PreparsedKey;\ntype preparseKey<k> = k extends symbol ? PreparsedKey.from<{\n    kind: "required";\n    normalized: k;\n}> : k extends `${infer inner}?` ? inner extends `${infer baseName}${EscapeChar}` ? PreparsedKey.from<{\n    kind: "required";\n    normalized: `${baseName}?`;\n}> : PreparsedKey.from<{\n    kind: "optional";\n    normalized: inner;\n}> : k extends "+" ? {\n    kind: "undeclared";\n} : k extends "..." ? {\n    kind: "spread";\n} : k extends `${EscapeChar}${infer escapedMeta extends MetaKey}` ? PreparsedKey.from<{\n    kind: "required";\n    normalized: escapedMeta;\n}> : k extends IndexKey<infer def> ? PreparsedKey.from<{\n    kind: "index";\n    normalized: def;\n}> : PreparsedKey.from<{\n    kind: "required";\n    normalized: k extends (`${EscapeChar}${infer escapedIndexKey extends IndexKey}`) ? escapedIndexKey : k extends Key ? k : `${k & number}`;\n}>;\ndeclare const writeInvalidSpreadTypeMessage: <def extends string>(def: def) => writeInvalidSpreadTypeMessage<def>;\ntype writeInvalidSpreadTypeMessage<def extends string> = `Spread operand must resolve to an object literal type (was ${def})`;\n\ntype ParsedOptionalProperty = readonly [BaseRoot, "?"];\ntype validateProperty<def, keyKind extends ParsedKeyKind, $, args> = [\n    def\n] extends [anyOrNever] ? \n/** this extra [anyOrNever] check is required to ensure that nested `type` invocations\n * like the following are not prematurely validated by the outer call:\n *\n * ```ts\n * type({\n * \t"test?": type("string").pipe(x => x === "true")\n * })\n * ```\n */\ndef : keyKind extends "spread" ? def extends validateInnerDefinition<def, $, args> ? inferDefinition<def, $, args> extends object ? def : ErrorType<writeInvalidSpreadTypeMessage<typeToString<inferDefinition<def, $, args>>>> : validateInnerDefinition<def, $, args> : keyKind extends "undeclared" ? UndeclaredKeyBehavior : keyKind extends "required" ? validateInnerDefinition<def, $, args> : def extends OptionalPropertyDefinition ? ErrorMessage<invalidOptionalKeyKindMessage> : isDefaultable<def, $, args> extends true ? ErrorMessage<invalidDefaultableKeyKindMessage> : validateInnerDefinition<def, $, args>;\ntype isDefaultable<def, $, args> = def extends DefaultablePropertyTuple ? true : def extends PossibleDefaultableStringDefinition ? parseString<def, $, args> extends DefaultablePropertyTuple ? true : false : false;\ntype OptionalPropertyDefinition<baseDef = unknown> = OptionalPropertyTuple<baseDef> | OptionalPropertyString<baseDef & string>;\ntype OptionalPropertyString<baseDef extends string = string> = `${baseDef}?`;\ntype OptionalPropertyTuple<baseDef = unknown> = readonly [baseDef, "?"];\ntype PossibleDefaultableStringDefinition = `${string}=${string}`;\ntype DefaultablePropertyTuple<baseDef = unknown, thunkableProperty = unknown> = readonly [baseDef, "=", thunkableProperty];\ndeclare const invalidOptionalKeyKindMessage = "Only required keys may make their values optional, e.g. { [mySymbol]: [\'number\', \'?\'] }";\ntype invalidOptionalKeyKindMessage = typeof invalidOptionalKeyKindMessage;\ndeclare const invalidDefaultableKeyKindMessage = "Only required keys may specify default values, e.g. { value: \'number = 0\' }";\ntype invalidDefaultableKeyKindMessage = typeof invalidDefaultableKeyKindMessage;\n\ninterface ArkScopeConfig extends ArkSchemaScopeConfig {\n}\ninterface ScopeParser {\n    <const def>(def: scope.validate<def>, config?: ArkScopeConfig): Scope<scope.infer<def>>;\n    define: <const def>(def: scope.validate<def>) => def;\n}\ntype ModuleParser = <const def>(def: scope.validate<def>, config?: ArkScopeConfig) => scope.infer<def> extends infer $ ? Module<{\n    [k in exportedNameOf<$>]: $[k];\n}> : never;\ntype bindThis<def> = {\n    this: Def<def>;\n};\n/** nominal type for an unparsed definition used during scope bootstrapping */\ntype Def<def = {}> = Brand<def, "unparsed">;\n/** sentinel indicating a scope that will be associated with a generic has not yet been parsed */\ntype UnparsedScope = "$";\n/** These are legal as values of a scope but not as definitions in other contexts */\ntype PreparsedResolution = PreparsedNodeResolution;\ntype bootstrapAliases<def> = {\n    [k in Exclude<keyof def, GenericDeclaration>]: def[k] extends (PreparsedResolution) ? def[k] extends {\n        t: infer g extends GenericAst;\n    } ? g : def[k] extends Module<infer $> | BoundModule<infer $, any> ? Submodule<$> : def[k] : def[k] extends (() => infer thunkReturn extends PreparsedResolution) ? thunkReturn extends {\n        t: infer g extends GenericAst;\n    } ? g : thunkReturn extends Module<infer $> | BoundModule<infer $, any> ? Submodule<$> : thunkReturn : Def<def[k]>;\n} & {\n    [k in keyof def & GenericDeclaration as extractGenericName<k>]: GenericAst<parseValidGenericParams<extractGenericParameters<k>, bootstrapAliases<def>>, def[k], UnparsedScope>;\n};\ntype inferBootstrapped<$> = {\n    [name in keyof $]: $[name] extends Def<infer def> ? inferDefinition<def, $, {}> : $[name] extends {\n        t: infer g extends GenericAst;\n    } ? bindGenericToScope<g, $> : $[name];\n} & unknown;\ntype bindGenericToScope<g extends GenericAst, $> = GenericAst<g["paramsAst"], g["bodyDef"], g["$"] extends UnparsedScope ? $ : g["$"], $>;\ntype extractGenericName<k> = k extends GenericDeclaration<infer name> ? name : never;\ntype extractGenericParameters<k> = k extends `${string}<${infer params}>` ? ParameterString<params> : never;\ntype resolutionToAst<alias extends string, resolution> = [\n    resolution\n] extends [anyOrNever] ? InferredAst<resolution, alias> : resolution extends Def<infer def> ? DefAst<def, alias> : resolution extends {\n    [arkKind]: "module";\n    root: infer root;\n} ? InferredAst<root, alias> : resolution extends GenericAst ? resolution : InferredAst<resolution, alias>;\ninterface InternalScope {\n    constructor: typeof InternalScope;\n}\ndeclare class InternalScope<$ extends {} = {}> extends BaseScope<$> {\n    get ambientAttachments(): Ark.boundTypeAttachments<$> | undefined;\n    protected preparseOwnAliasEntry(alias: string, def: unknown): AliasDefEntry;\n    parseGenericParams(def: string, opts: BaseParseOptions): array<GenericParamDef>;\n    protected normalizeRootScopeValue(resolution: unknown): unknown;\n    protected preparseOwnDefinitionFormat(def: unknown, opts: BaseParseOptions): BaseRoot | BaseParseContextInput;\n    parseOwnDefinitionFormat(def: unknown, ctx: BaseParseContext): BaseRoot;\n    unit: UnitTypeParser<$>;\n    valueOf: ValueOfTypeParser<$>;\n    enumerated: EnumeratedTypeParser<$>;\n    instanceOf: InstanceOfTypeParser<$>;\n    or: NaryUnionParser<$>;\n    and: NaryIntersectionParser<$>;\n    merge: NaryMergeParser<$>;\n    pipe: NaryPipeParser<$>;\n    match: InternalMatchParser;\n    declare: () => {\n        type: InternalTypeParser;\n    };\n    define<def>(def: def): def;\n    type: InternalTypeParser;\n    static scope: ScopeParser;\n    static module: ModuleParser;\n}\ndeclare const scope: ScopeParser;\ndeclare namespace scope {\n    type validate<def> = {\n        [k in keyof def]: k extends noSuggest ? unknown : parseScopeKey<k, def>["params"] extends infer params ? params extends array<GenericParamAst> ? params["length"] extends 0 ? def[k] extends type.Any | PreparsedResolution ? def[k] : k extends (PrivateDeclaration<infer name extends keyof def & string>) ? ErrorType<writeDuplicateAliasError<name>> : type.validate<def[k], bootstrapAliases<def>, {}> : type.validate<def[k], bootstrapAliases<def>, baseGenericConstraints<params>> : params : never;\n    };\n    type infer<def> = inferBootstrapped<bootstrapAliases<def>>;\n}\ninterface ScopeConstructor {\n    new <$ = {}>(...args: ConstructorParameters<typeof InternalScope>): Scope<$>;\n    scope: ScopeParser;\n    module: ModuleParser;\n}\ninterface Scope<$ = {}> {\n    t: $;\n    [arkKind]: "scope";\n    config: ArkScopeConfig;\n    references: readonly BaseNode[];\n    json: JsonStructure;\n    exportedNames: array<exportedNameOf<$>>;\n    /** The set of names defined at the root-level of the scope mapped to their\n     * corresponding definitions.**/\n    aliases: Record<string, unknown>;\n    internal: toInternalScope<$>;\n    defineSchema<const def extends RootSchema>(schema: def): def;\n    node<kinds extends NodeKind | array<RootKind>>(kinds: kinds, schema: NodeSchema<flattenListable<kinds>>, opts?: BaseParseOptions): nodeOfKind<reducibleKindOf<flattenListable<kinds>>>;\n    unit: UnitTypeParser<$>;\n    enumerated: EnumeratedTypeParser<$>;\n    valueOf: ValueOfTypeParser<$>;\n    instanceOf: InstanceOfTypeParser<$>;\n    type: TypeParser<$>;\n    match: MatchParser<$>;\n    declare: DeclarationParser<$>;\n    define: DefinitionParser<$>;\n    generic: GenericParser<$>;\n    schema: SchemaParser<$>;\n    import(): Module<{\n        [k in exportedNameOf<$> as PrivateDeclaration<k>]: $[k];\n    }>;\n    import<names extends exportedNameOf<$>[]>(...names: names): BoundModule<{\n        [k in names[number] as PrivateDeclaration<k>]: $[k];\n    } & unknown, $>;\n    export(): Module<{\n        [k in exportedNameOf<$>]: $[k];\n    }>;\n    export<names extends exportedNameOf<$>[]>(...names: names): BoundModule<{\n        [k in names[number]]: $[k];\n    } & unknown, $>;\n    resolve<name extends exportedNameOf<$>>(name: name): instantiateExport<$[name], $>;\n}\ndeclare const Scope: ScopeConstructor;\ntype parseScopeKey<k, def> = k extends `${infer name}<${infer params}>` ? parseGenericScopeKey<name, params, def> : {\n    name: k;\n    params: [];\n};\ntype parseGenericScopeKey<name extends string, params extends string, def> = {\n    name: name;\n    params: parseGenericParams<params, bootstrapAliases<def>>;\n};\ntype InnerParseResult = BaseRoot | ParsedOptionalProperty | ParsedDefaultableProperty;\n\ntype maybeValidateTupleExpression<def extends array, $, args> = def extends IndexZeroExpression ? validatePrefixExpression<def, $, args> : def extends IndexOneExpression ? validateIndexOneExpression<def, $, args> : def extends (readonly ["", ...unknown[]] | readonly [unknown, "", ...unknown[]]) ? readonly [\n    def[0] extends "" ? BaseCompletions<$, args, IndexZeroOperator | "..."> : def[0],\n    def[1] extends "" ? BaseCompletions<$, args, IndexOneOperator | "..."> : def[1]\n] : null;\ntype inferTupleExpression<def extends TupleExpression, $, args> = def[1] extends "[]" ? inferDefinition<def[0], $, args>[] : def[1] extends "?" ? inferDefinition<def[0], $, args> : def[1] extends "&" ? inferIntersection<inferDefinition<def[0], $, args>, inferDefinition<def[2], $, args>> : def[1] extends "|" ? inferDefinition<def[0], $, args> | inferDefinition<def[2], $, args> : def[1] extends ":" ? inferPredicate<inferDefinition<def[0], $, args>, def[2]> : def[1] extends "=>" ? parseMorph<def[0], def[2], $, args> : def[1] extends "|>" ? parseTo<def[0], def[2], $, args> : def[1] extends "=" ? withDefault<inferDefinition<def[0], $, args>, unwrapDefault<def[2]>> : def[1] extends "@" ? inferDefinition<def[0], $, args> : def extends readonly ["===", ...infer values] ? values[number] : def extends (readonly ["instanceof", ...infer constructors extends Constructor[]]) ? InstanceType<constructors[number]> : def[0] extends "keyof" ? inferKeyOfExpression<def[1], $, args> : never;\ntype validatePrefixExpression<def extends IndexZeroExpression, $, args> = def["length"] extends 1 ? readonly [writeMissingRightOperandMessage<def[0]>] : def[0] extends "keyof" ? readonly [def[0], validateDefinition<def[1], $, args>] : def[0] extends "===" ? readonly [def[0], ...unknown[]] : def[0] extends "instanceof" ? readonly [def[0], ...Constructor[]] : never;\ntype validateIndexOneExpression<def extends IndexOneExpression, $, args> = def[1] extends TuplePostfixOperator ? readonly [validateDefinition<def[0], $, args>, def[1]] : readonly [\n    validateDefinition<def[0], $, args>,\n    def["length"] extends 2 ? writeMissingRightOperandMessage<def[1]> : def[1],\n    def[1] extends "|" ? validateDefinition<def[2], $, args> : def[1] extends "&" ? validateDefinition<def[2], $, args> : def[1] extends ":" ? Predicate<type.infer.Out<def[0], $, args>> : def[1] extends "=>" ? Morph<type.infer.Out<def[0], $, args>> : def[1] extends "|>" ? validateDefinition<def[2], $, args> : def[1] extends "=" ? defaultFor<type.infer.In<def[0], $, args>> : def[1] extends "@" ? TypeMeta.MappableInput : validateDefinition<def[2], $, args>\n];\ntype inferKeyOfExpression<operandDef, $, args> = show<keyof inferDefinition<operandDef, $, args>>;\ntype TupleExpression = IndexZeroExpression | IndexOneExpression;\ntype ArgTwoOperator = Exclude<IndexOneOperator, "?" | "=">;\ntype parseTo<inDef, outDef, $, args> = inferPipe<inferDefinition<inDef, $, args>, inferDefinition<outDef, $, args>>;\ntype parseMorph<inDef, morph, $, args> = morph extends Morph ? inferMorphOut<morph> extends infer out ? (In: distill.In<inferDefinition<inDef, $, args>>) => Out<out> : never : never;\ntype IndexOneExpression<token extends string = IndexOneOperator> = readonly [unknown, token, ...unknown[]];\ntype IndexOneParser<token extends string> = (def: IndexOneExpression<token>, ctx: BaseParseContext) => BaseRoot;\ndeclare const postfixParsers: {\n    "?": IndexOneParser<"?">;\n    "[]": IndexOneParser<"[]">;\n};\ntype TuplePostfixOperator = keyof typeof postfixParsers;\ndeclare const infixParsers: {\n    "|": IndexOneParser<"|">;\n    "=": IndexOneParser<"=">;\n    "|>": IndexOneParser<"|>">;\n    "&": IndexOneParser<"&">;\n    "=>": IndexOneParser<"=>">;\n    ":": IndexOneParser<":">;\n    "@": IndexOneParser<"@">;\n};\ntype TupleInfixOperator = keyof typeof infixParsers;\ndeclare const indexOneParsers: {\n    "|": IndexOneParser<"|">;\n    "=": IndexOneParser<"=">;\n    "|>": IndexOneParser<"|>">;\n    "&": IndexOneParser<"&">;\n    "=>": IndexOneParser<"=>">;\n    ":": IndexOneParser<":">;\n    "@": IndexOneParser<"@">;\n    "?": IndexOneParser<"?">;\n    "[]": IndexOneParser<"[]">;\n};\ntype IndexOneOperator = keyof typeof indexOneParsers;\ntype IndexZeroParser<token extends string> = (def: IndexZeroExpression<token>, ctx: BaseParseContext) => BaseRoot;\ntype IndexZeroExpression<token extends string = IndexZeroOperator> = readonly [\n    token,\n    ...unknown[]\n];\ndeclare const indexZeroParsers: {\n    keyof: IndexZeroParser<"keyof">;\n    instanceof: IndexZeroParser<"instanceof">;\n    "===": IndexZeroParser<"===">;\n};\ntype IndexZeroOperator = keyof typeof indexZeroParsers;\n\ntype validateTupleLiteral<def extends array, $, args> = parseSequence<def, $, args> extends infer s extends SequenceParseState ? Readonly<s["validated"]> : never;\ntype inferTupleLiteral<def extends array, $, args> = parseSequence<def, $, args> extends infer s extends SequenceParseState ? s["inferred"] : never;\ntype SequencePhase = satisfy<keyof Sequence.Inner, SequencePhase.prefix | SequencePhase.optionals | SequencePhase.defaultables | SequencePhase.postfix>;\ndeclare namespace SequencePhase {\n    type prefix = "prefix";\n    type optionals = "optionals";\n    type defaultables = "defaultables";\n    type postfix = "postfix";\n}\ntype SequenceParseState = {\n    unscanned: array;\n    inferred: array;\n    validated: array;\n    phase: SequencePhase;\n};\ntype parseSequence<def extends array, $, args> = parseNextElement<{\n    unscanned: def;\n    inferred: [];\n    validated: [];\n    phase: SequencePhase.prefix;\n}, $, args>;\ntype PreparsedElementKind = "required" | SequencePhase.optionals | SequencePhase.defaultables;\ntype PreparsedElement = {\n    head: unknown;\n    tail: array;\n    inferred: unknown;\n    validated: unknown;\n    kind: PreparsedElementKind;\n    spread: boolean;\n};\ndeclare namespace PreparsedElement {\n    type from<result extends PreparsedElement> = result;\n    type required = "required";\n    type optionals = "optionals";\n    type defaultables = "defaultables";\n}\ntype preparseNextState<s extends SequenceParseState, $, args> = s["unscanned"] extends readonly ["...", infer head, ...infer tail] ? preparseNextElement<head, tail, true, $, args> : s["unscanned"] extends readonly [infer head, ...infer tail] ? preparseNextElement<head, tail, false, $, args> : null;\ntype preparseNextElement<head, tail extends array, spread extends boolean, $, args> = PreparsedElement.from<{\n    head: head;\n    tail: tail;\n    inferred: inferDefinition<head, $, args>;\n    validated: validateInnerDefinition<head, $, args>;\n    kind: head extends OptionalPropertyDefinition ? PreparsedElement.optionals : head extends DefaultablePropertyTuple ? PreparsedElement.defaultables : isDefaultable<head, $, args> extends true ? PreparsedElement.defaultables : PreparsedElement.required;\n    spread: spread;\n}>;\ntype parseNextElement<s extends SequenceParseState, $, args> = preparseNextState<s, $, args> extends infer next extends PreparsedElement ? parseNextElement<{\n    unscanned: next["tail"];\n    inferred: nextInferred<s, next>;\n    validated: nextValidated<s, next>;\n    phase: next["kind"] extends (SequencePhase.optionals | SequencePhase.defaultables) ? next["kind"] : number extends nextInferred<s, next>["length"] ? s["phase"] : SequencePhase.prefix;\n}, $, args> : s;\ntype nextInferred<s extends SequenceParseState, next extends PreparsedElement> = next["spread"] extends true ? [\n    ...s["inferred"],\n    ...conform<next["inferred"], array>\n] : next["kind"] extends SequencePhase.optionals ? [\n    ...s["inferred"],\n    next["inferred"]?\n] : [...s["inferred"], next["inferred"]];\ntype nextValidated<s extends SequenceParseState, next extends PreparsedElement> = [\n    ...s["validated"],\n    ...nextValidatedSpreadOperatorIfPresent<s, next>,\n    nextValidatedElement<s, next>\n];\ntype nextValidatedSpreadOperatorIfPresent<s extends SequenceParseState, next extends PreparsedElement> = next["spread"] extends true ? [\n    next["inferred"] extends infer spreadOperand extends array ? [\n        number,\n        number\n    ] extends ([\n        s["inferred"]["length"],\n        spreadOperand["length"]\n    ]) ? ErrorMessage<multipleVariadicMessage> : "..." : ErrorMessage<writeNonArraySpreadMessage<next["head"]>>\n] : [];\ntype nextValidatedElement<s extends SequenceParseState, next extends PreparsedElement> = next["kind"] extends SequencePhase.optionals ? next["spread"] extends true ? ErrorMessage<spreadOptionalMessage> : s["phase"] extends SequencePhase.postfix ? ErrorMessage<optionalOrDefaultableAfterVariadicMessage> : next["validated"] : next["kind"] extends SequencePhase.defaultables ? next["spread"] extends true ? ErrorMessage<spreadDefaultableMessage> : s["phase"] extends SequencePhase.optionals ? ErrorMessage<defaultablePostOptionalMessage> : s["phase"] extends SequencePhase.postfix ? ErrorMessage<optionalOrDefaultableAfterVariadicMessage> : next["validated"] : [s["phase"], next["spread"]] extends ([\n    SequencePhase.optionals | SequencePhase.defaultables,\n    false\n]) ? ErrorMessage<postfixAfterOptionalOrDefaultableMessage> : next["validated"];\ndeclare const writeNonArraySpreadMessage: <operand extends string>(operand: operand) => writeNonArraySpreadMessage<operand>;\ntype writeNonArraySpreadMessage<operand> = `Spread element must be an array${operand extends string ? ` (was ${operand})` : ""}`;\ndeclare const multipleVariadicMesage = "A tuple may have at most one variadic element";\ntype multipleVariadicMessage = typeof multipleVariadicMesage;\ndeclare const optionalOrDefaultableAfterVariadicMessage = "An optional element may not follow a variadic element";\ntype optionalOrDefaultableAfterVariadicMessage = typeof optionalOrDefaultableAfterVariadicMessage;\ndeclare const spreadOptionalMessage = "A spread element cannot be optional";\ntype spreadOptionalMessage = typeof spreadOptionalMessage;\ndeclare const spreadDefaultableMessage = "A spread element cannot have a default";\ntype spreadDefaultableMessage = typeof spreadDefaultableMessage;\ndeclare const defaultablePostOptionalMessage = "A defaultable element may not follow an optional element without a default";\ntype defaultablePostOptionalMessage = typeof defaultablePostOptionalMessage;\n\ntype inferDefinition<def, $, args> = [\n    def\n] extends [anyOrNever] ? def : def extends type.cast<infer t> ? ifEmptyObjectLiteral<def, object, t> : def extends ThunkCast<infer t> ? t : def extends string ? inferString<def, $, args> : def extends array ? inferTuple<def, $, args> : def extends RegExp ? string : def extends object ? inferObjectLiteral<def, $, args> : never;\ntype validateDefinition<def, $, args> = null extends undefined ? ErrorMessage<`\'strict\' or \'strictNullChecks\' must be set to true in your tsconfig\'s \'compilerOptions\'`> : [def] extends [anyOrNever] ? def : def extends OptionalPropertyDefinition ? ErrorMessage<shallowOptionalMessage> : isDefaultable<def, $, args> extends true ? ErrorMessage<shallowDefaultableMessage> : validateInnerDefinition<def, $, args>;\ntype validateInnerDefinition<def, $, args> = [\n    def\n] extends [Terminal] ? def : def extends string ? validateString<def, $, args> : def extends array ? validateTuple<def, $, args> : def extends BadDefinitionType ? ErrorMessage<writeBadDefinitionTypeMessage<objectKindOrDomainOf<def>>> : unknown extends def ? BaseCompletions<$, args> | {} : RegExp extends def ? def : validateObjectLiteral<def, $, args>;\ntype validateTuple<def extends array, $, args> = maybeValidateTupleExpression<def, $, args> extends infer result ? result extends null ? validateTupleLiteral<def, $, args> : result : never;\ntype inferTuple<def extends array, $, args> = def extends TupleExpression ? inferTupleExpression<def, $, args> : inferTupleLiteral<def, $, args>;\ntype validateDeclared<declared, def, $, args> = def extends type.validate<def, $, args> ? validateInference<def, declared, $, args> : type.validate<def, $, args>;\ntype validateInference<def, declared, $, args> = def extends RegExp | type.cast<unknown> | ThunkCast | TupleExpression ? validateShallowInference<def, declared, $, args> : def extends array ? declared extends array ? {\n    [i in keyof declared]: i extends keyof def ? validateInference<def[i], declared[i], $, args> : declared[i];\n} : show<declarationMismatch<def, declared, $, args>> : def extends object ? show<{\n    [k in requiredKeyOf<declared>]: k extends keyof def ? validateInference<def[k], declared[k], $, args> : declared[k];\n} & {\n    [k in optionalKeyOf<declared> & string as `${k}?`]: `${k}?` extends (keyof def) ? validateInference<def[`${k}?`], defined<declared[k]>, $, args> : declared[k];\n}> : validateShallowInference<def, declared, $, args>;\ntype validateShallowInference<def, declared, $, args> = equals<inferDefinition<def, $, args>, declared> extends true ? def : show<declarationMismatch<def, declared, $, args>>;\ntype declarationMismatch<def, declared, $, args> = {\n    declared: declared;\n    inferred: inferDefinition<def, $, args>;\n};\ntype Terminal = type.cast<unknown> | Fn;\ntype ThunkCast<t = unknown> = () => type.cast<t>;\ntype BadDefinitionType = Exclude<Primitive, string>;\ndeclare const writeBadDefinitionTypeMessage: <actual extends string>(actual: actual) => writeBadDefinitionTypeMessage<actual>;\ntype writeBadDefinitionTypeMessage<actual extends string> = `Type definitions must be strings or objects (was ${actual})`;\n\n/** The convenience properties attached to `type` */\ntype TypeParserAttachments = Omit<TypeParser, never>;\ninterface TypeParser<$ = {}> extends Ark.boundTypeAttachments<$> {\n    /**\n     * Create a {@link Type} from your definition.\n     *\n     * @example const Person = type({ name: "string" })\n     */\n    <const def, r = type.instantiate<def, $>>(def: type.validate<def, $>): r extends infer _ ? _ : never;\n    /**\n     * Create a {@link Generic} from a parameter string and body definition.\n     *\n     * @param params A string like "<t, n extends number>" specifying the\n     * {@link Generic}\'s parameters and any associated constraints via `extends`.\n     *\n     * @param def The definition for the body of the {@link Generic}. Can reference the\n     * parameter names specified in the previous argument in addition to aliases\n     * from its {@link Scope}.\n     *\n     * @example const BoxOf = type("<t extends string | number>", { contents: "t" })\n     */\n    <const params extends ParameterString, const def, r = Generic<parseValidGenericParams<params, $>, def, $>>(params: validateParameterString<params, $>, def: type.validate<def, $, baseGenericConstraints<parseValidGenericParams<params, $>>>): r extends infer _ ? _ : never;\n    /**\n     * Create a {@link Type} from a [tuple expression](http://localhost:3000/docs/expressions)\n     * spread as this function\'s arguments.\n     *\n     * @example type("string", "|", { foo: "number" })\n     */\n    <const zero, const one, const rest extends array, r = type.instantiate<[zero, one, ...rest], $>>(_0: zero extends IndexZeroOperator ? zero : type.validate<zero, $>, _1: zero extends "keyof" ? type.validate<one, $> : zero extends "instanceof" ? conform<one, Constructor> : zero extends "===" ? conform<one, unknown> : conform<one, ArgTwoOperator>, ..._2: zero extends "===" ? rest : zero extends "instanceof" ? conform<rest, readonly Constructor[]> : one extends TupleInfixOperator ? one extends ":" ? [Predicate<distill.In<type.infer<zero, $>>>] : one extends "=>" ? [Morph<distill.Out<type.infer<zero, $>>, unknown>] : one extends "|>" ? [type.validate<rest[0], $>] : one extends "@" ? [TypeMeta.MappableInput] : [type.validate<rest[0], $>] : []): r extends infer _ ? _ : never;\n    /**\n     * An alias of the {@link ArkErrors} class, an instance of which is returned when a {@link Type}\n     * is invoked with invalid input.\n     *\n     * @example\n     * const out = myType(data)\n     *\n     * if(out instanceof type.errors) console.log(out.summary)\n     *\n     */\n    errors: typeof ArkErrors;\n    hkt: typeof Hkt;\n    keywords: typeof keywords;\n    /**\n     * The {@link Scope} in which definitions passed to this function will be parsed.\n     */\n    $: Scope<$>;\n    /**\n     * An alias of `type` with no type-level validation or inference.\n     *\n     * Useful when wrapping `type` or using it to parse a dynamic definition.\n     */\n    raw(def: unknown): Type<any, $>;\n    module: ModuleParser;\n    scope: ScopeParser;\n    define: DefinitionParser<$>;\n    generic: GenericParser<$>;\n    match: MatchParser<$>;\n    schema: SchemaParser<$>;\n    /**\n     * Create a {@link Type} that is satisfied only by a value strictly equal (`===`) to the argument passed to this function.\n     * @example const foo = type.unit(\'foo\') // {@link Type}<\'foo\'>\n     * @example const sym: unique symbol = Symbol(); type.unit(sym) // {@link Type}<typeof sym>\n     */\n    unit: UnitTypeParser<$>;\n    /**\n     * Create a {@link Type} that is satisfied only by a value strictly equal (`===`) to one of the arguments passed to this function.\n     * @example const enum = type.enumerated(\'foo\', \'bar\', obj) // obj is a by-reference object\n     * @example const TupleForm = type([\'===\', \'foo\', \'bar\', obj])\n     * @example const ArgsForm = type(\'===\', \'foo\', \'bar\', obj)\n     */\n    enumerated: EnumeratedTypeParser<$>;\n    /**\n     * Create a {@link Type} that is satisfied only by one of the Object.values() of the argument passed to this function.\n     *\n     * ⚠️ For TypeScript enum compatibility, values at numeric keys with corresponding numeric values will not be included.\n     * @example const myEnum = type.valueOf(myTsEnum)\n     */\n    valueOf: ValueOfTypeParser<$>;\n    /**\n     * Create a {@link Type} that is satisfied only by a value of a specific class.\n     * @example const array = type.instanceOf(Array)\n     */\n    instanceOf: InstanceOfTypeParser<$>;\n    /**\n     * Create a {@link Type} from a union of definitions\n     * @example const T = type.or("string", "number")\n     */\n    or: NaryUnionParser<$>;\n    /**\n     * Create a {@link Type} from an intersection of definitions\n     * @example const T = type.and({ a: "1" }, { b: "2" })\n     */\n    and: NaryIntersectionParser<$>;\n    /**\n     * Create a {@link Type} by merging object definitions, with later\n     * definitions having precedence for overlapping keys\n     * @example\n     * // Type<{ a: "3", b: "2", c: "4" }>\n     * const T = type.merge({ a: "1", b: "2" }, { a: "3", c: "4" })\n     */\n    merge: NaryMergeParser<$>;\n    /**\n     * Create a {@link Type} from a set of morphs (including Types)\n     * @example\n     * // Type<(In: string) => To<object>>\n     * const T = type.pipe(type.string, s => JSON.parse(s), type.object)\n     */\n    pipe: NaryPipeParser<$>;\n}\ndeclare class InternalTypeParser extends Callable<(...args: unknown[]) => BaseRoot | Generic, TypeParserAttachments> {\n    constructor($: InternalScope);\n}\ntype DeclarationParser<$> = <preinferred>() => {\n    type: <const def>(def: validateDeclared<preinferred, def, $, bindThis<def>>) => Type$1<preinferred, $>;\n};\ntype UnitTypeParser<$> = <const t>(value: t) => Type$1<t, $>;\ntype InstanceOfTypeParser<$> = <const t extends object>(ctor: Constructor<t>) => Type$1<t, $>;\ntype EnumeratedTypeParser<$> = <const values extends readonly unknown[]>(...values: values) => Type$1<values[number], $>;\ntype ValueOfTypeParser<$> = <const o extends object>(o: o) => Type$1<o[keyof o], $>;\ntype DefinitionParser<$> = <const def>(def: type.validate<def, $>) => def;\ntype SchemaParser<$> = (schema: RootSchema, opts?: BaseParseOptions) => Type$1<unknown, $>;\ntype TypeConstructor<t = unknown, $ = {}> = new (def: unknown, $: Scope<$>) => Type$1<t, $>;\ntype Type$1<t = unknown, $ = {}> = instantiateType<t, $>;\ndeclare const Type$1: TypeConstructor;\n\ntype NaryUnionParser<$> = {\n    (): Type$1<never, $>;\n    <const a, r = Type$1<type.infer<a>, $>>(a: type.validate<a, $>): r extends infer _ ? _ : never;\n    <const a, const b, r = Type$1<type.infer<a> | type.infer<b>, $>>(a: type.validate<a, $>, b: type.validate<b, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, r = Type$1<type.infer<a> | type.infer<b> | type.infer<c>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, r = Type$1<type.infer<a> | type.infer<b> | type.infer<c> | type.infer<d>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, r = Type$1<type.infer<a> | type.infer<b> | type.infer<c> | type.infer<d> | type.infer<e>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, r = Type$1<type.infer<a> | type.infer<b> | type.infer<c> | type.infer<d> | type.infer<e> | type.infer<f>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, r = Type$1<type.infer<a> | type.infer<b> | type.infer<c> | type.infer<d> | type.infer<e> | type.infer<f> | type.infer<g>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, r = Type$1<type.infer<a> | type.infer<b> | type.infer<c> | type.infer<d> | type.infer<e> | type.infer<f> | type.infer<g> | type.infer<h>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>, h: type.validate<h, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, r = Type$1<type.infer<a> | type.infer<b> | type.infer<c> | type.infer<d> | type.infer<e> | type.infer<f> | type.infer<g> | type.infer<h> | type.infer<i>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>, h: type.validate<h, $>, i: type.validate<i, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, r = Type$1<type.infer<a> | type.infer<b> | type.infer<c> | type.infer<d> | type.infer<e> | type.infer<f> | type.infer<g> | type.infer<h> | type.infer<i> | type.infer<j>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>, h: type.validate<h, $>, i: type.validate<i, $>, j: type.validate<j, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, r = Type$1<type.infer<a> | type.infer<b> | type.infer<c> | type.infer<d> | type.infer<e> | type.infer<f> | type.infer<g> | type.infer<h> | type.infer<i> | type.infer<j> | type.infer<k>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>, h: type.validate<h, $>, i: type.validate<i, $>, j: type.validate<j, $>, k: type.validate<k, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, const l, r = Type$1<type.infer<a> | type.infer<b> | type.infer<c> | type.infer<d> | type.infer<e> | type.infer<f> | type.infer<g> | type.infer<h> | type.infer<i> | type.infer<j> | type.infer<k> | type.infer<l>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>, h: type.validate<h, $>, i: type.validate<i, $>, j: type.validate<j, $>, k: type.validate<k, $>, l: type.validate<l, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, const l, const m, r = Type$1<type.infer<a> | type.infer<b> | type.infer<c> | type.infer<d> | type.infer<e> | type.infer<f> | type.infer<g> | type.infer<h> | type.infer<i> | type.infer<j> | type.infer<k> | type.infer<l> | type.infer<m>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>, h: type.validate<h, $>, i: type.validate<i, $>, j: type.validate<j, $>, k: type.validate<k, $>, l: type.validate<l, $>, m: type.validate<m, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, const l, const m, const n, r = Type$1<type.infer<a> | type.infer<b> | type.infer<c> | type.infer<d> | type.infer<e> | type.infer<f> | type.infer<g> | type.infer<h> | type.infer<i> | type.infer<j> | type.infer<k> | type.infer<l> | type.infer<m> | type.infer<n>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>, h: type.validate<h, $>, i: type.validate<i, $>, j: type.validate<j, $>, k: type.validate<k, $>, l: type.validate<l, $>, m: type.validate<m, $>, n: type.validate<n, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, const l, const m, const n, const o, r = Type$1<type.infer<a> | type.infer<b> | type.infer<c> | type.infer<d> | type.infer<e> | type.infer<f> | type.infer<g> | type.infer<h> | type.infer<i> | type.infer<j> | type.infer<k> | type.infer<l> | type.infer<m> | type.infer<n> | type.infer<o>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>, h: type.validate<h, $>, i: type.validate<i, $>, j: type.validate<j, $>, k: type.validate<k, $>, l: type.validate<l, $>, m: type.validate<m, $>, n: type.validate<n, $>, o: type.validate<o, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, const l, const m, const n, const o, const p, r = Type$1<type.infer<a> | type.infer<b> | type.infer<c> | type.infer<d> | type.infer<e> | type.infer<f> | type.infer<g> | type.infer<h> | type.infer<i> | type.infer<j> | type.infer<k> | type.infer<l> | type.infer<m> | type.infer<n> | type.infer<o> | type.infer<p>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>, h: type.validate<h, $>, i: type.validate<i, $>, j: type.validate<j, $>, k: type.validate<k, $>, l: type.validate<l, $>, m: type.validate<m, $>, n: type.validate<n, $>, o: type.validate<o, $>, p: type.validate<p, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, const l, const m, const n, const o, const p, const q, r = Type$1<type.infer<a> | type.infer<b> | type.infer<c> | type.infer<d> | type.infer<e> | type.infer<f> | type.infer<g> | type.infer<h> | type.infer<i> | type.infer<j> | type.infer<k> | type.infer<l> | type.infer<m> | type.infer<n> | type.infer<o> | type.infer<p> | type.infer<q>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>, h: type.validate<h, $>, i: type.validate<i, $>, j: type.validate<j, $>, k: type.validate<k, $>, l: type.validate<l, $>, m: type.validate<m, $>, n: type.validate<n, $>, o: type.validate<o, $>, p: type.validate<p, $>, q: type.validate<q, $>): r extends infer _ ? _ : never;\n    <const defs extends readonly unknown[], r = Type$1<type.infer<defs[number]>, $>>(...defs: {\n        [i in keyof defs]: type.validate<defs[i]>;\n    }): r extends infer _ ? _ : never;\n};\ntype NaryIntersectionParser<$> = {\n    (): Type$1<unknown, $>;\n    <const a, r = Type$1<type.infer<a>, $>>(a: type.validate<a, $>): r extends infer _ ? _ : never;\n    <const a, const b, r = Type$1<inferIntersection<type.infer<a>, type.infer<b>>, $>>(a: type.validate<a, $>, b: type.validate<b, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, r = Type$1<inferNaryIntersection<[type.infer<a>, type.infer<b>, type.infer<c>]>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, r = Type$1<inferNaryIntersection<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>\n    ]>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, r = Type$1<inferNaryIntersection<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>\n    ]>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, r = Type$1<inferNaryIntersection<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>\n    ]>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, r = Type$1<inferNaryIntersection<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>\n    ]>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, r = Type$1<inferNaryIntersection<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>,\n        type.infer<h>\n    ]>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>, h: type.validate<h, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, r = Type$1<inferNaryIntersection<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>,\n        type.infer<h>,\n        type.infer<i>\n    ]>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>, h: type.validate<h, $>, i: type.validate<i, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, r = Type$1<inferNaryIntersection<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>,\n        type.infer<h>,\n        type.infer<i>,\n        type.infer<j>\n    ]>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>, h: type.validate<h, $>, i: type.validate<i, $>, j: type.validate<j, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, r = Type$1<inferNaryIntersection<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>,\n        type.infer<h>,\n        type.infer<i>,\n        type.infer<j>,\n        type.infer<k>\n    ]>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>, h: type.validate<h, $>, i: type.validate<i, $>, j: type.validate<j, $>, k: type.validate<k, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, const l, r = Type$1<inferNaryIntersection<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>,\n        type.infer<h>,\n        type.infer<i>,\n        type.infer<j>,\n        type.infer<k>,\n        type.infer<l>\n    ]>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>, h: type.validate<h, $>, i: type.validate<i, $>, j: type.validate<j, $>, k: type.validate<k, $>, l: type.validate<l, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, const l, const m, r = Type$1<inferNaryIntersection<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>,\n        type.infer<h>,\n        type.infer<i>,\n        type.infer<j>,\n        type.infer<k>,\n        type.infer<l>,\n        type.infer<m>\n    ]>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>, h: type.validate<h, $>, i: type.validate<i, $>, j: type.validate<j, $>, k: type.validate<k, $>, l: type.validate<l, $>, m: type.validate<m, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, const l, const m, const n, r = Type$1<inferNaryIntersection<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>,\n        type.infer<h>,\n        type.infer<i>,\n        type.infer<j>,\n        type.infer<k>,\n        type.infer<l>,\n        type.infer<m>,\n        type.infer<n>\n    ]>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>, h: type.validate<h, $>, i: type.validate<i, $>, j: type.validate<j, $>, k: type.validate<k, $>, l: type.validate<l, $>, m: type.validate<m, $>, n: type.validate<n, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, const l, const m, const n, const o, r = Type$1<inferNaryIntersection<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>,\n        type.infer<h>,\n        type.infer<i>,\n        type.infer<j>,\n        type.infer<k>,\n        type.infer<l>,\n        type.infer<m>,\n        type.infer<n>,\n        type.infer<o>\n    ]>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>, h: type.validate<h, $>, i: type.validate<i, $>, j: type.validate<j, $>, k: type.validate<k, $>, l: type.validate<l, $>, m: type.validate<m, $>, n: type.validate<n, $>, o: type.validate<o, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, const l, const m, const n, const o, const p, r = Type$1<inferNaryIntersection<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>,\n        type.infer<h>,\n        type.infer<i>,\n        type.infer<j>,\n        type.infer<k>,\n        type.infer<l>,\n        type.infer<m>,\n        type.infer<n>,\n        type.infer<o>,\n        type.infer<p>\n    ]>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>, h: type.validate<h, $>, i: type.validate<i, $>, j: type.validate<j, $>, k: type.validate<k, $>, l: type.validate<l, $>, m: type.validate<m, $>, n: type.validate<n, $>, o: type.validate<o, $>, p: type.validate<p, $>): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, const l, const m, const n, const o, const p, const q, r = Type$1<inferNaryIntersection<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>,\n        type.infer<h>,\n        type.infer<i>,\n        type.infer<j>,\n        type.infer<k>,\n        type.infer<l>,\n        type.infer<m>,\n        type.infer<n>,\n        type.infer<o>,\n        type.infer<p>,\n        type.infer<q>\n    ]>, $>>(a: type.validate<a, $>, b: type.validate<b, $>, c: type.validate<c, $>, d: type.validate<d, $>, e: type.validate<e, $>, f: type.validate<f, $>, g: type.validate<g, $>, h: type.validate<h, $>, i: type.validate<i, $>, j: type.validate<j, $>, k: type.validate<k, $>, l: type.validate<l, $>, m: type.validate<m, $>, n: type.validate<n, $>, o: type.validate<o, $>, p: type.validate<p, $>, q: type.validate<q, $>): r extends infer _ ? _ : never;\n    <const defs extends readonly unknown[], r = Type$1<inferNaryIntersection<{\n        [i in keyof defs]: type.infer<defs[i]>;\n    }>, $>>(...defs: {\n        [i in keyof defs]: type.validate<defs[i]>;\n    }): r extends infer _ ? _ : never;\n};\ntype NaryMergeParser<$> = {\n    (): Type$1<object, $>;\n    <const a, inferredA = type.infer<a, $>, r = Type$1<inferredA, $>>(a: type.validate<a, $> & (inferredA extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredA]>)): r extends infer _ ? _ : never;\n    <const a, const b, inferredA = type.infer<a, $>, inferredB = type.infer<b, $>, r = Type$1<merge<inferredA, inferredB>, $>>(a: type.validate<a, $> & (inferredA extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredA]>), b: type.validate<b, $> & (inferredB extends object ? unknown : ErrorType<"Merged type must be an object", [actual: inferredB]>)): r extends infer _ ? _ : never;\n    <const a, const b, const c, inferredA = type.infer<a, $>, inferredB = type.infer<b, $>, inferredC = type.infer<c, $>, r = Type$1<inferNaryMerge<[type.infer<a>, type.infer<b>, type.infer<c>]>, $>>(a: type.validate<a, $> & (inferredA extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredA]>), b: type.validate<b, $> & (inferredB extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredB]>), c: type.validate<c, $> & (inferredC extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredC]>)): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, inferredA = type.infer<a, $>, inferredB = type.infer<b, $>, inferredC = type.infer<c, $>, inferredD = type.infer<d, $>, r = Type$1<inferNaryMerge<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>\n    ]>, $>>(a: type.validate<a, $> & (inferredA extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredA]>), b: type.validate<b, $> & (inferredB extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredB]>), c: type.validate<c, $> & (inferredC extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredC]>), d: type.validate<d, $> & (inferredD extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredD]>)): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, inferredA = type.infer<a, $>, inferredB = type.infer<b, $>, inferredC = type.infer<c, $>, inferredD = type.infer<d, $>, inferredE = type.infer<e, $>, r = Type$1<inferNaryMerge<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>\n    ]>, $>>(a: type.validate<a, $> & (inferredA extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredA]>), b: type.validate<b, $> & (inferredB extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredB]>), c: type.validate<c, $> & (inferredC extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredC]>), d: type.validate<d, $> & (inferredD extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredD]>), e: type.validate<e, $> & (inferredE extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredE]>)): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, inferredA = type.infer<a, $>, inferredB = type.infer<b, $>, inferredC = type.infer<c, $>, inferredD = type.infer<d, $>, inferredE = type.infer<e, $>, inferredF = type.infer<f, $>, r = Type$1<inferNaryMerge<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>\n    ]>, $>>(a: type.validate<a, $> & (inferredA extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredA]>), b: type.validate<b, $> & (inferredB extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredB]>), c: type.validate<c, $> & (inferredC extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredC]>), d: type.validate<d, $> & (inferredD extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredD]>), e: type.validate<e, $> & (inferredE extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredE]>), f: type.validate<f, $> & (inferredF extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredF]>)): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, inferredA = type.infer<a, $>, inferredB = type.infer<b, $>, inferredC = type.infer<c, $>, inferredD = type.infer<d, $>, inferredE = type.infer<e, $>, inferredF = type.infer<f, $>, inferredG = type.infer<g, $>, r = Type$1<inferNaryMerge<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>\n    ]>, $>>(a: type.validate<a, $> & (inferredA extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredA]>), b: type.validate<b, $> & (inferredB extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredB]>), c: type.validate<c, $> & (inferredC extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredC]>), d: type.validate<d, $> & (inferredD extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredD]>), e: type.validate<e, $> & (inferredE extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredE]>), f: type.validate<f, $> & (inferredF extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredF]>), g: type.validate<g, $> & (inferredG extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredG]>)): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, inferredA = type.infer<a, $>, inferredB = type.infer<b, $>, inferredC = type.infer<c, $>, inferredD = type.infer<d, $>, inferredE = type.infer<e, $>, inferredF = type.infer<f, $>, inferredG = type.infer<g, $>, inferredH = type.infer<h, $>, r = Type$1<inferNaryMerge<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>,\n        type.infer<h>\n    ]>, $>>(a: type.validate<a, $> & (inferredA extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredA]>), b: type.validate<b, $> & (inferredB extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredB]>), c: type.validate<c, $> & (inferredC extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredC]>), d: type.validate<d, $> & (inferredD extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredD]>), e: type.validate<e, $> & (inferredE extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredE]>), f: type.validate<f, $> & (inferredF extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredF]>), g: type.validate<g, $> & (inferredG extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredG]>), h: type.validate<h, $> & (inferredH extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredH]>)): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, inferredA = type.infer<a, $>, inferredB = type.infer<b, $>, inferredC = type.infer<c, $>, inferredD = type.infer<d, $>, inferredE = type.infer<e, $>, inferredF = type.infer<f, $>, inferredG = type.infer<g, $>, inferredH = type.infer<h, $>, inferredI = type.infer<i, $>, r = Type$1<inferNaryMerge<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>,\n        type.infer<h>,\n        type.infer<i>\n    ]>, $>>(a: type.validate<a, $> & (inferredA extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredA]>), b: type.validate<b, $> & (inferredB extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredB]>), c: type.validate<c, $> & (inferredC extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredC]>), d: type.validate<d, $> & (inferredD extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredD]>), e: type.validate<e, $> & (inferredE extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredE]>), f: type.validate<f, $> & (inferredF extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredF]>), g: type.validate<g, $> & (inferredG extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredG]>), h: type.validate<h, $> & (inferredH extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredH]>), i: type.validate<i, $> & (inferredI extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredI]>)): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, inferredA = type.infer<a, $>, inferredB = type.infer<b, $>, inferredC = type.infer<c, $>, inferredD = type.infer<d, $>, inferredE = type.infer<e, $>, inferredF = type.infer<f, $>, inferredG = type.infer<g, $>, inferredH = type.infer<h, $>, inferredI = type.infer<i, $>, inferredJ = type.infer<j, $>, r = Type$1<inferNaryMerge<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>,\n        type.infer<h>,\n        type.infer<i>,\n        type.infer<j>\n    ]>, $>>(a: type.validate<a, $> & (inferredA extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredA]>), b: type.validate<b, $> & (inferredB extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredB]>), c: type.validate<c, $> & (inferredC extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredC]>), d: type.validate<d, $> & (inferredD extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredD]>), e: type.validate<e, $> & (inferredE extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredE]>), f: type.validate<f, $> & (inferredF extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredF]>), g: type.validate<g, $> & (inferredG extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredG]>), h: type.validate<h, $> & (inferredH extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredH]>), i: type.validate<i, $> & (inferredI extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredI]>), j: type.validate<j, $> & (inferredJ extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredJ]>)): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, inferredA = type.infer<a, $>, inferredB = type.infer<b, $>, inferredC = type.infer<c, $>, inferredD = type.infer<d, $>, inferredE = type.infer<e, $>, inferredF = type.infer<f, $>, inferredG = type.infer<g, $>, inferredH = type.infer<h, $>, inferredI = type.infer<i, $>, inferredJ = type.infer<j, $>, inferredK = type.infer<k, $>, r = Type$1<inferNaryMerge<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>,\n        type.infer<h>,\n        type.infer<i>,\n        type.infer<j>,\n        type.infer<k>\n    ]>, $>>(a: type.validate<a, $> & (inferredA extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredA]>), b: type.validate<b, $> & (inferredB extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredB]>), c: type.validate<c, $> & (inferredC extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredC]>), d: type.validate<d, $> & (inferredD extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredD]>), e: type.validate<e, $> & (inferredE extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredE]>), f: type.validate<f, $> & (inferredF extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredF]>), g: type.validate<g, $> & (inferredG extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredG]>), h: type.validate<h, $> & (inferredH extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredH]>), i: type.validate<i, $> & (inferredI extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredI]>), j: type.validate<j, $> & (inferredJ extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredJ]>), k: type.validate<k, $> & (inferredK extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredK]>)): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, const l, inferredA = type.infer<a, $>, inferredB = type.infer<b, $>, inferredC = type.infer<c, $>, inferredD = type.infer<d, $>, inferredE = type.infer<e, $>, inferredF = type.infer<f, $>, inferredG = type.infer<g, $>, inferredH = type.infer<h, $>, inferredI = type.infer<i, $>, inferredJ = type.infer<j, $>, inferredK = type.infer<k, $>, inferredL = type.infer<l, $>, r = Type$1<inferNaryMerge<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>,\n        type.infer<h>,\n        type.infer<i>,\n        type.infer<j>,\n        type.infer<k>,\n        type.infer<l>\n    ]>, $>>(a: type.validate<a, $> & (inferredA extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredA]>), b: type.validate<b, $> & (inferredB extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredB]>), c: type.validate<c, $> & (inferredC extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredC]>), d: type.validate<d, $> & (inferredD extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredD]>), e: type.validate<e, $> & (inferredE extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredE]>), f: type.validate<f, $> & (inferredF extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredF]>), g: type.validate<g, $> & (inferredG extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredG]>), h: type.validate<h, $> & (inferredH extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredH]>), i: type.validate<i, $> & (inferredI extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredI]>), j: type.validate<j, $> & (inferredJ extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredJ]>), k: type.validate<k, $> & (inferredK extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredK]>), l: type.validate<l, $> & (inferredL extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredL]>)): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, const l, const m, inferredA = type.infer<a, $>, inferredB = type.infer<b, $>, inferredC = type.infer<c, $>, inferredD = type.infer<d, $>, inferredE = type.infer<e, $>, inferredF = type.infer<f, $>, inferredG = type.infer<g, $>, inferredH = type.infer<h, $>, inferredI = type.infer<i, $>, inferredJ = type.infer<j, $>, inferredK = type.infer<k, $>, inferredL = type.infer<l, $>, inferredM = type.infer<m, $>, r = Type$1<inferNaryMerge<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>,\n        type.infer<h>,\n        type.infer<i>,\n        type.infer<j>,\n        type.infer<k>,\n        type.infer<l>,\n        type.infer<m>\n    ]>, $>>(a: type.validate<a, $> & (inferredA extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredA]>), b: type.validate<b, $> & (inferredB extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredB]>), c: type.validate<c, $> & (inferredC extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredC]>), d: type.validate<d, $> & (inferredD extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredD]>), e: type.validate<e, $> & (inferredE extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredE]>), f: type.validate<f, $> & (inferredF extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredF]>), g: type.validate<g, $> & (inferredG extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredG]>), h: type.validate<h, $> & (inferredH extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredH]>), i: type.validate<i, $> & (inferredI extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredI]>), j: type.validate<j, $> & (inferredJ extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredJ]>), k: type.validate<k, $> & (inferredK extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredK]>), l: type.validate<l, $> & (inferredL extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredL]>), m: type.validate<m, $> & (inferredM extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredM]>)): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, const l, const m, const n, inferredA = type.infer<a, $>, inferredB = type.infer<b, $>, inferredC = type.infer<c, $>, inferredD = type.infer<d, $>, inferredE = type.infer<e, $>, inferredF = type.infer<f, $>, inferredG = type.infer<g, $>, inferredH = type.infer<h, $>, inferredI = type.infer<i, $>, inferredJ = type.infer<j, $>, inferredK = type.infer<k, $>, inferredL = type.infer<l, $>, inferredM = type.infer<m, $>, inferredN = type.infer<n, $>, r = Type$1<inferNaryMerge<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>,\n        type.infer<h>,\n        type.infer<i>,\n        type.infer<j>,\n        type.infer<k>,\n        type.infer<l>,\n        type.infer<m>,\n        type.infer<n>\n    ]>, $>>(a: type.validate<a, $> & (inferredA extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredA]>), b: type.validate<b, $> & (inferredB extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredB]>), c: type.validate<c, $> & (inferredC extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredC]>), d: type.validate<d, $> & (inferredD extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredD]>), e: type.validate<e, $> & (inferredE extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredE]>), f: type.validate<f, $> & (inferredF extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredF]>), g: type.validate<g, $> & (inferredG extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredG]>), h: type.validate<h, $> & (inferredH extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredH]>), i: type.validate<i, $> & (inferredI extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredI]>), j: type.validate<j, $> & (inferredJ extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredJ]>), k: type.validate<k, $> & (inferredK extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredK]>), l: type.validate<l, $> & (inferredL extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredL]>), m: type.validate<m, $> & (inferredM extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredM]>), n: type.validate<n, $> & (inferredN extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredN]>)): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, const l, const m, const n, const o, inferredA = type.infer<a, $>, inferredB = type.infer<b, $>, inferredC = type.infer<c, $>, inferredD = type.infer<d, $>, inferredE = type.infer<e, $>, inferredF = type.infer<f, $>, inferredG = type.infer<g, $>, inferredH = type.infer<h, $>, inferredI = type.infer<i, $>, inferredJ = type.infer<j, $>, inferredK = type.infer<k, $>, inferredL = type.infer<l, $>, inferredM = type.infer<m, $>, inferredN = type.infer<n, $>, inferredO = type.infer<o, $>, r = Type$1<inferNaryMerge<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>,\n        type.infer<h>,\n        type.infer<i>,\n        type.infer<j>,\n        type.infer<k>,\n        type.infer<l>,\n        type.infer<m>,\n        type.infer<n>,\n        type.infer<o>\n    ]>, $>>(a: type.validate<a, $> & (inferredA extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredA]>), b: type.validate<b, $> & (inferredB extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredB]>), c: type.validate<c, $> & (inferredC extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredC]>), d: type.validate<d, $> & (inferredD extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredD]>), e: type.validate<e, $> & (inferredE extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredE]>), f: type.validate<f, $> & (inferredF extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredF]>), g: type.validate<g, $> & (inferredG extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredG]>), h: type.validate<h, $> & (inferredH extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredH]>), i: type.validate<i, $> & (inferredI extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredI]>), j: type.validate<j, $> & (inferredJ extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredJ]>), k: type.validate<k, $> & (inferredK extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredK]>), l: type.validate<l, $> & (inferredL extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredL]>), m: type.validate<m, $> & (inferredM extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredM]>), n: type.validate<n, $> & (inferredN extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredN]>), o: type.validate<o, $> & (inferredO extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredO]>)): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, const l, const m, const n, const o, const p, inferredA = type.infer<a, $>, inferredB = type.infer<b, $>, inferredC = type.infer<c, $>, inferredD = type.infer<d, $>, inferredE = type.infer<e, $>, inferredF = type.infer<f, $>, inferredG = type.infer<g, $>, inferredH = type.infer<h, $>, inferredI = type.infer<i, $>, inferredJ = type.infer<j, $>, inferredK = type.infer<k, $>, inferredL = type.infer<l, $>, inferredM = type.infer<m, $>, inferredN = type.infer<n, $>, inferredO = type.infer<o, $>, inferredP = type.infer<p, $>, r = Type$1<inferNaryMerge<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>,\n        type.infer<h>,\n        type.infer<i>,\n        type.infer<j>,\n        type.infer<k>,\n        type.infer<l>,\n        type.infer<m>,\n        type.infer<n>,\n        type.infer<o>,\n        type.infer<p>\n    ]>, $>>(a: type.validate<a, $> & (inferredA extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredA]>), b: type.validate<b, $> & (inferredB extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredB]>), c: type.validate<c, $> & (inferredC extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredC]>), d: type.validate<d, $> & (inferredD extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredD]>), e: type.validate<e, $> & (inferredE extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredE]>), f: type.validate<f, $> & (inferredF extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredF]>), g: type.validate<g, $> & (inferredG extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredG]>), h: type.validate<h, $> & (inferredH extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredH]>), i: type.validate<i, $> & (inferredI extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredI]>), j: type.validate<j, $> & (inferredJ extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredJ]>), k: type.validate<k, $> & (inferredK extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredK]>), l: type.validate<l, $> & (inferredL extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredL]>), m: type.validate<m, $> & (inferredM extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredM]>), n: type.validate<n, $> & (inferredN extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredN]>), o: type.validate<o, $> & (inferredO extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredO]>), p: type.validate<p, $> & (inferredP extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredP]>)): r extends infer _ ? _ : never;\n    <const a, const b, const c, const d, const e, const f, const g, const h, const i, const j, const k, const l, const m, const n, const o, const p, const q, inferredA = type.infer<a, $>, inferredB = type.infer<b, $>, inferredC = type.infer<c, $>, inferredD = type.infer<d, $>, inferredE = type.infer<e, $>, inferredF = type.infer<f, $>, inferredG = type.infer<g, $>, inferredH = type.infer<h, $>, inferredI = type.infer<i, $>, inferredJ = type.infer<j, $>, inferredK = type.infer<k, $>, inferredL = type.infer<l, $>, inferredM = type.infer<m, $>, inferredN = type.infer<n, $>, inferredO = type.infer<o, $>, inferredP = type.infer<p, $>, inferredQ = type.infer<q, $>, r = Type$1<inferNaryMerge<[\n        type.infer<a>,\n        type.infer<b>,\n        type.infer<c>,\n        type.infer<d>,\n        type.infer<e>,\n        type.infer<f>,\n        type.infer<g>,\n        type.infer<h>,\n        type.infer<i>,\n        type.infer<j>,\n        type.infer<k>,\n        type.infer<l>,\n        type.infer<m>,\n        type.infer<n>,\n        type.infer<o>,\n        type.infer<p>,\n        type.infer<q>\n    ]>, $>>(a: type.validate<a, $> & (inferredA extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredA]>), b: type.validate<b, $> & (inferredB extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredB]>), c: type.validate<c, $> & (inferredC extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredC]>), d: type.validate<d, $> & (inferredD extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredD]>), e: type.validate<e, $> & (inferredE extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredE]>), f: type.validate<f, $> & (inferredF extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredF]>), g: type.validate<g, $> & (inferredG extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredG]>), h: type.validate<h, $> & (inferredH extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredH]>), i: type.validate<i, $> & (inferredI extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredI]>), j: type.validate<j, $> & (inferredJ extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredJ]>), k: type.validate<k, $> & (inferredK extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredK]>), l: type.validate<l, $> & (inferredL extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredL]>), m: type.validate<m, $> & (inferredM extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredM]>), n: type.validate<n, $> & (inferredN extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredN]>), o: type.validate<o, $> & (inferredO extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredO]>), p: type.validate<p, $> & (inferredP extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredP]>), q: type.validate<q, $> & (inferredQ extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [actual: inferredQ]>)): r extends infer _ ? _ : never;\n    <const defs extends readonly unknown[], r = Type$1<inferNaryMerge<{\n        [i in keyof defs]: type.infer<defs[i]>;\n    }>, $>>(...defs: {\n        [i in keyof defs]: type.validate<defs[i]> & (type.infer<defs[i], $> extends object ? unknown : ErrorType<NonObjectMergeErrorMessage, [\n            actual: type.infer<defs[i], $>\n        ]>);\n    }): r extends infer _ ? _ : never;\n};\ntype NaryPipeParser<$, initial = unknown> = {\n    (): Type$1<initial, $>;\n    <a extends Morph<distill.Out<initial>>, r = instantiateType<inferMorph<initial, a>, $>>(a: a): r extends infer _ ? _ : never;\n    <a extends Morph<distill.Out<initial>>, b extends Morph<inferMorphOut<a>>, r = instantiateType<inferNaryPipe<[Type$1<initial>, a, b]>, $>>(a: a, b: b): r extends infer _ ? _ : never;\n    <a extends Morph<distill.Out<initial>>, b extends Morph<inferMorphOut<a>>, c extends Morph<inferMorphOut<b>>, r = instantiateType<inferNaryPipe<[Type$1<initial>, a, b, c]>, $>>(a: a, b: b, c: c): r extends infer _ ? _ : never;\n    <a extends Morph<distill.Out<initial>>, b extends Morph<inferMorphOut<a>>, c extends Morph<inferMorphOut<b>>, d extends Morph<inferMorphOut<c>>, r = instantiateType<inferNaryPipe<[Type$1<initial>, a, b, c, d]>, $>>(a: a, b: b, c: c, d: d): r extends infer _ ? _ : never;\n    <a extends Morph<distill.Out<initial>>, b extends Morph<inferMorphOut<a>>, c extends Morph<inferMorphOut<b>>, d extends Morph<inferMorphOut<c>>, e extends Morph<inferMorphOut<d>>, r = instantiateType<inferNaryPipe<[Type$1<initial>, a, b, c, d, e]>, $>>(a: a, b: b, c: c, d: d, e: e): r extends infer _ ? _ : never;\n    <a extends Morph<distill.Out<initial>>, b extends Morph<inferMorphOut<a>>, c extends Morph<inferMorphOut<b>>, d extends Morph<inferMorphOut<c>>, e extends Morph<inferMorphOut<d>>, f extends Morph<inferMorphOut<e>>, r = instantiateType<inferNaryPipe<[Type$1<initial>, a, b, c, d, e, f]>, $>>(a: a, b: b, c: c, d: d, e: e, f: f): r extends infer _ ? _ : never;\n    <a extends Morph<distill.Out<initial>>, b extends Morph<inferMorphOut<a>>, c extends Morph<inferMorphOut<b>>, d extends Morph<inferMorphOut<c>>, e extends Morph<inferMorphOut<d>>, f extends Morph<inferMorphOut<e>>, g extends Morph<inferMorphOut<f>>, r = instantiateType<inferNaryPipe<[Type$1<initial>, a, b, c, d, e, f, g]>, $>>(a: a, b: b, c: c, d: d, e: e, f: f, g: g): r extends infer _ ? _ : never;\n    <a extends Morph<distill.Out<initial>>, b extends Morph<inferMorphOut<a>>, c extends Morph<inferMorphOut<b>>, d extends Morph<inferMorphOut<c>>, e extends Morph<inferMorphOut<d>>, f extends Morph<inferMorphOut<e>>, g extends Morph<inferMorphOut<f>>, h extends Morph<inferMorphOut<g>>, r = instantiateType<inferNaryPipe<[Type$1<initial>, a, b, c, d, e, f, g, h]>, $>>(a: a, b: b, c: c, d: d, e: e, f: f, g: g, h: h): r extends infer _ ? _ : never;\n    <a extends Morph<distill.Out<initial>>, b extends Morph<inferMorphOut<a>>, c extends Morph<inferMorphOut<b>>, d extends Morph<inferMorphOut<c>>, e extends Morph<inferMorphOut<d>>, f extends Morph<inferMorphOut<e>>, g extends Morph<inferMorphOut<f>>, h extends Morph<inferMorphOut<g>>, i extends Morph<inferMorphOut<h>>, r = instantiateType<inferNaryPipe<[Type$1<initial>, a, b, c, d, e, f, g, h, i]>, $>>(a: a, b: b, c: c, d: d, e: e, f: f, g: g, h: h, i: i): r extends infer _ ? _ : never;\n    <a extends Morph<distill.Out<initial>>, b extends Morph<inferMorphOut<a>>, c extends Morph<inferMorphOut<b>>, d extends Morph<inferMorphOut<c>>, e extends Morph<inferMorphOut<d>>, f extends Morph<inferMorphOut<e>>, g extends Morph<inferMorphOut<f>>, h extends Morph<inferMorphOut<g>>, i extends Morph<inferMorphOut<h>>, j extends Morph<inferMorphOut<i>>, r = instantiateType<inferNaryPipe<[Type$1<initial>, a, b, c, d, e, f, g, h, i, j]>, $>>(a: a, b: b, c: c, d: d, e: e, f: f, g: g, h: h, i: i, j: j): r extends infer _ ? _ : never;\n    <a extends Morph<distill.Out<initial>>, b extends Morph<inferMorphOut<a>>, c extends Morph<inferMorphOut<b>>, d extends Morph<inferMorphOut<c>>, e extends Morph<inferMorphOut<d>>, f extends Morph<inferMorphOut<e>>, g extends Morph<inferMorphOut<f>>, h extends Morph<inferMorphOut<g>>, i extends Morph<inferMorphOut<h>>, j extends Morph<inferMorphOut<i>>, k extends Morph<inferMorphOut<j>>, r = instantiateType<inferNaryPipe<[Type$1<initial>, a, b, c, d, e, f, g, h, i, j, k]>, $>>(a: a, b: b, c: c, d: d, e: e, f: f, g: g, h: h, i: i, j: j, k: k): r extends infer _ ? _ : never;\n    <a extends Morph<distill.Out<initial>>, b extends Morph<inferMorphOut<a>>, c extends Morph<inferMorphOut<b>>, d extends Morph<inferMorphOut<c>>, e extends Morph<inferMorphOut<d>>, f extends Morph<inferMorphOut<e>>, g extends Morph<inferMorphOut<f>>, h extends Morph<inferMorphOut<g>>, i extends Morph<inferMorphOut<h>>, j extends Morph<inferMorphOut<i>>, k extends Morph<inferMorphOut<j>>, l extends Morph<inferMorphOut<k>>, r = instantiateType<inferNaryPipe<[Type$1<initial>, a, b, c, d, e, f, g, h, i, j, k, l]>, $>>(a: a, b: b, c: c, d: d, e: e, f: f, g: g, h: h, i: i, j: j, k: k, l: l): r extends infer _ ? _ : never;\n    <a extends Morph<distill.Out<initial>>, b extends Morph<inferMorphOut<a>>, c extends Morph<inferMorphOut<b>>, d extends Morph<inferMorphOut<c>>, e extends Morph<inferMorphOut<d>>, f extends Morph<inferMorphOut<e>>, g extends Morph<inferMorphOut<f>>, h extends Morph<inferMorphOut<g>>, i extends Morph<inferMorphOut<h>>, j extends Morph<inferMorphOut<i>>, k extends Morph<inferMorphOut<j>>, l extends Morph<inferMorphOut<k>>, m extends Morph<inferMorphOut<l>>, r = instantiateType<inferNaryPipe<[Type$1<initial>, a, b, c, d, e, f, g, h, i, j, k, l, m]>, $>>(a: a, b: b, c: c, d: d, e: e, f: f, g: g, h: h, i: i, j: j, k: k, l: l, m: m): r extends infer _ ? _ : never;\n    <a extends Morph<distill.Out<initial>>, b extends Morph<inferMorphOut<a>>, c extends Morph<inferMorphOut<b>>, d extends Morph<inferMorphOut<c>>, e extends Morph<inferMorphOut<d>>, f extends Morph<inferMorphOut<e>>, g extends Morph<inferMorphOut<f>>, h extends Morph<inferMorphOut<g>>, i extends Morph<inferMorphOut<h>>, j extends Morph<inferMorphOut<i>>, k extends Morph<inferMorphOut<j>>, l extends Morph<inferMorphOut<k>>, m extends Morph<inferMorphOut<l>>, n extends Morph<inferMorphOut<m>>, r = instantiateType<inferNaryPipe<[Type$1<initial>, a, b, c, d, e, f, g, h, i, j, k, l, m, n]>, $>>(a: a, b: b, c: c, d: d, e: e, f: f, g: g, h: h, i: i, j: j, k: k, l: l, m: m, n: n): r extends infer _ ? _ : never;\n    <a extends Morph<distill.Out<initial>>, b extends Morph<inferMorphOut<a>>, c extends Morph<inferMorphOut<b>>, d extends Morph<inferMorphOut<c>>, e extends Morph<inferMorphOut<d>>, f extends Morph<inferMorphOut<e>>, g extends Morph<inferMorphOut<f>>, h extends Morph<inferMorphOut<g>>, i extends Morph<inferMorphOut<h>>, j extends Morph<inferMorphOut<i>>, k extends Morph<inferMorphOut<j>>, l extends Morph<inferMorphOut<k>>, m extends Morph<inferMorphOut<l>>, n extends Morph<inferMorphOut<m>>, o extends Morph<inferMorphOut<n>>, r = instantiateType<inferNaryPipe<[\n        Type$1<initial>,\n        a,\n        b,\n        c,\n        d,\n        e,\n        f,\n        g,\n        h,\n        i,\n        j,\n        k,\n        l,\n        m,\n        n,\n        o\n    ]>, $>>(a: a, b: b, c: c, d: d, e: e, f: f, g: g, h: h, i: i, j: j, k: k, l: l, m: m, n: n, o: o): r extends infer _ ? _ : never;\n    <a extends Morph<distill.Out<initial>>, b extends Morph<inferMorphOut<a>>, c extends Morph<inferMorphOut<b>>, d extends Morph<inferMorphOut<c>>, e extends Morph<inferMorphOut<d>>, f extends Morph<inferMorphOut<e>>, g extends Morph<inferMorphOut<f>>, h extends Morph<inferMorphOut<g>>, i extends Morph<inferMorphOut<h>>, j extends Morph<inferMorphOut<i>>, k extends Morph<inferMorphOut<j>>, l extends Morph<inferMorphOut<k>>, m extends Morph<inferMorphOut<l>>, n extends Morph<inferMorphOut<m>>, o extends Morph<inferMorphOut<n>>, p extends Morph<inferMorphOut<o>>, r = instantiateType<inferNaryPipe<[\n        Type$1<initial>,\n        a,\n        b,\n        c,\n        d,\n        e,\n        f,\n        g,\n        h,\n        i,\n        j,\n        k,\n        l,\n        m,\n        n,\n        o,\n        p\n    ]>, $>>(a: a, b: b, c: c, d: d, e: e, f: f, g: g, h: h, i: i, j: j, k: k, l: l, m: m, n: n, o: o, p: p): r extends infer _ ? _ : never;\n    <a extends Morph<distill.Out<initial>>, b extends Morph<inferMorphOut<a>>, c extends Morph<inferMorphOut<b>>, d extends Morph<inferMorphOut<c>>, e extends Morph<inferMorphOut<d>>, f extends Morph<inferMorphOut<e>>, g extends Morph<inferMorphOut<f>>, h extends Morph<inferMorphOut<g>>, i extends Morph<inferMorphOut<h>>, j extends Morph<inferMorphOut<i>>, k extends Morph<inferMorphOut<j>>, l extends Morph<inferMorphOut<k>>, m extends Morph<inferMorphOut<l>>, n extends Morph<inferMorphOut<m>>, o extends Morph<inferMorphOut<n>>, p extends Morph<inferMorphOut<o>>, q extends Morph<inferMorphOut<p>>, r = instantiateType<inferNaryPipe<[\n        Type$1<initial>,\n        a,\n        b,\n        c,\n        d,\n        e,\n        f,\n        g,\n        h,\n        i,\n        j,\n        k,\n        l,\n        m,\n        n,\n        o,\n        p,\n        q\n    ]>, $>>(a: a, b: b, c: c, d: d, e: e, f: f, g: g, h: h, i: i, j: j, k: k, l: l, m: m, n: n, o: o, p: p, q: q): r extends infer _ ? _ : never;\n    <const morphs extends readonly Morph[], r = Type$1<inferNaryPipe<morphs>, $>>(...defs: morphs): r extends infer _ ? _ : never;\n};\n\n/** @ts-ignore cast variance */\ninterface Inferred<out t = unknown, $ = {}> {\n    internal: BaseRoot;\n    [inferred]: t;\n    /**\n     * precompiled JS used to optimize validation\n     *\n     * ⚠️ will be `undefined` in [jitless](https://arktype.io/docs/configuration#jitless) mode\n     */\n    precompilation: string | undefined;\n    /**\n     * generic parameter representing this Type\n     *\n     * @typeonly\n     *\n     * ⚠️ May contain types representing morphs or default values that would\n     * be inaccurate if used directly for runtime values. In those cases,\n     * you should use {@link infer} or {@link inferIn} on this object instead.\n     */\n    t: t;\n    /**\n     * #### {@link Scope} in which chained methods are parsed\n     */\n    $: Scope<$>;\n    /**\n     * #### type of output this returns\n     *\n     * @typeonly\n     *\n     * @example\n     * const parseNumber = type("string").pipe(s => Number.parseInt(s))\n     * type ParsedNumber = typeof parseNumber.infer // number\n     */\n    infer: this["inferOut"];\n    /**\n     * type of output this returns\n     *\n     * 🔗 alias of {@link infer}\n     * @typeonly\n     *\n     *\n     * @example\n     * const parseNumber = type("string").pipe(s => Number.parseInt(s))\n     * type ParsedNumber = typeof parseNumber.infer // number\n     */\n    inferOut: distill.Out<t>;\n    /**\n     * type of output that can be introspected at runtime (e.g. via {@link out})\n     *\n     * ⚠️ If your Type contains morphs, they will be inferred as `unknown` unless\n     * they are an ArkType keyword or have an explicitly defined output validator.\n     *\n     * @typeonly\n     *\n     * @example\n     * const Unmorphed = type("string")\n     * // with no morphs, we can introspect the input and output as a single Type\n     * type UnmorphedOut = typeof Unmorphed.inferIntrospectableOut // string\n     *\n     * const Morphed = type("string").pipe(s => s.length)\n     * // with a standard user-defined morph, TypeScript can infer a\n     * // return type from your function, but we have no way to\n     * // know the shape at runtime\n     * type MorphOut = typeof Morphed.inferIntrospectableOut  // unknown\n     *\n     * const Validated = type("string").pipe(s => s.length).to("number")\n     * // morphs with validated output, including all morph keywords, are introspectable\n     * type ValidatedMorphOut = typeof Validated.inferIntrospectableOut\n     */\n    inferIntrospectableOut: distill.introspectable.Out<t>;\n    /**\n     * #### type of input this allows\n     *\n     * @typeonly\n     *\n     * @example\n     * const parseNumber = type("string").pipe(s => Number.parseInt(s))\n     * type UnparsedNumber = typeof parseNumber.inferIn // string\n     */\n    inferIn: distill.In<t>;\n    /**\n     * #### internal JSON representation\n     */\n    json: JsonStructure;\n    /**\n     * alias of {@link json} for `JSON.stringify` compatibility\n     */\n    toJSON(): JsonStructure;\n    /**\n     * #### generate a JSON Schema\n     *\n     * @throws {JsonSchema.UnjsonifiableError} if this cannot be converted to JSON Schema\n     */\n    toJsonSchema(): JsonSchema;\n    /**\n     * #### metadata like custom descriptions and error messages\n     *\n     * ✅ type {@link https://arktype.io/docs/configuration#custom | can be customized} for your project\n     */\n    meta: ArkAmbient.meta;\n    /**\n     * #### human-readable English description\n     *\n     * ✅ works best for primitive values\n     *\n     * @example\n     * const N = type("0 < number <= 100")\n     * console.log(N.description) // positive and at most 100\n     */\n    description: string;\n    /**\n     * #### syntax string similar to native TypeScript\n     *\n     * ✅ works well for both primitives and structures\n     *\n     * @example\n     * const Loc = type({ coords: ["number", "number"] })\n     * console.log(Loc.expression) // { coords: [number, number] }\n     */\n    expression: string;\n    /**\n     * #### validate and return transformed data or throw\n     *\n     * ✅ sugar to avoid checking for {@link type.errors} if they are unrecoverable\n     *\n     * @example\n     * const CriticalPayload = type({\n     *     superImportantValue: "string"\n     * })\n     * // throws TraversalError: superImportantValue must be a string (was missing)\n     * const data = CriticalPayload.assert({ irrelevantValue: "whoops" })\n     * console.log(data.superImportantValue) // valid output can be accessed directly\n     *\n     * @throws {TraversalError}\n     */\n    assert(data: unknown): this["infer"];\n    /**\n     * #### check input without applying morphs\n     *\n     * ✅ good for stuff like filtering that doesn\'t benefit from detailed errors\n     *\n     * @example\n     * const Numeric = type("number | bigint")\n     * // [0, 2n]\n     * const numerics = [0, "one", 2n].filter(Numeric.allows)\n     */\n    allows(data: unknown): data is this["inferIn"];\n    /**\n     * #### add metadata to shallow references\n     *\n     * ⚠️ does not affect error messages within properties of an object\n     *\n     * @example\n     * const NotOdd = type("number % 2").configure({ description: "not odd" })\n     * // all constraints at the root are affected\n     * const odd = NotOdd(3) // must be not odd (was 3)\n     * const nonNumber = NotOdd("two") // must be not odd (was "two")\n     *\n     * const NotOddBox = type({\n     *    // we should have referenced notOdd or added meta here\n     *    notOdd: "number % 2",\n     * // but instead chained from the root object\n     * }).configure({ description: "not odd" })\n     * // error message at path notOdd is not affected\n     * const oddProp = NotOddBox({ notOdd: 3 }) // notOdd must be even (was 3)\n     * // error message at root is affected, leading to a misleading description\n     * const nonObject = NotOddBox(null) // must be not odd (was null)\n     */\n    configure: NodeSelector.SelectableFn<TypeMeta.MappableInput, this>;\n    /**\n     * #### add description to shallow references\n     *\n     * 🔗 equivalent to `.configure({ description })` (see {@link configure})\n     * ⚠️ does not affect error messages within properties of an object\n     *\n     * @example\n     * const AToZ = type(/^a.*z$/).describe("a string like \'a...z\'")\n     * const good = AToZ("alcatraz") // "alcatraz"\n     * // ArkErrors: must be a string like \'a...z\' (was "albatross")\n     * const badPattern = AToZ("albatross")\n     */\n    describe: NodeSelector.SelectableFn<string, this>;\n    /**\n     * #### apply undeclared key behavior\n     *\n     * {@inheritDoc UndeclaredKeyBehavior}\n     */\n    onUndeclaredKey(behavior: UndeclaredKeyBehavior): this;\n    /**\n     * #### deeply apply undeclared key behavior\n     *\n     * {@inheritDoc UndeclaredKeyBehavior}\n     **/\n    onDeepUndeclaredKey(behavior: UndeclaredKeyBehavior): this;\n    /**\n     * #### alias for {@link assert} with typed input\n     *\n     * @example\n     * const T = type({ foo: "string" });\n     * // TypeScript: foo must be a string (was 5)\n     * const data = T.from({ foo: 5 });\n     */\n    from(literal: this["inferIn"]): this["infer"];\n    /**\n     * #### deeply extract inputs\n     *\n     * ✅ will never include morphs\n     * ✅ good for generating JSON Schema or other non-transforming formats\n     *\n     * @example\n     * const User = type({\n     *    age: "string.numeric.parse"\n     * })\n     * // { age: 25 } (age parsed to a number)\n     * const out = User({ age: "25" })\n     * // { age: "25" } (age is still a string)\n     * const inOut = User.in({ age: "25" })\n     */\n    get in(): instantiateType<this["inferIn"], $>;\n    /**\n     * #### deeply extract outputs\n     *\n     * ✅ will never include morphs\n     * ⚠️ if your type includes morphs, their output will likely be unknown unless they\n     * were defined with an explicit output validator via `.to(outputDef)` or `.pipe(morph, outputType)`\n     *\n     * @example\n     * const join = type("string[]").pipe(a => a.join(","))\n     *\n     * const T = type({\n     *    // all keywords have introspectable output\n     *    keyword: "string.numeric.parse",\n     *    // TypeScript knows this returns a string, but we can\'t introspect that at runtime\n     *    unvalidated: join,\n     *    // if needed, it can be made introspectable with an output validator\n     *    validated: join.to("string")\n     * })\n     *\n     * // Type<{ keyword: number; unvalidated: unknown; validated: string }>\n     * const baseOut = base.out\n     */\n    get out(): instantiateType<this["inferIntrospectableOut"], $>;\n    /**\n     * #### add a compile-time brand to output\n     *\n     * @typenoop\n     *\n     * @example\n     * const Palindrome = type("string")\n     *     .narrow(s => s === [...s].reverse().join(""))\n     *     .brand("palindrome")\n     * // Brand<string, "palindrome">\n     * const out = Palindrome.assert("racecar")\n     */\n    brand<const name extends string, r = instantiateType<type.brand<t, name>, $>>(name: name): r extends infer _ ? _ : never;\n    /**\n     * #### an array of this\n     *\n     * @example\n     * // Type<{ rebmun: number }[]>\n     * const T = type({ rebmun: "number" }).array();\n     */\n    array(): Type$5<t[], $>;\n    /**\n     * #### {@link https://arktype.io/docs/objects#properties-optional | optional definition}\n     *\n     * @chainedDefinition\n     *\n     * @example\n     * const Prop = type({ foo: "number" })\n     * // Type<{ bar?: { foo: number } }>\n     * const Obj = type({ bar: Prop.optional() })\n     */\n    optional(): [this, "?"];\n    /**\n     * #### {@link https://arktype.io/docs/objects#properties-defaultable | defaultable definition}\n     *\n     * ✅ object defaults can be returned from a function\n     * ⚠️ throws if the default value is not allowed\n     * @chainedDefinition\n     *\n     * @example\n     * // Type<{ count: Default<number, 0> }>\n     * const State = type({ count: type.number.default(0) })\n     * const Prop = type({ nested: "boolean" })\n     * const ForObj = type({\n     *     key: Prop.default(() => ({ nested: false }))\n     * })\n     */\n    default<const value extends defaultFor<this["inferIn"]>>(value: value): [this, "=", value];\n    /**\n     * #### apply a predicate function to input\n     *\n     * ⚠️ the behavior of {@link narrow}, this method\'s output counterpart, is usually more desirable\n     * ✅ most useful for morphs with input types that are re-used externally\n     * @predicateCast\n     *\n     * @example\n     * const stringifyUser = type({ name: "string" }).pipe(user => JSON.stringify(user))\n     * const stringifySafe = stringifyUser.filter(user => user.name !== "Bobby Tables")\n     * // Type<(In: `${string}Z`) => To<Date>>\n     * const WithPredicate = type("string.date.parse").filter((s): s is `${string}Z` =>\n     *     s.endsWith("Z")\n     * )\n     */\n    filter<narrowed extends this["inferIn"] = never, r = instantiateType<[\n        narrowed\n    ] extends [never] ? t : t extends InferredMorph<any, infer o> ? (In: narrowed) => o : narrowed, $>>(predicate: Predicate.Castable<this["inferIn"], narrowed>): r extends infer _ ? _ : never;\n    /**\n     * #### apply a predicate function to output\n     *\n     * ✅ go-to fallback for validation not composable via builtin types and operators\n     * ✅ runs after all other validators and morphs, if present\n     * @predicateCast\n     *\n     * @example\n     * const Palindrome = type("string").narrow(s => s === [...s].reverse().join(""))\n     *\n     * const PalindromicEmail = type("string.date.parse").narrow((date, ctx) =>\n     *\t\tdate.getFullYear() === 2025 || ctx.mustBe("the current year")\n     * )\n     * // Type<`${string}.tsx`>\n     * const WithPredicate = type("string").narrow((s): s is `${string}.tsx` => /\\.tsx?$/.test(s))\n     */\n    narrow<narrowed extends this["infer"] = never, r = instantiateType<[\n        narrowed\n    ] extends [never] ? t : t extends InferredMorph<infer i, infer o> ? o extends To ? (In: i) => To<narrowed> : (In: i) => Out<narrowed> : narrowed, $>>(predicate: Predicate.Castable<this["infer"], narrowed>): r extends infer _ ? _ : never;\n    /**\n     * #### pipe output through arbitrary transformations or other Types\n     *\n     * @example\n     * const User = type({ name: "string" })\n     *\n     * // parse a string and validate that the result as a user\n     * const parseUser = type("string").pipe(s => JSON.parse(s), user)\n     */\n    pipe: ChainedPipeParser<$, t>;\n    /**\n     * #### parse a definition as an output validator\n     *\n     * 🔗 `to({ name: "string" })` is equivalent to `.pipe(type({ name: "string" }))`\n     *\n     * @example\n     * // parse a string and validate that the result as a user\n     * const parseUser = type("string").pipe(s => JSON.parse(s)).to({ name: "string" })\n     */\n    to<const def, r = instantiateType<inferPipe<t, type.infer<def, $>>, $>>(def: type.validate<def, $>): r extends infer _ ? _ : never;\n    /**\n     * #### query internal node references\n     *\n     * @experimental filters and returns the Type\'s internal representation from `@ark/schema`\n     *\n     * @example\n     * // ["blue", "red"]\n     * const values = type("\'red\' | \'blue\'").select("unit").map(u => u.unit)\n     */\n    select: BaseNode["select"];\n}\n/** @ts-ignore cast variance */\ninterface Type<out t = unknown, $ = {}> extends Callable<(data: unknown) => distill.Out<t> | ArkEnv.onFail>, Inferred<t, $> {\n    /**\n     * #### cast the way this is inferred\n     *\n     * @typenoop\n     *\n     * @example\n     * // Type<`LEEEEEEEE${string}ROY`>\n     * const Leeroy = type(/^LE{8,}ROY$/).as<`LEEEEEEEE${string}ROY`>()\n     */\n    as<castTo = unset>(...args: validateChainedAsArgs<castTo>): instantiateType<castTo, $>;\n    /**\n     * #### intersect the parsed Type, throwing if the result is unsatisfiable\n     *\n     * @example\n     * // Type<{ foo: number; bar: string }>\n     * const T = type({ foo: "number" }).and({ bar: "string" })\n     * // ParseError: Intersection at foo of number and string results in an unsatisfiable type\n     * const Bad = type({ foo: "number" }).and({ foo: "string" })\n     */\n    and<const def, r = instantiateType<inferIntersection<t, type.infer<def, $>>, $>>(def: type.validate<def, $>): r extends infer _ ? _ : never;\n    /**\n     * #### union with the parsed Type\n     *\n     * ⚠️ a union that could apply different morphs to the same data is a ParseError ({@link https://arktype.io/docs/expressions#union-morphs | docs})\n     *\n     * @example\n     * // Type<string | { box: string }>\n     * const T = type("string").or({ box: "string" })\n     */\n    or<const def, r = instantiateType<t | type.infer<def, $>, $>>(def: type.validate<def, $>): r extends infer _ ? _ : never;\n    /**\n     * #### intersect the parsed Type, returning an introspectable {@link Disjoint} if the result is unsatisfiable\n     *\n     * @example\n     * // Type<{ foo: number; bar: string }>\n     * const T = type({ foo: "number" }).intersect({ bar: "string" })\n     * const Bad = type("number > 10").intersect("number < 5")\n     * // logs "Intersection of > 10 and < 5 results in an unsatisfiable type"\n     * if (Bad instanceof Disjoint) console.log(`${bad.summary}`)\n     */\n    intersect<const def, r = instantiateType<inferIntersection<t, type.infer<def, $>>, $>>(def: type.validate<def, $>): r extends infer _ ? _ | Disjoint : never;\n    /**\n     * #### check if the parsed Type\'s constraints are identical\n     *\n     * ✅ equal types have identical input and output constraints and transforms\n     * @ignoresMeta\n     *\n     * @example\n     * const DivisibleBy6 = type.number.divisibleBy(6).moreThan(0)\n     * // false (left side must also be positive)\n     * DivisibleBy6.equals("number % 6")\n     * // false (right side has an additional <100 constraint)\n     * console.log(DivisibleBy6.equals("0 < (number % 6) < 100"))\n     * const ThirdTry = type("(number % 2) > 0").divisibleBy(3)\n     * // true (types are normalized and reduced)\n     * console.log(DivisibleBy6.equals(ThirdTry))\n     */\n    equals<const def>(def: type.validate<def, $>): boolean;\n    /**\n     * #### narrow this based on an {@link equals} check\n     *\n     * @ignoresMeta\n     *\n     * @example\n     * const N = type.raw(`${Math.random()}`)\n     * // Type<0.5> | undefined\n     * const Ez = N.ifEquals("0.5")\n     */\n    ifEquals<const def, r = type.instantiate<def, $>>(def: type.validate<def, $>): r extends infer _ ? _ | undefined : never;\n    /**\n     * #### check if this is a subtype of the parsed Type\n     *\n     * ✅ a subtype must include all constraints from the base type\n     * ✅ unlike {@link equals}, additional constraints may be present\n     * @ignoresMeta\n     *\n     * @example\n     * type.string.extends("unknown") // true\n     * type.string.extends(/^a.*z$/) // false\n     */\n    extends<const def>(other: type.validate<def, $>): boolean;\n    /**\n     * #### narrow this based on an {@link extends} check\n     *\n     * @ignoresMeta\n     *\n     * @example\n     * const N = type(Math.random() > 0.5 ? "true" : "0") // Type<0 | true>\n     * const Ez = N.ifExtends("boolean") // Type<true> | undefined\n     */\n    ifExtends<const def, r = type.instantiate<def, $>>(other: type.validate<def, $>): r extends infer _ ? _ | undefined : never;\n    /**\n     * #### check if a value could satisfy this and the parsed Type\n     *\n     * ⚠️ will return true unless a {@link Disjoint} can be proven\n     *\n     * @example\n     * type.string.overlaps("string | number") // true (e.g. "foo")\n     * type("string | number").overlaps("1") // true (1)\n     * type("number > 0").overlaps("number < 0") // false (no values exist)\n     *\n     * const NoAt = type("string").narrow(s => !s.includes("@"))\n     * NoAt.overlaps("string.email") // true (no values exist, but not provable)\n     */\n    overlaps<const def>(r: type.validate<def, $>): boolean;\n    /**\n     * #### extract branches {@link extend}ing the parsed Type\n     *\n     * @example\n     * // Type<true | 0 | 2>\n     * const T = type("boolean | 0 | \'one\' | 2 | bigint").extract("number | 0n | true")\n     */\n    extract<const def, r = instantiateType<t extends type.infer<def, $> ? t : never, $>>(r: type.validate<def, $>): r extends infer _ extends r ? _ : never;\n    /**\n     * #### exclude branches {@link extend}ing the parsed Type\n     *\n     * @example\n     *\n     * // Type<false | \'one\' | bigint>\n     * const T = type("boolean | 0 | \'one\' | 2 | bigint").exclude("number | 0n | true")\n     */\n    exclude<const def, r = instantiateType<t extends type.infer<def, $> ? never : t, $>>(r: type.validate<def, $>): r extends infer _ ? _ : never;\n    /**\n     * @experimental\n     * Map and optionally reduce branches of a union. Types that are not unions\n     * are treated as a single branch.\n     *\n     * @param mapBranch - the mapping function, accepting a branch Type\n     *     Returning another `Type` is common, but any value can be returned and\n     *     inferred as part of the output.\n     *\n     * @param [reduceMapped] - an operation to perform on the mapped branches\n     *     Can be used to e.g. merge an array of returned Types representing\n     *     branches back to a single union.\n     */\n    distribute<mapOut, reduceOut = mapOut[]>(mapBranch: (branch: Type, i: number, branches: array<Type>) => mapOut, reduceMapped?: (mappedBranches: mapOut[]) => reduceOut): reduceOut;\n    /** The Type\'s [StandardSchema](https://github.com/standard-schema/standard-schema) properties */\n    "~standard": StandardSchemaV1.ArkTypeProps<this["inferIn"], this["inferOut"]>;\n    /** @deprecated */\n    apply: Function["apply"];\n    /** @deprecated */\n    bind: Function["bind"];\n    /** @deprecated */\n    call: Function["call"];\n    /** @deprecated */\n    caller: Function;\n    /** @deprecated */\n    length: number;\n    /** @deprecated */\n    name: string;\n    /** @deprecated */\n    prototype: Function["prototype"];\n    /** @deprecated */\n    arguments: Function["arguments"];\n    /** @deprecated */\n    Symbol: never;\n}\ninterface ChainedPipeParser<$, t> extends NaryPipeParser<$, t> {\n    try: NaryPipeParser<$, t>;\n}\ntype validateChainedAsArgs<t> = [\n    t\n] extends [unset] ? [\n    t\n] extends [anyOrNever] ? [\n] : [\n    ErrorMessage<"as requires an explicit type parameter like myType.as<t>()">\n] : [];\n\ntype MatchParserContext<input = unknown> = {\n    cases: Morph[];\n    $: unknown;\n    input: input;\n    checked: boolean;\n    key: PropertyKey | null;\n};\ndeclare namespace ctx {\n    type from<ctx extends MatchParserContext> = ctx;\n    type init<$, input = unknown, checked extends boolean = false> = from<{\n        cases: [];\n        $: $;\n        input: input;\n        checked: checked;\n        key: null;\n    }>;\n    type atKey<ctx extends MatchParserContext, key extends string> = from<{\n        cases: ctx["cases"];\n        $: ctx["$"];\n        input: ctx["input"];\n        checked: ctx["checked"];\n        key: key;\n    }>;\n}\ninterface MatchParser<$> extends CaseMatchParser<ctx.init<$>> {\n    in<const def>(def: type.validate<def, $>): ChainableMatchParser<ctx.init<$, type.infer<def, $>, true>>;\n    in<const typedInput = never>(...args: [typedInput] extends [never] ? [\n        ErrorMessage<"in requires a definition or type argument (in(\'string\') or in<string>())">\n    ] : []): ChainableMatchParser<ctx.init<$, typedInput>>;\n    in<const def>(def: type.validate<def, $>): ChainableMatchParser<ctx.init<$, type.infer<def, $>, true>>;\n    case: CaseParser<ctx.init<$>>;\n    at: AtParser<ctx.init<$>>;\n}\ntype addCasesToContext<ctx extends MatchParserContext, cases extends unknown[]> = cases extends Morph[] ? ctx.from<{\n    $: ctx["$"];\n    input: ctx["input"];\n    cases: [...ctx["cases"], ...cases];\n    checked: ctx["checked"];\n    key: ctx["key"];\n}> : never;\ntype addDefaultToContext<ctx extends MatchParserContext, defaultCase extends DefaultCase<ctx>> = ctx.from<{\n    $: ctx["$"];\n    input: defaultCase extends "never" ? Morph.In<ctx["cases"][number]> : ctx["input"];\n    cases: defaultCase extends "never" | "assert" ? ctx["cases"] : defaultCase extends Morph ? ctx["checked"] extends true ? [\n        (In: unknown) => ArkErrors,\n        ...ctx["cases"],\n        defaultCase\n    ] : [...ctx["cases"], defaultCase] : [\n        ...ctx["cases"],\n        (In: ctx["input"]) => ArkErrors\n    ];\n    checked: ctx["checked"];\n    key: ctx["key"];\n}>;\ntype CaseKeyKind = "def" | "string";\ntype casesToMorphTuple<cases, ctx extends MatchParserContext, kind extends CaseKeyKind> = unionToTuple<propValueOf<{\n    [def in Exclude<keyof cases, "default">]: cases[def] extends (Morph<never, infer o>) ? kind extends "def" ? (In: inferCaseArg<def extends number ? `${number}` : def, ctx, "in">) => o : (In: maybeLiftToKey<def, ctx>) => o : never;\n}>>;\ntype addCasesToParser<cases, ctx extends MatchParserContext, kind extends CaseKeyKind> = cases extends {\n    default: infer defaultDef extends DefaultCase<ctx>;\n} ? finalizeMatchParser<addCasesToContext<ctx, casesToMorphTuple<cases, ctx, kind>>, defaultDef> : ChainableMatchParser<addCasesToContext<ctx, casesToMorphTuple<cases, ctx, kind>>>;\ntype inferCaseArg<def, ctx extends MatchParserContext, endpoint extends "in" | "out"> = _finalizeCaseArg<maybeLiftToKey<type.infer<def, ctx["$"]>, ctx>, ctx, endpoint>;\ntype maybeLiftToKey<t, ctx extends MatchParserContext> = ctx["key"] extends PropertyKey ? {\n    [k in ctx["key"]]: t;\n} : t;\ntype _finalizeCaseArg<t, ctx extends MatchParserContext, endpoint extends "in" | "out"> = [\n    distill<t, "in">,\n    distill<t, endpoint>\n] extends [infer i, infer result] ? i extends ctx["input"] ? result : Extract<ctx["input"], i> extends never ? result : Extract<ctx["input"], result> : never;\ntype CaseParser<ctx extends MatchParserContext> = <const def, ret>(def: type.validate<def, ctx["$"]>, resolve: (In: inferCaseArg<def, ctx, "out">) => ret) => ChainableMatchParser<addCasesToContext<ctx, [(In: inferCaseArg<def, ctx, "in">) => ret]>>;\ntype validateKey<key extends Key, ctx extends MatchParserContext> = ctx["key"] extends Key ? ErrorMessage<doubleAtMessage> : ctx["cases"]["length"] extends 0 ? keyof ctx["input"] extends never ? key : conform<key, keyof ctx["input"]> : ErrorMessage<chainedAtMessage>;\ninterface StringsParser<ctx extends MatchParserContext> {\n    <const cases>(def: cases extends validateStringCases<cases, ctx> ? cases : validateStringCases<cases, ctx>): addCasesToParser<cases, ctx, "string">;\n}\ntype validateStringCases<cases, ctx extends MatchParserContext> = {\n    [k in keyof cases | stringValue<ctx> | "default"]?: k extends "default" ? DefaultCase<ctx> : k extends stringValue<ctx> ? (In: _finalizeCaseArg<maybeLiftToKey<k, ctx>, ctx, "out">) => unknown : ErrorType<`${k & string} must be a possible string value`>;\n};\ntype stringValue<ctx extends MatchParserContext> = ctx["key"] extends keyof ctx["input"] ? ctx["input"][ctx["key"]] extends string ? ctx["input"][ctx["key"]] : never : ctx["input"] extends string ? ctx["input"] : never;\ninterface AtParser<ctx extends MatchParserContext> {\n    <const key extends string>(key: validateKey<key, ctx>): ChainableMatchParser<ctx.atKey<ctx, key>>;\n    <const key extends string, const cases, ctxAtKey extends MatchParserContext = ctx.atKey<ctx, key>>(key: validateKey<key, ctx>, cases: cases extends validateCases<cases, ctxAtKey> ? cases : errorCases<cases, ctxAtKey>): addCasesToParser<cases, ctxAtKey, "def">;\n}\ninterface ChainableMatchParser<ctx extends MatchParserContext> {\n    case: CaseParser<ctx>;\n    match: CaseMatchParser<ctx>;\n    default: DefaultMethod<ctx>;\n    at: AtParser<ctx>;\n    /** @experimental */\n    strings: StringsParser<ctx>;\n}\ntype DefaultCaseKeyword = "never" | "assert" | "reject";\ntype DefaultCase<ctx extends MatchParserContext = MatchParserContext<any>> = DefaultCaseKeyword | Morph<ctx["input"]>;\ntype DefaultMethod<ctx extends MatchParserContext> = <const def extends DefaultCase<ctx>>(def: def) => finalizeMatchParser<ctx, def>;\ntype validateCases<cases, ctx extends MatchParserContext> = {\n    [def in keyof cases | BaseCompletions<ctx["$"], {}, "default">]?: def extends "default" ? DefaultCase<ctx> : def extends number ? (In: inferCaseArg<`${def}`, ctx, "out">) => unknown : def extends type.validate<def, ctx["$"]> ? (In: inferCaseArg<def, ctx, "out">) => unknown : type.validate<def, ctx["$"]>;\n};\ntype errorCases<cases, ctx extends MatchParserContext> = {\n    [def in keyof cases]?: def extends "default" ? DefaultCase<ctx> : def extends number ? (In: inferCaseArg<`${def}`, ctx, "out">) => unknown : def extends type.validate<def, ctx["$"]> ? (In: inferCaseArg<def, ctx, "out">) => unknown : ErrorType<type.validate<def, ctx["$"]>>;\n} & {\n    [k in BaseCompletions<ctx["$"], {}>]?: (In: inferCaseArg<k, ctx, "out">) => unknown;\n} & {\n    default?: DefaultCase<ctx>;\n};\ntype CaseMatchParser<ctx extends MatchParserContext> = <const cases>(def: cases extends validateCases<cases, ctx> ? cases : errorCases<cases, ctx>) => addCasesToParser<cases, ctx, "def">;\ntype finalizeMatchParser<ctx extends MatchParserContext, defaultCase extends DefaultCase<ctx>> = addDefaultToContext<ctx, defaultCase> extends (infer ctx extends MatchParserContext) ? Match<ctx["input"], ctx["cases"]> : never;\ninterface Match<In = any, cases extends Morph[] = Morph[]> extends Inferred<(In: Morph.In<cases[number]>) => Out<ReturnType<cases[number]>>> {\n    <const data extends In>(data: data): {\n        [i in numericStringKeyOf<cases>]: isDisjoint<data, Morph.In<cases[i]>> extends true ? never : Morph.Out<cases[i]>;\n    }[numericStringKeyOf<cases>];\n}\ndeclare class InternalMatchParser extends Callable<InternalCaseParserFn> {\n    $: InternalScope;\n    constructor($: InternalScope);\n    in(def?: unknown): InternalChainedMatchParser;\n    at(key: Key, cases?: InternalCases): InternalChainedMatchParser | Match;\n    case(when: unknown, then: Morph): InternalChainedMatchParser;\n}\ntype InternalCases = Record<string, Morph | DefaultCase>;\ntype InternalCaseParserFn = (cases: InternalCases) => InternalChainedMatchParser | Match;\ntype CaseEntry = [BaseRoot, Morph] | ["default", DefaultCase];\ndeclare class InternalChainedMatchParser extends Callable<InternalCaseParserFn> {\n    $: InternalScope;\n    in: BaseRoot | undefined;\n    protected key: Key | undefined;\n    protected branches: BaseRoot[];\n    constructor($: InternalScope, In?: BaseRoot);\n    at(key: Key, cases?: InternalCases): InternalChainedMatchParser | Match;\n    case(def: unknown, resolver: Morph): InternalChainedMatchParser;\n    protected caseEntry(node: BaseRoot, resolver: Morph): InternalChainedMatchParser;\n    match(cases: InternalCases): InternalChainedMatchParser | Match;\n    strings(cases: InternalCases): InternalChainedMatchParser | Match;\n    protected caseEntries(entries: CaseEntry[]): InternalChainedMatchParser | Match;\n    default(defaultCase: DefaultCase): Match;\n}\ndeclare const chainedAtMessage = "A key matcher must be specified before the first case i.e. match.at(\'foo\') or match.in<object>().at(\'bar\')";\ntype chainedAtMessage = typeof chainedAtMessage;\ndeclare const doubleAtMessage = "At most one key matcher may be specified per expression";\ntype doubleAtMessage = typeof doubleAtMessage;\n\ndeclare class MergeHkt extends Hkt<[base: object, props: object]> {\n    body: util.merge<this[0], this[1]>;\n    description: string;\n}\ndeclare const Merge: _ark_schema.GenericRoot<readonly [["base", object], ["props", object]], MergeHkt>;\ndeclare const arkBuiltins: arkBuiltins;\ntype arkBuiltins = Module<arkBuiltins.$>;\ndeclare namespace arkBuiltins {\n    type submodule = Submodule<$>;\n    type $ = {\n        Key: Key;\n        Merge: typeof Merge.t;\n    };\n}\n\ndeclare const number: number.module;\ndeclare namespace number {\n    type module = Module<submodule>;\n    type submodule = Submodule<$>;\n    type $ = {\n        root: number;\n        epoch: number;\n        integer: number;\n        safe: number;\n        NaN: number;\n        Infinity: number;\n        NegativeInfinity: number;\n    };\n}\n\ndeclare const stringInteger: stringInteger.module;\ndeclare namespace stringInteger {\n    type module = Module<submodule>;\n    type submodule = Submodule<$>;\n    type $ = {\n        root: string;\n        parse: (In: string) => To<number>;\n    };\n}\ndeclare const base64: Module<{\n    root: unknown;\n    url: unknown;\n}>;\ndeclare namespace base64 {\n    type module = Module<submodule>;\n    type submodule = Submodule<$>;\n    type $ = {\n        root: string;\n        url: string;\n    };\n}\ndeclare const capitalize: capitalize.module;\ndeclare namespace capitalize {\n    type module = Module<submodule>;\n    type submodule = Submodule<$>;\n    type $ = {\n        root: (In: string) => To<string>;\n        preformatted: string;\n    };\n}\ndeclare const stringDate: stringDate.module;\ndeclare namespace stringDate {\n    type module = Module<stringDate.submodule>;\n    type submodule = Submodule<$>;\n    type $ = {\n        root: string;\n        parse: (In: string) => To<Date>;\n        iso: iso.submodule;\n        epoch: epoch.submodule;\n    };\n    namespace iso {\n        type submodule = Submodule<$>;\n        type $ = {\n            root: string;\n            parse: (In: string) => To<Date>;\n        };\n    }\n    namespace epoch {\n        type submodule = Submodule<$>;\n        type $ = {\n            root: string;\n            parse: (In: string) => To<Date>;\n        };\n    }\n}\ndeclare const ip: ip.module;\ndeclare namespace ip {\n    type module = Module<submodule>;\n    type submodule = Submodule<$>;\n    type $ = {\n        root: string;\n        v4: string;\n        v6: string;\n    };\n}\ndeclare namespace stringJson {\n    type module = Module<submodule>;\n    type submodule = Submodule<$>;\n    type $ = {\n        root: string;\n        parse: (In: string) => To<Json>;\n    };\n}\ndeclare namespace lower {\n    type module = Module<submodule>;\n    type submodule = Submodule<$>;\n    type $ = {\n        root: (In: string) => To<string>;\n        preformatted: string;\n    };\n}\ndeclare const normalize: Module<{\n    root: unknown;\n    NFC: Submodule<{\n        root: unknown;\n        preformatted: unknown;\n    }>;\n    NFD: Submodule<{\n        root: unknown;\n        preformatted: unknown;\n    }>;\n    NFKC: Submodule<{\n        root: unknown;\n        preformatted: unknown;\n    }>;\n    NFKD: Submodule<{\n        root: unknown;\n        preformatted: unknown;\n    }>;\n}>;\ndeclare namespace normalize {\n    type module = Module<submodule>;\n    type submodule = Submodule<$>;\n    type $ = {\n        root: (In: string) => To<string>;\n        NFC: NFC.submodule;\n        NFD: NFD.submodule;\n        NFKC: NFKC.submodule;\n        NFKD: NFKD.submodule;\n    };\n    namespace NFC {\n        type submodule = Submodule<$>;\n        type $ = {\n            root: (In: string) => To<string>;\n            preformatted: string;\n        };\n    }\n    namespace NFD {\n        type submodule = Submodule<$>;\n        type $ = {\n            root: (In: string) => To<string>;\n            preformatted: string;\n        };\n    }\n    namespace NFKC {\n        type submodule = Submodule<$>;\n        type $ = {\n            root: (In: string) => To<string>;\n            preformatted: string;\n        };\n    }\n    namespace NFKD {\n        type submodule = Submodule<$>;\n        type $ = {\n            root: (In: string) => To<string>;\n            preformatted: string;\n        };\n    }\n}\ndeclare namespace stringNumeric {\n    type module = Module<submodule>;\n    type submodule = Submodule<$>;\n    type $ = {\n        root: string;\n        parse: (In: string) => To<number>;\n    };\n}\ndeclare namespace trim {\n    type module = Module<submodule>;\n    type submodule = Submodule<$>;\n    type $ = {\n        root: (In: string) => To<string>;\n        preformatted: string;\n    };\n}\ndeclare const upper: upper.module;\ndeclare namespace upper {\n    type module = Module<submodule>;\n    type submodule = Submodule<$>;\n    type $ = {\n        root: (In: string) => To<string>;\n        preformatted: string;\n    };\n}\ndeclare const url: url.module;\ndeclare namespace url {\n    type module = Module<submodule>;\n    type submodule = Submodule<$>;\n    type $ = {\n        root: string;\n        parse: (In: string) => To<URL>;\n    };\n}\ndeclare const uuid: Module<{\n    root: string;\n    v4: unknown;\n    v6: unknown;\n    v1: unknown;\n    v2: unknown;\n    v3: unknown;\n    v5: unknown;\n    v7: unknown;\n    v8: unknown;\n}>;\ndeclare namespace uuid {\n    type module = Module<submodule>;\n    type submodule = Submodule<$>;\n    type $ = {\n        root: string;\n        v1: string;\n        v2: string;\n        v3: string;\n        v4: string;\n        v5: string;\n        v6: string;\n        v7: string;\n        v8: string;\n    };\n    namespace $ {\n        type flat = {};\n    }\n}\ndeclare const string: Module<{\n    integer: Submodule<stringInteger.submodule>;\n    trim: Submodule<trim.submodule>;\n    normalize: Submodule<{\n        root: unknown;\n        NFC: Submodule<{\n            root: unknown;\n            preformatted: unknown;\n        }>;\n        NFD: Submodule<{\n            root: unknown;\n            preformatted: unknown;\n        }>;\n        NFKC: Submodule<{\n            root: unknown;\n            preformatted: unknown;\n        }>;\n        NFKD: Submodule<{\n            root: unknown;\n            preformatted: unknown;\n        }>;\n    }>;\n    root: unknown;\n    json: Submodule<stringJson.submodule>;\n    date: Submodule<stringDate.submodule>;\n    lower: Submodule<lower.submodule>;\n    upper: Submodule<upper.submodule>;\n    alpha: unknown;\n    alphanumeric: unknown;\n    hex: unknown;\n    base64: Submodule<{\n        root: unknown;\n        url: unknown;\n    }>;\n    capitalize: Submodule<capitalize.submodule>;\n    creditCard: unknown;\n    digits: unknown;\n    email: unknown;\n    ip: Submodule<ip.submodule>;\n    numeric: Submodule<stringNumeric.submodule>;\n    semver: unknown;\n    url: Submodule<url.submodule>;\n    uuid: Submodule<{\n        root: string;\n        v4: unknown;\n        v6: unknown;\n        v1: unknown;\n        v2: unknown;\n        v3: unknown;\n        v5: unknown;\n        v7: unknown;\n        v8: unknown;\n    }>;\n}>;\ndeclare namespace string {\n    type module = Module<string.submodule>;\n    type submodule = Submodule<$>;\n    type $ = {\n        root: string;\n        alpha: string;\n        alphanumeric: string;\n        hex: string;\n        base64: base64.submodule;\n        capitalize: capitalize.submodule;\n        creditCard: string;\n        date: stringDate.submodule;\n        digits: string;\n        email: string;\n        integer: stringInteger.submodule;\n        ip: ip.submodule;\n        json: stringJson.submodule;\n        lower: lower.submodule;\n        normalize: normalize.submodule;\n        numeric: stringNumeric.submodule;\n        semver: string;\n        trim: trim.submodule;\n        upper: upper.submodule;\n        url: url.submodule;\n        uuid: uuid.submodule;\n    };\n}\n\ndeclare const arkTsKeywords: arkTsKeywords;\ntype arkTsKeywords = Module<arkTsKeywords.$>;\ndeclare namespace arkTsKeywords {\n    type submodule = Submodule<$>;\n    type $ = {\n        bigint: bigint;\n        boolean: boolean;\n        false: false;\n        never: never;\n        null: null;\n        number: number;\n        object: object;\n        string: string;\n        symbol: symbol;\n        true: true;\n        unknown: unknown;\n        undefined: undefined;\n    };\n}\ndeclare const unknown: Module<{\n    any: unknown;\n    root: unknown;\n}>;\ndeclare namespace unknown {\n    type submodule = Submodule<$>;\n    type $ = {\n        root: unknown;\n        any: any;\n    };\n}\ndeclare const json: Module<{\n    stringify: unknown;\n    root: unknown;\n}>;\ndeclare namespace json {\n    type submodule = Submodule<$>;\n    type $ = {\n        root: Json;\n        stringify: (In: Json) => To<string>;\n    };\n}\ndeclare const object: Module<{\n    root: unknown;\n    json: Submodule<{\n        stringify: unknown;\n        root: unknown;\n    }>;\n}>;\ndeclare namespace object {\n    type submodule = Submodule<$>;\n    type $ = {\n        root: object;\n        json: json.submodule;\n    };\n}\ndeclare class RecordHkt extends Hkt<[Key, unknown]> {\n    body: Record$1<this[0], this[1]>;\n    description: string;\n}\ndeclare const Record$1: _ark_schema.GenericRoot<readonly [["K", Key], ["V", unknown]], RecordHkt>;\ndeclare class PickHkt extends Hkt<[object, Key]> {\n    body: pick<this[0], this[1] & keyof this[0]>;\n    description: string;\n}\ndeclare const Pick: _ark_schema.GenericRoot<readonly [["T", object], ["K", Key]], PickHkt>;\ndeclare class OmitHkt extends Hkt<[object, Key]> {\n    body: omit<this[0], this[1] & keyof this[0]>;\n    description: string;\n}\ndeclare const Omit$1: _ark_schema.GenericRoot<readonly [["T", object], ["K", Key]], OmitHkt>;\ndeclare class PartialHkt extends Hkt<[object]> {\n    body: show<Partial<this[0]>>;\n    description: string;\n}\ndeclare const Partial: _ark_schema.GenericRoot<readonly [["T", object]], PartialHkt>;\ndeclare class RequiredHkt extends Hkt<[object]> {\n    body: show<Required<this[0]>>;\n    description: string;\n}\ndeclare const Required: _ark_schema.GenericRoot<readonly [["T", object]], RequiredHkt>;\ndeclare class ExcludeHkt extends Hkt<[unknown, unknown]> {\n    body: Exclude$1<this[0], this[1]>;\n    description: string;\n}\ndeclare const Exclude$1: _ark_schema.GenericRoot<readonly [["T", unknown], ["U", unknown]], ExcludeHkt>;\ndeclare class ExtractHkt extends Hkt<[unknown, unknown]> {\n    body: Extract$1<this[0], this[1]>;\n    description: string;\n}\ndeclare const Extract$1: _ark_schema.GenericRoot<readonly [["T", unknown], ["U", unknown]], ExtractHkt>;\ndeclare const arkTsGenerics: arkTsGenerics.module;\ndeclare namespace arkTsGenerics {\n    type module = Module<arkTsGenerics.$>;\n    type submodule = Submodule<$>;\n    type $ = {\n        Exclude: typeof Exclude$1.t;\n        Extract: typeof Extract$1.t;\n        Omit: typeof Omit$1.t;\n        Partial: typeof Partial.t;\n        Pick: typeof Pick.t;\n        Record: typeof Record$1.t;\n        Required: typeof Required.t;\n    };\n}\n\ninterface Ark extends Omit<Ark.keywords, keyof Ark.wrapped>, Ark.wrapped {\n}\ndeclare namespace Ark {\n    interface keywords extends arkTsKeywords.$, arkTsGenerics.$, arkPrototypes.keywords, arkBuiltins.$ {\n    }\n    interface wrapped extends arkPrototypes.wrapped {\n        string: string.submodule;\n        number: number.submodule;\n        object: object.submodule;\n        unknown: unknown.submodule;\n    }\n    type flat = flatResolutionsOf<Ark>;\n    interface typeAttachments extends arkTsKeywords.$ {\n        arrayIndex: arkPrototypes.$["Array"]["index"];\n        Key: arkBuiltins.$["Key"];\n        Record: arkTsGenerics.$["Record"];\n        Date: arkPrototypes.$["Date"];\n        Array: arkPrototypes.$["Array"]["root"];\n    }\n    interface boundTypeAttachments<$> extends Omit<BoundModule<typeAttachments, $>, arkKind> {\n    }\n}\ndeclare const ark: Scope<Ark>;\ndeclare const keywords: Module<Ark>;\ndeclare const type: TypeParser<{}>;\ndeclare namespace type {\n    interface cast<to> {\n        [inferred]?: to;\n    }\n    type errors = ArkErrors;\n    type validate<def, $ = {}, args = bindThis<def>> = validateDefinition<def, $, args>;\n    type instantiate<def, $ = {}, args = bindThis<def>> = instantiateType<inferDefinition<def, $, args>, $>;\n    type infer<def, $ = {}, args = bindThis<def>> = inferDefinition<def, $, args>;\n    namespace infer {\n        type In<def, $ = {}, args = {}> = distill.In<inferDefinition<def, $, args>>;\n        type Out<def, $ = {}, args = {}> = distill.Out<inferDefinition<def, $, args>>;\n        namespace introspectable {\n            type Out<def, $ = {}, args = {}> = distill.introspectable.Out<inferDefinition<def, $, args>>;\n        }\n    }\n    type brand<t, id> = t extends InferredMorph<infer i, infer o> ? o["introspectable"] extends true ? (In: i) => To<Brand<o["t"], id>> : (In: i) => Out<Brand<o["t"], id>> : Brand<t, id>;\n    /** @ts-ignore cast variance */\n    interface Any<out t = any, $ = any> extends Type<t, $> {\n    }\n}\ntype type<t = unknown, $ = {}> = Type$1<t, $>;\ndeclare const match: MatchParser<{}>;\ndeclare const generic: GenericParser<{}>;\ndeclare const define: DefinitionParser<{}>;\ndeclare const declare: DeclarationParser<{}>;\n\ntype ParameterString<params extends string = string> = `<${params}>`;\ntype extractParams<s extends ParameterString> = s extends ParameterString<infer params> ? params : never;\ntype validateParameterString<s extends ParameterString, $> = parseGenericParams<extractParams<s>, $> extends infer e extends ErrorMessage ? e : s;\ntype validateGenericArg<arg, param extends GenericParamAst, $> = type.infer<arg, $> extends param[1] ? unknown : ErrorType<`Invalid argument for ${param[0]}`, [expected: param[1]]>;\ntype GenericInstantiator<params extends array<GenericParamAst>, def, $, args$> = params["length"] extends 1 ? {\n    <const a, r = instantiateGeneric<def, params, [a], $, args$>>(a: type.validate<a, args$> & validateGenericArg<a, params[0], args$>): r extends infer _ ? _ : never;\n} : params["length"] extends 2 ? {\n    <const a, const b, r = instantiateGeneric<def, params, [a, b], $, args$>>(...args: [\n        type.validate<a, args$> & validateGenericArg<a, params[0], args$>,\n        type.validate<b, args$> & validateGenericArg<b, params[1], args$>\n    ]): r extends infer _ ? _ : never;\n} : params["length"] extends 3 ? {\n    <const a, const b, const c, r = instantiateGeneric<def, params, [a, b, c], $, args$>>(...args: [\n        type.validate<a, args$> & validateGenericArg<a, params[0], args$>,\n        type.validate<b, args$> & validateGenericArg<b, params[1], args$>,\n        type.validate<c, args$> & validateGenericArg<c, params[2], args$>\n    ]): r extends infer _ ? _ : never;\n} : params["length"] extends 4 ? {\n    <const a, const b, const c, const d, r = instantiateGeneric<def, params, [a, b, c, d], $, args$>>(...args: [\n        type.validate<a, args$> & validateGenericArg<a, params[0], args$>,\n        type.validate<b, args$> & validateGenericArg<b, params[1], args$>,\n        type.validate<c, args$> & validateGenericArg<c, params[2], args$>,\n        type.validate<d, args$> & validateGenericArg<d, params[3], args$>\n    ]): r extends infer _ ? _ : never;\n} : params["length"] extends 5 ? {\n    <const a, const b, const c, const d, const e, r = instantiateGeneric<def, params, [a, b, c, d, e], $, args$>>(...args: [\n        type.validate<a, args$> & validateGenericArg<a, params[0], args$>,\n        type.validate<b, args$> & validateGenericArg<b, params[1], args$>,\n        type.validate<c, args$> & validateGenericArg<c, params[2], args$>,\n        type.validate<d, args$> & validateGenericArg<d, params[3], args$>,\n        type.validate<e, args$> & validateGenericArg<e, params[4], args$>\n    ]): r extends infer _ ? _ : never;\n} : params["length"] extends 6 ? {\n    <const a, const b, const c, const d, const e, const f, r = instantiateGeneric<def, params, [a, b, c, d, e, f], $, args$>>(...args: [\n        type.validate<a, args$> & validateGenericArg<a, params[0], args$>,\n        type.validate<b, args$> & validateGenericArg<b, params[1], args$>,\n        type.validate<c, args$> & validateGenericArg<c, params[2], args$>,\n        type.validate<d, args$> & validateGenericArg<d, params[3], args$>,\n        type.validate<e, args$> & validateGenericArg<e, params[4], args$>,\n        type.validate<f, args$> & validateGenericArg<f, params[5], args$>\n    ]): r extends infer _ ? _ : never;\n} : (error: ErrorMessage<`You may not define more than 6 positional generic parameters`>) => never;\ntype instantiateGeneric<def, params extends array<GenericParamAst>, args, $, args$> = Type$1<[\n    def\n] extends [Hkt] ? Hkt.apply<def, {\n    [i in keyof args]: type.infer<args[i], args$>;\n}> : inferDefinition<def, $, bindGenericArgs<params, args$, args>>, args$>;\ntype bindGenericArgs<params extends array<GenericParamAst>, $, args> = {\n    [i in keyof params & `${number}` as params[i][0]]: type.infer<args[i & keyof args], $>;\n};\ntype baseGenericResolutions<params extends array<GenericParamAst>, $> = baseGenericConstraints<params> extends infer baseConstraints ? {\n    [k in keyof baseConstraints]: Type$1<baseConstraints[k], $>;\n} : never;\ntype baseGenericConstraints<params extends array<GenericParamAst>> = {\n    [i in keyof params & `${number}` as params[i][0]]: params[i][1];\n};\ntype GenericConstructor<params extends array<GenericParamAst> = array<GenericParamAst>, bodyDef = unknown, $ = {}, arg$ = {}> = new () => Generic<params, bodyDef, $, arg$>;\ninterface Generic<params extends array<GenericParamAst> = array<GenericParamAst>, bodyDef = unknown, $ = {}, arg$ = $> extends Callable<GenericInstantiator<params, bodyDef, $, arg$>> {\n    [arkKind]: "generic";\n    t: GenericAst<params, bodyDef, $, arg$>;\n    bodyDef: bodyDef;\n    params: {\n        [i in keyof params]: [params[i][0], Type$1<params[i][1], $>];\n    };\n    names: genericParamNames<params>;\n    constraints: {\n        [i in keyof params]: Type$1<params[i][1], $>;\n    };\n    $: Scope<$>;\n    arg$: Scope<arg$>;\n    internal: GenericRoot;\n    json: JsonStructure;\n}\ndeclare const Generic: GenericConstructor;\ntype GenericDeclaration<name extends string = string, params extends ParameterString = ParameterString> = `${name}${params}`;\ntype parseValidGenericParams<def extends ParameterString, $> = conform<parseGenericParams<extractParams<def>, $>, array<GenericParamAst>>;\ndeclare const emptyGenericParameterMessage = "An empty string is not a valid generic parameter name";\ntype emptyGenericParameterMessage = typeof emptyGenericParameterMessage;\ntype parseGenericParams<def extends string, $> = parseNextNameChar<ArkTypeScanner.skipWhitespace<def>, "", [\n], $>;\ntype ParamsTerminator = WhitespaceChar | ",";\ntype parseName<unscanned extends string, result extends array<GenericParamAst>, $> = parseNextNameChar<ArkTypeScanner.skipWhitespace<unscanned>, "", result, $>;\ntype parseNextNameChar<unscanned extends string, name extends string, result extends array<GenericParamAst>, $> = unscanned extends `${infer lookahead}${infer nextUnscanned}` ? lookahead extends ParamsTerminator ? name extends "" ? ErrorMessage<emptyGenericParameterMessage> : lookahead extends "," ? parseName<nextUnscanned, [...result, [name, unknown]], $> : lookahead extends WhitespaceChar ? _parseOptionalConstraint<nextUnscanned, name, result, $> : never : parseNextNameChar<nextUnscanned, `${name}${lookahead}`, result, $> : name extends "" ? result : [...result, [name, unknown]];\ndeclare const extendsToken = "extends ";\ntype extendsToken = typeof extendsToken;\ndeclare const _parseOptionalConstraint: (scanner: ArkTypeScanner, name: string, result: GenericParamDef[], ctx: BaseParseContext) => GenericParamDef[];\ntype _parseOptionalConstraint<unscanned extends string, name extends string, result extends array<GenericParamAst>, $> = ArkTypeScanner.skipWhitespace<unscanned> extends (`${extendsToken}${infer nextUnscanned}`) ? parseUntilFinalizer<state.initialize<nextUnscanned>, $, {}> extends (infer finalArgState extends StaticState) ? validateAst<finalArgState["root"], $, {}> extends (infer e extends ErrorMessage) ? e : parseName<finalArgState["unscanned"], [\n    ...result,\n    [name, inferAstRoot<finalArgState["root"], $, {}>]\n], $> : never : parseName<ArkTypeScanner.skipWhitespace<unscanned> extends (`,${infer nextUnscanned}`) ? nextUnscanned : unscanned, [\n    ...result,\n    [name, unknown]\n], $>;\ntype genericParamDefToAst<schema extends GenericParamDef, $> = schema extends string ? [schema, unknown] : schema extends readonly [infer name, infer def] ? [name, type.infer<def, $>] : never;\ntype genericParamDefsToAst<defs extends array<GenericParamDef>, $> = [\n    ...{\n        [i in keyof defs]: genericParamDefToAst<defs[i], $>;\n    }\n];\ntype GenericParser<$ = {}> = <const paramsDef extends array<GenericParamDef>>(...params: {\n    [i in keyof paramsDef]: paramsDef[i] extends (readonly [infer name, infer def]) ? readonly [name, type.validate<def, $>] : paramsDef[i];\n}) => GenericBodyParser<genericParamDefsToAst<paramsDef, $>, $>;\ninterface GenericBodyParser<params extends array<GenericParamAst>, $> {\n    <const body>(body: type.validate<body, $, baseGenericConstraints<params>>): Generic<params, body, $, $>;\n    <hkt extends Hkt.constructor>(instantiateDef: LazyGenericBody<baseGenericResolutions<params, $>>, hkt: hkt): Generic<params, InstanceType<hkt>, $, $>;\n}\n\ndeclare const Module: new <$ extends {}>(exports: exportScope<$>) => Module<$>;\ninterface Module<$ extends {} = {}> extends RootModule<exportScope<$>> {\n}\ntype exportScope<$> = bindExportsToScope<$, $>;\ndeclare const BoundModule: new <exports extends {}, $ extends {}>(exports: bindExportsToScope<exports, $>, $: $) => BoundModule<exports, $>;\ninterface BoundModule<exports extends {}, $> extends RootModule<bindExportsToScope<exports, $>> {\n}\ntype bindExportsToScope<exports, $> = {\n    [k in keyof exports]: instantiateExport<exports[k], $>;\n} & unknown;\ntype Submodule<exports extends {}> = RootModule<exports & ("root" extends keyof exports ? {\n    [inferred]: exports["root"];\n} : {})>;\ntype instantiateExport<t, $> = [\n    t\n] extends [PreparsedNodeResolution] ? [\n    t\n] extends [anyOrNever] ? Type$1<t, $> : t extends GenericAst<infer params, infer body, infer body$> ? Generic<params, body, body$, $> : t extends Submodule<infer exports> ? BoundModule<exports, $> : never : Type$1<t, $>;\n\ndeclare class liftFromHkt extends Hkt<[element: unknown]> {\n    body: liftArray<this[0]> extends infer lifted ? (In: this[0] | lifted) => To<lifted> : never;\n}\ndeclare const liftFrom: _ark_schema.GenericRoot<readonly [["element", unknown]], liftFromHkt>;\ndeclare const arkArray: arkArray.module;\ndeclare namespace arkArray {\n    type module = Module<submodule>;\n    type submodule = Submodule<$>;\n    type $ = {\n        root: unknown[];\n        readonly: readonly unknown[];\n        index: NonNegativeIntegerString;\n        liftFrom: typeof liftFrom.t;\n    };\n}\ntype NonNegativeIntegerString = `${Digit}` | (`${Exclude<Digit, 0>}${string}` & `${bigint}`);\n\ntype FormDataValue = string | File;\ntype ParsedFormData = Record<string, FormDataValue | FormDataValue[]>;\ndeclare const arkFormData: arkFormData.module;\ndeclare namespace arkFormData {\n    type module = Module<submodule>;\n    type submodule = Submodule<$>;\n    type $ = {\n        root: FormData;\n        value: FormDataValue;\n        parse: (In: FormData) => To<ParsedFormData>;\n        parsed: ParsedFormData;\n    };\n}\n\ndeclare const TypedArray: TypedArray.module;\ndeclare namespace TypedArray {\n    type module = Module<TypedArray.$>;\n    type submodule = Submodule<$>;\n    type $ = {\n        Int8: Int8Array;\n        Uint8: Uint8Array;\n        Uint8Clamped: Uint8ClampedArray;\n        Int16: Int16Array;\n        Uint16: Uint16Array;\n        Int32: Int32Array;\n        Uint32: Uint32Array;\n        Float32: Float32Array;\n        Float64: Float64Array;\n        BigInt64: BigInt64Array;\n        BigUint64: BigUint64Array;\n    };\n}\n\ndeclare const omittedPrototypes: {\n    Boolean: 1;\n    Number: 1;\n    String: 1;\n};\ndeclare const arkPrototypes: arkPrototypes.module;\ndeclare namespace arkPrototypes {\n    type module = Module<submodule>;\n    type submodule = Submodule<$>;\n    interface keywords extends ecmascript, platform {\n    }\n    interface $ extends Omit<keywords, keyof wrapped>, wrapped {\n    }\n    interface wrapped {\n        Array: arkArray.submodule;\n        TypedArray: TypedArray.submodule;\n        FormData: arkFormData.submodule;\n    }\n    type ecmascript = Omit<EcmascriptObjects, keyof typeof omittedPrototypes>;\n    type platform = PlatformObjects;\n    interface instances extends ecmascript, platform {\n    }\n    type NonDegenerateName = keyof instances extends infer k ? k extends keyof instances ? {} extends instances[k] ? never : k : never : never;\n    type instanceOf<name extends NonDegenerateName = NonDegenerateName> = instances[name];\n}\n\ntype DateLiteral<source extends string = string> = `d"${source}"` | `d\'${source}\'`;\ntype LimitLiteral = number | DateLiteral;\ntype distill<t, endpoint extends distill.Endpoint> = finalizeDistillation<t, _distill<t, endpoint, never>>;\ndeclare namespace distill {\n    type Endpoint = "in" | "out" | "out.introspectable";\n    type In<t> = distill<t, "in">;\n    type Out<t> = distill<t, "out">;\n    namespace introspectable {\n        type Out<t> = distill<t, "out.introspectable">;\n    }\n}\ntype finalizeDistillation<t, distilled> = equals<t, distilled> extends true ? t : distilled;\ntype _distill<t, endpoint extends distill.Endpoint, seen> = t extends undefined ? t : [t] extends [anyOrNever | seen] ? t : unknown extends t ? unknown : t extends Brand<infer base> ? endpoint extends "in" ? base : t : t extends TerminallyInferredObject | Primitive ? t : t extends Function ? t extends (...args: never) => anyOrNever ? t : t extends InferredMorph<infer i, infer o> ? distillIo<i, o, endpoint, seen> : t : t extends Default<infer constraint> ? _distill<constraint, endpoint, seen> : t extends array ? distillArray<t, endpoint, seen | t> : isSafelyMappable<t> extends true ? distillMappable<t, endpoint, seen | t> : t;\ntype distillMappable<o, endpoint extends distill.Endpoint, seen> = endpoint extends "in" ? show<{\n    [k in keyof o as k extends inferredDefaultKeyOf<o> ? never : k]: _distill<o[k], endpoint, seen>;\n} & {\n    [k in inferredDefaultKeyOf<o>]?: _distill<o[k], endpoint, seen>;\n}> : {\n    [k in keyof o]: _distill<o[k], endpoint, seen>;\n};\ntype distillIo<i, o extends Out, endpoint extends distill.Endpoint, seen> = endpoint extends "out" ? _distill<o["t"], endpoint, seen> : endpoint extends "in" ? _distill<i, endpoint, seen> : o extends To<infer validatedOut> ? _distill<validatedOut, endpoint, seen> : unknown;\ntype unwrapInput<t> = t extends InferredMorph<infer i> ? t extends anyOrNever ? t : i : t;\ntype inferredDefaultKeyOf<o> = keyof o extends infer k ? k extends keyof o ? unwrapInput<o[k]> extends Default<infer t> ? [\n    t\n] extends [anyOrNever] ? never : k : never : never : never;\ntype distillArray<t extends array, endpoint extends distill.Endpoint, seen> = t[number][] extends t ? alignReadonly<_distill<t[number], endpoint, seen>[], t> : distillNonArraykeys<t, alignReadonly<distillArrayFromPrefix<[...t], endpoint, seen, []>, t>, endpoint, seen>;\ntype alignReadonly<result extends unknown[], original extends array> = original extends unknown[] ? result : Readonly<result>;\ntype distillNonArraykeys<originalArray extends array, distilledArray, endpoint extends distill.Endpoint, seen> = keyof originalArray extends keyof distilledArray ? distilledArray : distilledArray & _distill<{\n    [k in keyof originalArray as k extends keyof distilledArray ? never : k]: originalArray[k];\n}, endpoint, seen>;\ntype distillArrayFromPrefix<t extends array, endpoint extends distill.Endpoint, seen, prefix extends array> = t extends readonly [infer head, ...infer tail] ? distillArrayFromPrefix<tail, endpoint, seen, [\n    ...prefix,\n    _distill<head, endpoint, seen>\n]> : [...prefix, ...distillArrayFromPostfix<t, endpoint, seen, []>];\ntype distillArrayFromPostfix<t extends array, endpoint extends distill.Endpoint, seen, postfix extends array> = t extends readonly [...infer init, infer last] ? distillArrayFromPostfix<init, endpoint, seen, [\n    _distill<last, endpoint, seen>,\n    ...postfix\n]> : [...{\n    [i in keyof t]: _distill<t[i], endpoint, seen>;\n}, ...postfix];\ntype BuiltinTerminalObjectKind = Exclude<arkPrototypes.NonDegenerateName, "Array" | "Function">;\n/** Objects we don\'t want to expand during inference like Date or Promise */\ntype TerminallyInferredObject = arkPrototypes.instanceOf<BuiltinTerminalObjectKind> | ArkEnv.prototypes;\ntype inferPredicate<t, predicate> = predicate extends (data: any, ...args: any[]) => data is infer narrowed ? narrowed : t;\ntype inferNaryPipe<morphs extends readonly Morph[]> = _inferNaryPipe<morphs, unknown>;\ntype _inferNaryPipe<remaining extends readonly unknown[], result> = remaining extends (readonly [infer head extends Morph, ...infer tail extends Morph[]]) ? _inferNaryPipe<tail, inferMorph<result, head>> : result;\ntype inferNaryIntersection<types extends readonly unknown[]> = _inferNaryIntersection<types, unknown>;\ntype _inferNaryIntersection<remaining extends readonly unknown[], result> = remaining extends readonly [infer head, ...infer tail] ? _inferNaryIntersection<tail, inferIntersection<result, head>> : result;\ntype inferNaryMerge<types extends readonly unknown[]> = _inferNaryMerge<types, {}>;\ntype _inferNaryMerge<remaining extends readonly unknown[], result> = remaining extends (readonly [infer head, ...infer tail extends readonly unknown[]]) ? _inferNaryMerge<tail, merge<result, head>> : result;\ntype inferMorphOut<morph extends Morph> = Exclude<ReturnType<morph>, ArkError | ArkErrors>;\ndeclare const isMorphOutKey: " isMorphOut";\ninterface Out<o = any> {\n    [isMorphOutKey]: true;\n    t: o;\n    introspectable: boolean;\n}\ninterface To<o = any> extends Out<o> {\n    introspectable: true;\n}\ntype InferredMorph<i = any, o extends Out = Out> = (In: i) => o;\ndeclare const defaultsToKey: " defaultsTo";\ntype Default<t = unknown, v = unknown> = {\n    [defaultsToKey]: [t, v];\n};\ntype withDefault<t, v, undistributed = t> = t extends InferredMorph ? addDefaultToMorph<t, v> : Default<Exclude<undistributed, InferredMorph>, v>;\ntype addDefaultToMorph<t extends InferredMorph, v> = [\n    normalizeMorphDistribution<t>\n] extends [InferredMorph<infer i, infer o>] ? (In: Default<i, v>) => o : never;\ntype normalizeMorphDistribution<t, undistributedIn = t extends InferredMorph<infer i> ? i : never, undistributedOut extends Out = t extends InferredMorph<any, infer o> ? [\n    o\n] extends [To<infer unwrappedOut>] ? To<unwrappedOut> : o : never> = (Extract<t, InferredMorph> extends anyOrNever ? never : Extract<t, InferredMorph> extends InferredMorph<infer i, infer o> ? [\n    undistributedOut\n] extends [o] ? (In: undistributedIn) => undistributedOut : [undistributedIn] extends [i] ? (In: undistributedIn) => undistributedOut : t : never) | Exclude<t, InferredMorph> extends infer _ ? _ : never;\ntype defaultFor<t = unknown> = (Primitive extends t ? Primitive : t extends Primitive ? t : never) | (() => t);\ntype inferIntersection<l, r> = normalizeMorphDistribution<_inferIntersection<l, r, false>>;\ntype inferMorph<t, morph extends Morph> = morph extends type.cast<infer tMorph> ? inferPipe<t, tMorph> : inferMorphOut<morph> extends infer out ? (In: distill.In<t>) => Out<out> : never;\ntype inferPipe<l, r> = normalizeMorphDistribution<_inferIntersection<l, r, true>>;\ntype _inferIntersection<l, r, piped extends boolean> = [\n    l & r\n] extends [infer t extends anyOrNever] ? t : l extends InferredMorph<infer lIn, infer lOut> ? r extends InferredMorph<any, infer rOut> ? piped extends true ? (In: lIn) => rOut : never : piped extends true ? (In: lIn) => To<r> : (In: _inferIntersection<lIn, r, false>) => lOut : r extends InferredMorph<infer rIn, infer rOut> ? (In: _inferIntersection<rIn, l, false>) => rOut : [l, r] extends [object, object] ? intersectObjects<l, r, piped> extends infer result ? result : never : l & r;\ninterface MorphableIntersection<piped extends boolean> extends Hkt<[unknown, unknown]> {\n    body: _inferIntersection<this[0], this[1], piped>;\n}\ntype intersectObjects<l, r, piped extends boolean> = l extends array ? r extends array ? intersectArrays<l, r, MorphableIntersection<piped>> : // for an intersection with exactly one array operand like { name: string } & string[],\nl & r : r extends array ? l & r : show<{\n    [k in keyof l]: k extends keyof r ? _inferIntersection<l[k], r[k], piped> : l[k];\n} & {\n    [k in keyof r]: k extends keyof l ? _inferIntersection<l[k], r[k], piped> : r[k];\n}>;\n\nexport { Ark, ArkAmbient, type ArkConfig, type Type as BaseType, BoundModule, Generic, type KeywordConfig, Module, Scope, type Submodule, Type$1 as Type, ark, type bindThis, configure, declare, define, distill, generic, type inferDefinition, keywords, match, scope, type, type validateDefinition };\n\n}'
